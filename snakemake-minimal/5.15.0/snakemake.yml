!Command
positional:
- !Positional
  description: 'Targets to build. May be rules or files. (default: None)'
  position: 0
  name: target
  optional: false
named:
- !Flag
  description: 'Do not execute anything, and display what would be done. If you have
    a very large workflow, use --dry-run --quiet to just print a summary of the DAG
    of jobs. (default: False)'
  synonyms:
  - --dry-run
  - --dryrun
  - -n
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Name of profile to use for configuring Snakemake. Snakemake will search\
    \ for a corresponding folder in /etc/xdg/snakemake and /home/ubuntu/.config/snakemake.\
    \ Alternatively, this can be an absolute or relative path. The profile folder\
    \ has to contain a file 'config.yaml'. This file can be used to set default values\
    \ for command line options in YAML format. For example, '--cluster qsub' becomes\
    \ 'cluster: qsub' in the YAML file. Profiles can be obtained from https://github.com/snakemake-profiles.\
    \ (default: None)"
  synonyms:
  - --profile
  args: !SimpleFlagArg
    name: PROFILE
  optional: true
- !Flag
  description: '[RULE [RULE ...]] Store output files of given rules in a central cache
    given by the environment variable $SNAKEMAKE_OUTPUT_CACHE. Likewise, retrieve
    output files of the given rules from this cache if they have been created before
    (by anybody writing to the same cache), instead of actually executing the rules.
    Output files are identified by hashing all steps, parameters and software stack
    (conda envs or containers) needed to create them. (default: None)'
  synonyms:
  - --cache
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "The workflow definition in form of a snakefile.Usually, you should\
    \ not need to specify this. By default, Snakemake will search for 'Snakefile',\
    \ 'snakefile', 'workflow/Snakefile', 'workflow/snakefile' beneath the current\
    \ working directory, in this order. Only if you definitely want a different layout,\
    \ you need to use this parameter. (default: None)"
  synonyms:
  - --snakefile
  - -s
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: "[N], --jobs [N], -j [N] Use at most N CPU cores/jobs in parallel.\
    \ If N is omitted or 'all', the limit is set to the number of available CPU cores.\
    \ (default: None)"
  synonyms:
  - --cores
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'In cluster mode, use at most N cores of the host machine in parallel
    (default: number of CPU cores of the host). The cores are used to execute local
    rules. This option is ignored when not in cluster mode. (default: 8)'
  synonyms:
  - --local-cores
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: "[NAME=INT [NAME=INT ...]], --res [NAME=INT [NAME=INT ...]] Define\
    \ additional resources that shall constrain the scheduling analogously to threads\
    \ (see above). A resource is defined as a name and an integer value. E.g. --resources\
    \ mem_mb=1000. Rules can use resources by defining the resource keyword, e.g.\
    \ resources: mem_mb=600. If now two rules require 600 of the resource 'mem_mb'\
    \ they won't be run in parallel by the scheduler. (default: None)"
  synonyms:
  - --resources
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: '[RULE=THREADS [RULE=THREADS ...]] Overwrite thread usage of rules.
    This allows to fine- tune workflow parallelization. In particular, this is helpful
    to target certain cluster nodes by e.g. shifting a rule to use more, or less threads
    than defined in the workflow. Thereby, THREADS has to be a positive integer, and
    RULE has to be the name of the rule. (default: None)'
  synonyms:
  - --set-threads
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "[NAME=INT [NAME=INT ...]], --default-res [NAME=INT [NAME=INT ...]]\
    \ Define default values of resources for rules that do not define their own values.\
    \ In addition to plain integers, python expressions over inputsize are allowed\
    \ (e.g. '2*input.size_mb').When specifying this without any arguments (--default-resources),\
    \ it defines 'mem_mb=max(2*input.size_mb, 1000)' 'disk_mb=max(2*input.size_mb,\
    \ 1000)', i.e., default disk and mem usage is twice the input file size but at\
    \ least 1GB. (default: None)"
  synonyms:
  - --default-resources
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: '[KEY=VALUE [KEY=VALUE ...]], -C [KEY=VALUE [KEY=VALUE ...]] Set or
    overwrite values in the workflow config object. The workflow config object is
    accessible as variable config inside the workflow. Default values can be set by
    providing a JSON file (see Documentation). (default: None)'
  synonyms:
  - --config
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Specify or overwrite the config file of the workflow (see the docs).
    Values specified in JSON or YAML format are available in the global config dictionary
    inside the workflow. Multiple files overwrite each other in the given order. (default:
    None)'
  synonyms:
  - --configfile
  - --configfiles
  args: !RepeatFlagArg
    name: FILE
  optional: true
- !Flag
  description: 'Specify working directory (relative paths in the snakefile will use
    this as their origin). (default: None)'
  synonyms:
  - --directory
  - -d
  args: !SimpleFlagArg
    name: DIR
  optional: true
- !Flag
  description: 'Touch output files (mark them up to date without really changing them)
    instead of running their commands. This is used to pretend that the rules were
    executed, in order to fool future invocations of snakemake. Fails if a file does
    not yet exist. Note that this will only touch files that would otherwise be recreated
    by Snakemake (e.g. because their input files are newer). For enforcing a touch,
    combine this with --force, --forceall, or --forcerun. Note however that you loose
    the provenance information when the files have been created in realitiy. Hence,
    this should be used only as a last resort. (default: False)'
  synonyms:
  - --touch
  - -t
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Go on with independent jobs if a job fails. (default: False)'
  synonyms:
  - --keep-going
  - -k
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Force the execution of the selected target or the first rule regardless
    of already created output. (default: False)'
  synonyms:
  - --force
  - -f
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Force the execution of the selected (or the first) rule and all rules
    it is dependent on regardless of already created output. (default: False)'
  synonyms:
  - --forceall
  - -F
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: '[TARGET [TARGET ...]], -R [TARGET [TARGET ...]] Force the re-execution
    or creation of the given rules or files. Use this option if you changed a rule
    and want to have all its output in your workflow updated. (default: None)'
  synonyms:
  - --forcerun
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Tell the scheduler to assign creation of given targets (and all their
    dependencies) highest priority. (EXPERIMENTAL) (default: None)'
  synonyms:
  - --prioritize
  - -P
  args: !RepeatFlagArg
    name: TARGET
  optional: true
- !Flag
  description: '=BATCH/BATCHES Only create the given BATCH of the input files of the
    given RULE. This can be used to iteratively run parts of very large workflows.
    Only the execution plan of the relevant part of the workflow has to be calculated,
    thereby speeding up DAG computation. It is recommended to provide the most suitable
    rule for batching when documenting a workflow. It should be some aggregating rule
    that would be executed only once, and has a large number of input files. For example,
    it can be a rule that aggregates over samples. (default: None)'
  synonyms:
  - --batch
  args: !SimpleFlagArg
    name: RULE
  optional: true
- !Flag
  description: 'Runs the pipeline until it reaches the specified rules or files. Only
    runs jobs that are dependencies of the specified rule or files, does not run sibling
    DAGs. (default: None)'
  synonyms:
  - --until
  - -U
  args: !RepeatFlagArg
    name: TARGET
  optional: true
- !Flag
  description: 'Prevent the execution or creation of the given rules or files as well
    as any rules or files that are downstream of these targets in the DAG. Also runs
    jobs in sibling DAGs that are independent of the rules or files specified here.
    (default: None)'
  synonyms:
  - --omit-from
  - -O
  args: !RepeatFlagArg
    name: TARGET
  optional: true
- !Flag
  description: 'Re-run all jobs the output of which is recognized as incomplete. (default:
    False)'
  synonyms:
  - --rerun-incomplete
  - --ri
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Specify a directory in which the 'shadow' directory is created. If\
    \ not supplied, the value is set to the '.snakemake' directory relative to the\
    \ working directory. (default: None)"
  synonyms:
  - --shadow-prefix
  args: !SimpleFlagArg
    name: DIR
  optional: true
- !Flag
  description: '[FILE]       Create an HTML report with results and statistics. This
    can be either a .html file or a .zip file. In the former case, all results are
    embedded into the .html (this only works for small data). In the latter case,
    results are stored along with a file report.html in the zip archive. If no filename
    is given, an embedded report.html is the default. (default: None)'
  synonyms:
  - --report
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Custom stylesheet to use for report. In particular, this can be used
    for branding the report with e.g. a custom logo, see docs. (default: None)'
  synonyms:
  - --report-stylesheet
  args: !SimpleFlagArg
    name: CSSFILE
  optional: true
- !Flag
  description: '[{text,json}]  Perform linting on the given workflow. This will print
    snakemake specific suggestions to improve code quality (work in progress, more
    lints to be added in the future). If no argument is provided, plain text output
    is used. (default: None)'
  synonyms:
  - --lint
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Compile workflow to CWL and store it in given FILE. (default: None)'
  synonyms:
  - --export-cwl
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: 'Show available rules in given Snakefile. (default: False)'
  synonyms:
  - --list
  - -l
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Show available target rules in given Snakefile. (default: False)'
  synonyms:
  - --list-target-rules
  - --lt
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not execute anything and print the directed acyclic graph of jobs
    in the dot language. Recommended use on Unix systems: snakemake --dag | dot |
    displayNote print statements in your Snakefile may interfere with visualization.
    (default: False)'
  synonyms:
  - --dag
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not execute anything and print the dependency graph of rules in
    the dot language. This will be less crowded than above DAG of jobs, but also show
    less information. Note that each rule is displayed once, hence the displayed graph
    will be cyclic if a rule appears in several steps of the workflow. Use this if
    above option leads to a DAG that is too large. Recommended use on Unix systems:
    snakemake --rulegraph | dot | displayNote print statements in your Snakefile may
    interfere with visualization. (default: False)'
  synonyms:
  - --rulegraph
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not execute anything and print the dependency graph of rules with
    their input and output files in the dot language. This is an intermediate solution
    between above DAG of jobs and the rule graph. Note that each rule is displayed
    once, hence the displayed graph will be cyclic if a rule appears in several steps
    of the workflow. Use this if above option leads to a DAG that is too large. Recommended
    use on Unix systems: snakemake --filegraph | dot | displayNote print statements
    in your Snakefile may interfere with visualization. (default: False)'
  synonyms:
  - --filegraph
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print the DAG in D3.js compatible JSON format. (default: False)'
  synonyms:
  - --d3dag
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print a summary of all files created by the workflow. The has the
    following columns: filename, modification time, rule version, status, plan. Thereby
    rule version contains the versionthe file was created with (see the version keyword
    of rules), and status denotes whether the file is missing, its input files are
    newer or if version or implementation of the rule changed since file creation.
    Finally the last column denotes whether the file will be updated or created during
    the next workflow execution. (default: False)'
  synonyms:
  - --summary
  - -S
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print a summary of all files created by the workflow. The has the
    following columns: filename, modification time, rule version, input file(s), shell
    command, status, plan. Thereby rule version contains the version the file was
    created with (see the version keyword of rules), and status denotes whether the
    file is missing, its input files are newer or if version or implementation of
    the rule changed since file creation. The input file and shell command columns
    are self explanatory. Finally the last column denotes whether the file will be
    updated or created during the next workflow execution. (default: False)'
  synonyms:
  - --detailed-summary
  - -D
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Archive the workflow into the given tar archive FILE. The archive
    will be created such that the workflow can be re-executed on a vanilla system.
    The function needs conda and git to be installed. It will archive every file that
    is under git version control. Note that it is best practice to have the Snakefile,
    config files, and scripts under version control. Hence, they will be included
    in the archive. Further, it will add input files that are not generated by by
    the workflow itself and conda environments. Note that symlinks are dereferenced.
    Supported formats are .tar, .tar.gz, .tar.bz2 and .tar.xz. (default: None)'
  synonyms:
  - --archive
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: 'Cleanup the metadata of given files. That means that snakemake removes
    any tracked version info, and any marks that files are incomplete. (default: None)'
  synonyms:
  - --cleanup-metadata
  - --cm
  args: !RepeatFlagArg
    name: FILE
  optional: true
- !Flag
  description: 'Cleanup old shadow directories which have not been deleted due to
    failures or power loss. (default: False)'
  synonyms:
  - --cleanup-shadow
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Don't delete wrapper scripts used for execution (default: False)"
  synonyms:
  - --skip-script-cleanup
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Remove a lock on the working directory. (default: False)'
  synonyms:
  - --unlock
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'List all output files that have been created with a different version
    (as determined by the version keyword). (default: False)'
  synonyms:
  - --list-version-changes
  - --lv
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'List all output files for which the rule body (run or shell) have
    changed in the Snakefile. (default: False)'
  synonyms:
  - --list-code-changes
  - --lc
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'List all output files for which the defined input files have changed
    in the Snakefile (e.g. new input files were added in the rule definition or files
    were renamed). For listing input file modification in the filesystem, use --summary.
    (default: False)'
  synonyms:
  - --list-input-changes
  - --li
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'List all output files for which the defined params have changed in
    the Snakefile. (default: False)'
  synonyms:
  - --list-params-changes
  - --lp
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'List all files in the working directory that are not used in the workflow.
    This can be used e.g. for identifying leftover files. Hidden files and directories
    are ignored. (default: False)'
  synonyms:
  - --list-untracked
  - --lu
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Remove all files generated by the workflow. Use together with --dry-run
    to list files without actually deleting anything. Note that this will not recurse
    into subworkflows. Write-protected files are not removed. Nevertheless, use with
    care! (default: False)'
  synonyms:
  - --delete-all-output
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Remove all temporary files generated by the workflow. Use together
    with --dry-run to list files without actually deleting anything. Note that this
    will not recurse into subworkflows. (default: False)'
  synonyms:
  - --delete-temp-output
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Output code to register bash completion for snakemake. Put the following
    in your .bashrc (including the accents): `snakemake --bash-completion` or issue
    it in an open terminal session. (default: False)'
  synonyms:
  - --bash-completion
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not remove incomplete output files by failed jobs. (default: False)'
  synonyms:
  - --keep-incomplete
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print the reason for each executed rule. (default: False)'
  synonyms:
  - --reason
  - -r
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: '[PORT]          Serve an HTML based user interface to the given network
    and port e.g. 168.129.10.15:8000. By default Snakemake is only available in the
    local network (default port: 8000). To make Snakemake listen to all ip addresses
    add the special host address 0.0.0.0 to the url (0.0.0.0:8000). This is important
    if Snakemake is used in a virtualised environment like Docker. If possible, a
    browser window is opened. (default: None)'
  synonyms:
  - --gui
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print out the shell commands that will be executed. (default: False)'
  synonyms:
  - --printshellcmds
  - -p
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print candidate and selected jobs (including their wildcards) while
    inferring DAG. This can help to debug unexpected DAG topology or errors. (default:
    False)'
  synonyms:
  - --debug-dag
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Write stats about Snakefile execution in JSON format to the given
    file. (default: None)'
  synonyms:
  - --stats
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: 'Do not use a colored output. (default: False)'
  synonyms:
  - --nocolor
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not output any progress or rule information. (default: False)'
  synonyms:
  - --quiet
  - -q
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print the python representation of the workflow. (default: False)'
  synonyms:
  - --print-compilation
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Print debugging output. (default: False)'
  synonyms:
  - --verbose
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Force threads rather than processes. Helpful if shared memory (/dev/shm)
    is full or unavailable. (default: False)'
  synonyms:
  - --force-use-threads
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Don't check for ambiguous rules and simply use the first if several\
    \ can produce the same file. This allows the user to prioritize rules by their\
    \ order in the snakefile. (default: False)"
  synonyms:
  - --allow-ambiguity
  - -a
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not lock the working directory (default: False)'
  synonyms:
  - --nolock
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not check for incomplete output files. (default: False)'
  synonyms:
  - --ignore-incomplete
  - --ii
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Wait given seconds if an output file of a job is not present after
    the job finished. This helps if your filesystem suffers from latency (default
    5). (default: 5)'
  synonyms:
  - --latency-wait
  - --output-wait
  - -w
  args: !SimpleFlagArg
    name: SECONDS
  optional: true
- !Flag
  description: '[FILE [FILE ...]] Wait --latency-wait seconds for these files to be
    present before executing the workflow. This option is used internally to handle
    filesystem latency in cluster environments. (default: None)'
  synonyms:
  - --wait-for-files
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Ignore temp() declarations. This is useful when running only a part
    of the workflow, since temp() would lead to deletion of probably needed files
    by other parts of the workflow. (default: False)'
  synonyms:
  - --notemp
  - --nt
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Keep local copies of remote input files. (default: False)'
  synonyms:
  - --keep-remote
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Do not adjust the paths of given target files relative to the working
    directory. (default: False)'
  synonyms:
  - --keep-target-files
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Only consider given rules. If omitted, all rules in Snakefile are
    used. Note that this is intended primarily for internal use and may lead to unexpected
    results otherwise. (default: None)'
  synonyms:
  - --allowed-rules
  args: !RepeatFlagArg
    name: ALLOWED_RULES
  optional: true
- !Flag
  description: 'Maximal number of cluster/drmaa jobs per second, default is 10, fractions
    allowed. (default: 10)'
  synonyms:
  - --max-jobs-per-second
  args: !SimpleFlagArg
    name: MAX_JOBS_PER_SECOND
  optional: true
- !Flag
  description: 'Maximal number of job status checks per second, default is 10, fractions
    allowed. (default: 10)'
  synonyms:
  - --max-status-checks-per-second
  args: !SimpleFlagArg
    name: MAX_STATUS_CHECKS_PER_SECOND
  optional: true
- !Flag
  description: 'Number of times to restart failing jobs (defaults to 0). (default:
    0)'
  synonyms:
  - --restart-times
  args: !SimpleFlagArg
    name: RESTART_TIMES
  optional: true
- !Flag
  description: 'Internal use only: define the initial value of the attempt parameter
    (default: 1). (default: 1)'
  synonyms:
  - --attempt
  args: !SimpleFlagArg
    name: ATTEMPT
  optional: true
- !Flag
  description: "Prefix for URL created from wrapper directive (default: https://github.com/snakemake/snakemake-\
    \ wrappers/raw/). Set this to a different URL to use your fork or a local clone\
    \ of the repository, e.g., use a git URL like 'git+file://path/to/your/local/clone@'.\
    \ (default: https://github.com/snakemake/snakemake-wrappers/raw/)"
  synonyms:
  - --wrapper-prefix
  args: !SimpleFlagArg
    name: WRAPPER_PREFIX
  optional: true
- !Flag
  description: "Specify default remote provider to be used for all input and output\
    \ files that don't yet specify one. (default: None)"
  synonyms:
  - --default-remote-provider
  args: !ChoiceFlagArg
    choices:
    - S3
    - GS
    - FTP
    - SFTP
    - S3Mocked
    - gfal
    - gridftp
    - iRODS
  optional: true
- !Flag
  description: 'Specify prefix for default remote provider. E.g. a bucket name. (default:
    )'
  synonyms:
  - --default-remote-prefix
  args: !SimpleFlagArg
    name: DEFAULT_REMOTE_PREFIX
  optional: true
- !Flag
  description: "Do not assume that jobs share a common file system. When this flag\
    \ is activated, Snakemake will assume that the filesystem on a cluster node is\
    \ not shared with other nodes. For example, this will lead to downloading remote\
    \ files on each cluster node separately. Further, it won't take special measures\
    \ to deal with filesystem latency issues. This option will in most cases only\
    \ make sense in combination with --default-remote-provider. Further, when using\
    \ --cluster you will have to also provide --cluster- status. Only activate this\
    \ if you know what you are doing. (default: False)"
  synonyms:
  - --no-shared-fs
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Set the greediness of scheduling. This value between 0 and 1 determines
    how careful jobs are selected for execution. The default value (1.0) provides
    the best speed and still acceptable scheduling quality. (default: None)'
  synonyms:
  - --greediness
  args: !SimpleFlagArg
    name: GREEDINESS
  optional: true
- !Flag
  description: 'Do not invoke onstart, onsuccess or onerror hooks after execution.
    (default: False)'
  synonyms:
  - --no-hooks
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Provide a shell command that shall be executed instead of those given
    in the workflow. This is for debugging purposes only. (default: None)'
  synonyms:
  - --overwrite-shellcmd
  args: !SimpleFlagArg
    name: OVERWRITE_SHELLCMD
  optional: true
- !Flag
  description: 'Allow to debug rules with e.g. PDB. This flag allows to set breakpoints
    in run blocks. (default: False)'
  synonyms:
  - --debug
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Profile Snakemake and write the output to FILE. This requires yappi
    to be installed. (default: None)'
  synonyms:
  - --runtime-profile
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: '{0,1,2}        Set execution mode of Snakemake (internal use only).
    (default: 0)'
  synonyms:
  - --mode
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Automatically display logs of failed jobs. (default: False)'
  synonyms:
  - --show-failed-logs
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Provide a custom script containing a function 'def log_handler(msg):'.\
    \ Snakemake will call this function for every logging output (given as a dictionary\
    \ msg)allowing to e.g. send notifications in the form of e.g. slack messages or\
    \ emails. (default: None)"
  synonyms:
  - --log-handler-script
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: 'Set a specific messaging service for logging output.Snakemake will
    notify the service on errors and completed execution.Currently only slack is supported.
    (default: None)'
  synonyms:
  - --log-service
  args: !ChoiceFlagArg
    choices:
    - none
    - slack
  optional: true
- !Flag
  description: "Execute snakemake rules with the given submit command, e.g. qsub.\
    \ Snakemake compiles jobs into scripts that are submitted to the cluster with\
    \ the given command, once all input files for a particular job are present. The\
    \ submit command can be decorated to make it aware of certain job properties (name,\
    \ rulename, input, output, params, wildcards, log, threads and dependencies (see\
    \ the argument below)), e.g.: $ snakemake --cluster 'qsub -pe threaded {threads}'.\
    \ (default: None)"
  synonyms:
  - --cluster
  - -c
  args: !SimpleFlagArg
    name: CMD
  optional: true
- !Flag
  description: "cluster submission command will block, returning the remote exitstatus\
    \ upon remote termination (for example, this should be usedif the cluster command\
    \ is 'qsub -sync y' (SGE) (default: None)"
  synonyms:
  - --cluster-sync
  args: !SimpleFlagArg
    name: CMD
  optional: true
- !Flag
  description: "[ARGS]        Execute snakemake on a cluster accessed via DRMAA, Snakemake\
    \ compiles jobs into scripts that are submitted to the cluster with the given\
    \ command, once all input files for a particular job are present. ARGS can be\
    \ used to specify options of the underlying cluster system, thereby using the\
    \ job properties name, rulename, input, output, params, wildcards, log, threads\
    \ and dependencies, e.g.: --drmaa ' -pe threaded {threads}'. Note that ARGS must\
    \ be given in quotes and with a leading whitespace. (default: None)"
  synonyms:
  - --drmaa
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "A JSON or YAML file that defines the wildcards used in 'cluster'for\
    \ specific rules, instead of having them specified in the Snakefile. For example,\
    \ for rule 'job' you may define: { 'job' : { 'time' : '24:00:00' } } to specify\
    \ the time for rule 'job'. You can specify more than one file. The configuration\
    \ files are merged with later values overriding earlier ones. This option is deprecated\
    \ in favor of using --profile, see docs. (default: [])"
  synonyms:
  - --cluster-config
  - -u
  args: !SimpleFlagArg
    name: FILE
  optional: true
- !Flag
  description: "Immediately submit all jobs to the cluster instead of waiting for\
    \ present input files. This will fail, unless you make the cluster aware of job\
    \ dependencies, e.g. via: $ snakemake --cluster 'sbatch --dependency {dependencies}.\
    \ Assuming that your submit script (here sbatch) outputs the generated job id\
    \ to the first stdout line, {dependencies} will be filled with space separated\
    \ job ids this job depends on. (default: False)"
  synonyms:
  - --immediate-submit
  - --is
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Provide a custom job script for submission to the cluster. The default\
    \ script resides as 'jobscript.sh' in the installation directory. (default: None)"
  synonyms:
  - --jobscript
  - --js
  args: !SimpleFlagArg
    name: SCRIPT
  optional: true
- !Flag
  description: 'Provide a custom name for the jobscript that is submitted to the cluster
    (see --cluster). NAME is "snakejob.{name}.{jobid}.sh" per default. The wildcard
    {jobid} has to be present in the name. (default: snakejob.{name}.{jobid}.sh)'
  synonyms:
  - --jobname
  - --jn
  args: !SimpleFlagArg
    name: NAME
  optional: true
- !Flag
  description: "Status command for cluster execution. This is only considered in combination\
    \ with the --cluster flag. If provided, Snakemake will use the status command\
    \ to determine if a job has finished successfully or failed. For this it is necessary\
    \ that the submit command provided to --cluster returns the cluster job id. Then,\
    \ the status command will be invoked with the job id. Snakemake expects it to\
    \ return 'success' if the job was successfull, 'failed' if the job failed and\
    \ 'running' if the job still runs. (default: None)"
  synonyms:
  - --cluster-status
  args: !SimpleFlagArg
    name: CLUSTER_STATUS
  optional: true
- !Flag
  description: "Specify a directory in which stdout and stderr files of DRMAA jobs\
    \ will be written. The value may be given as a relative path, in which case Snakemake\
    \ will use the current invocation directory as the origin. If given, this will\
    \ override any given '-o' and/or '-e' native specification. If not given, all\
    \ DRMAA stdout and stderr files are written to the current working directory.\
    \ (default: None)"
  synonyms:
  - --drmaa-log-dir
  args: !SimpleFlagArg
    name: DIR
  optional: true
- !Flag
  description: "[NAMESPACE] Execute workflow in a kubernetes cluster (in the cloud).\
    \ NAMESPACE is the namespace you want to use for your job (if nothing specified:\
    \ 'default'). Usually, this requires --default-remote-provider and --default-\
    \ remote-prefix to be set to a S3 or GS bucket where your . data shall be stored.\
    \ It is further advisable to activate conda integration via --use-conda. (default:\
    \ None)"
  synonyms:
  - --kubernetes
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Docker image to use, e.g., when submitting jobs to kubernetes. By\
    \ default, this is 'https://hub.docker.com/r/snakemake/snakemake', tagged with\
    \ the same version as the currently running Snakemake instance. Note that overwriting\
    \ this value is up to your responsibility. Any used image has to contain a working\
    \ snakemake installation that is compatible with (or ideally the same as) the\
    \ currently running version. (default: None)"
  synonyms:
  - --container-image
  args: !SimpleFlagArg
    name: IMAGE
  optional: true
- !Flag
  description: "Execute workflow on AWS cloud using Tibanna. This requires --default-remote-prefix\
    \ to be set to S3 bucket name and prefix (e.g. 'bucketname/subdirectory') where\
    \ input is already stored and output will be sent to. Using --tibanna implies\
    \ --default-resources is set as default. Optionally, use --precommand to specify\
    \ any preparation command to run before snakemake command on the cloud (inside\
    \ snakemake container on Tibanna VM). Also, --use-conda, --use-singularity, --config,\
    \ --configfile are supported and will be carried over. (default: False)"
  synonyms:
  - --tibanna
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Name of Tibanna Unicorn step function (e.g. tibanna_unicorn_monty).This
    works as serverless scheduler/resource allocator and must be deployed first using
    tibanna cli. (e.g. tibanna deploy_unicorn --usergroup=monty --buckets=bucketname)
    (default: None)'
  synonyms:
  - --tibanna-sfn
  args: !SimpleFlagArg
    name: TIBANNA_SFN
  optional: true
- !Flag
  description: 'Any command to execute before snakemake command on AWS cloud such
    as wget, git clone, unzip, etc. This is used with --tibanna.Do not include input/output
    download/upload commands - file transfer between S3 bucket and the run environment
    (container) is automatically handled by Tibanna. (default: None)'
  synonyms:
  - --precommand
  args: !SimpleFlagArg
    name: PRECOMMAND
  optional: true
- !Flag
  description: 'Additional tibanan config e.g. --tibanna-config spot_instance=true
    subnet=<subnet_id> security group=<security_group_id> (default: None)'
  synonyms:
  - --tibanna-config
  args: !RepeatFlagArg
    name: TIBANNA_CONFIG
  optional: true
- !Flag
  description: 'If defined in the rule, run job in a conda environment. If this flag
    is not set, the conda directive is ignored. (default: False)'
  synonyms:
  - --use-conda
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'List all conda environments and their location on disk. (default:
    False)'
  synonyms:
  - --list-conda-envs
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Specify a directory in which the 'conda' and 'conda- archive' directories\
    \ are created. These are used to store conda environments and their archives,\
    \ respectively. If not supplied, the value is set to the '.snakemake' directory\
    \ relative to the invocation directory. If supplied, the `--use-conda` flag must\
    \ also be set. The value may be given as a relative path, which will be extrapolated\
    \ to the invocation directory, or as an absolute path. (default: None)"
  synonyms:
  - --conda-prefix
  args: !SimpleFlagArg
    name: DIR
  optional: true
- !Flag
  description: 'Cleanup unused conda environments. (default: False)'
  synonyms:
  - --conda-cleanup-envs
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "[{tarballs,cache}] Cleanup conda packages after creating environments.\
    \ In case of 'tarballs' mode, will clean up all downloaded package tarballs. In\
    \ case of 'cache' mode, will additionally clean up unused package caches. If mode\
    \ is omitted, will default to only cleaning up the tarballs. (default: None)"
  synonyms:
  - --conda-cleanup-pkgs
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'If specified, only creates the job-specific conda environments then
    exits. The `--use-conda` flag must also be set. (default: False)'
  synonyms:
  - --conda-create-envs-only
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'If defined in the rule, run job within a singularity container. If
    this flag is not set, the singularity directive is ignored. (default: False)'
  synonyms:
  - --use-singularity
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Specify a directory in which singularity images will be stored.If\
    \ not supplied, the value is set to the '.snakemake' directory relative to the\
    \ invocation directory. If supplied, the `--use-singularity` flag must also be\
    \ set. The value may be given as a relative path, which will be extrapolated to\
    \ the invocation directory, or as an absolute path. (default: None)"
  synonyms:
  - --singularity-prefix
  args: !SimpleFlagArg
    name: DIR
  optional: true
- !Flag
  description: 'Pass additional args to singularity. (default: )'
  synonyms:
  - --singularity-args
  args: !SimpleFlagArg
    name: ARGS
  optional: true
- !Flag
  description: "If defined in the rule, run job within the given environment modules,\
    \ loaded in the given order. This can be combined with --use-conda and --use-\
    \ singularity, which will then be only used as a fallback for rules which don't\
    \ define environment modules. (default: False)"
  synonyms:
  - --use-envmodules
  args: !EmptyFlagArg {}
  optional: true
command:
- snakemake
subcommands: []
help_flag: !Flag
  description: show this help message and exit
  synonyms:
  - -h
  - --help
  args: !EmptyFlagArg {}
  optional: true
usage_flag:
version_flag: !Flag
  description: show program's version number and exit
  synonyms:
  - --version
  - -v
  args: !EmptyFlagArg {}
  optional: true
