!Command
positional:
- !Positional
  description: ''
  position: 0
  name: Welcome
  optional: false
- !Positional
  description: ''
  position: 1
  name: to
  optional: false
- !Positional
  description: ''
  position: 2
  name: SEQUANA
  optional: false
named:
- !Flag
  description: set verbosity off
  synonyms:
  - --quiet
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: 'Search for all source files with this extension. Valid extensions
    are: fastq, fastq.gz, fastq.bz2, fastq.dscr, fq, fq.gz, fq.bz2 and fq.dsrc'
  synonyms:
  - --source
  args: !SimpleFlagArg
    name: SOURCE
  optional: true
- !Flag
  description: Convert the source files to a new target format. Same extensions as
    above.
  synonyms:
  - --target
  args: !SimpleFlagArg
    name: TARGET
  optional: true
- !Flag
  description: recursive search
  synonyms:
  - --recursive
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Do not execute anything
  synonyms:
  - --dryrun
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Maximum number of threads to use per task (4).
  synonyms:
  - --threads
  args: !SimpleFlagArg
    name: THREADS
  optional: true
- !Flag
  description: Maximum number of cores to use at the same time (4).
  synonyms:
  - --jobs
  args: !SimpleFlagArg
    name: JOBS
  optional: true
- !Flag
  description: The number of jobs is limited to 20 to limit IO. If you want to bypass
    this limitation, use this option.
  synonyms:
  - --bypass-job-limit
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: If you stopped the application, the underlying snakemake process are
    interrupted and directories were snakemake was launch will be locked. If so please
    use this option using the --source and --target as when you got the error message
  synonyms:
  - --unlock
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Any valid list of options accepted by snakemake except -s and -j (for
    -j, use our --jobs argument). Note that by default --keep-going is used ; If you
    set this argument yourself, you have to add --keep-going as well otherwise it
    stops at the first error encountered
  synonyms:
  - --snakemake-options
  args: !SimpleFlagArg
    name: SNAKEMAKE
  optional: true
- !Flag
  description: "a valid snakemake option dedicated to a cluster.   e.g on LSF cluster\
    \ use: --cluster 'qsub -cwd -q<QUEUE> ' On a SLURM system use for example: --cluster\
    \ 'sbatch --qos normal'"
  synonyms:
  - --snakemake-cluster
  args: !SimpleFlagArg
    name: CLUSTER
  optional: true
command:
- sequana_compressor
parent:
subcommands: []
help_flag: !Flag
  description: show this help message and exit
  synonyms:
  - -h
  - --help
  args: !EmptyFlagArg {}
  optional: true
usage_flag:
version_flag: !Flag
  description: print version
  synonyms:
  - --version
  args: !EmptyFlagArg {}
  optional: true
help_text: "usage: Welcome to SEQUANA - Fastq compression standalone\n\n    This standalone\
  \ fetches recursively all files in a given format (--source)\n    and transform\
  \ them into another format (--target)\n\n    Compression supported ar gz, bz2 and\
  \ dsrc. Note that one must add\n    \"fastq\" in the extension as shown in the following\
  \ examples:\n\n        sequana_compressor --source fastq.gz   --target fastq.bz2\n\
  \        sequana_compressor --source fastq      --target fastq.bz2\n        sequana_compressor\
  \ --source fastq.gz   --target fastq\n        sequana_compressor --source fastq.bz2\
  \  --target fastq\n\n    If your job(s) were interrupted (ctrl+C), your directories\
  \ will most\n    probably be locked. Use the --unlock option in such situations.\n\
  \n        sequana_compressor --source ... --target ... --unlock\n\n    --source\
  \ and --target must be provided but no analysis will be performed\n    at that stage.\n\
  \n    Then, type your command again.\n\n    Note for IP users: if compressor is\
  \ launch on Institut Pasteur Cluster\n        (tars), the --snakemake-options must\
  \ be used to provide the slurm\n        sbatch command (see help below for example).\n\
  \n    Note for CLUSTER usage: consider an example where we request 4 jobs (default)\
  \ \n    and 4 threads (default). Each job is laucnhed independently. Yet, with a\n\
  \    scheduler like SLURM, it is highly possible that the requested resources \n\
  \    will occur on the same node if that node has 4 cpus starting 16 threads in\n\
  \    total irrespective of the current occupation by other users. \n    For SLURM\
  \ scheduler, once can provide an option to look for nodes that have \n    at least\
  \ 4 cpus (threads) available. The option is -c. So, please use\n\n        sbatch\
  \ -c 4\n\n    in such case.\n    \n\nAUTHORS: Thomas Cokelaer\nDocumentation: http://sequana.readthedocs.io\n\
  Issues: http://github.com/sequana/sequana\n\nDESCRIPTION:\n\noptional arguments:\n\
  \  -h, --help            show this help message and exit\n  --version          \
  \   print version\n  --quiet               set verbosity off\n\nINPUT/OUTPUT:\n\
  \  --source SOURCE       Search for all source files with this extension. Valid\n\
  \                        extensions are: fastq, fastq.gz, fastq.bz2,\n         \
  \               fastq.dscr, fq, fq.gz, fq.bz2 and fq.dsrc\n  --target TARGET   \
  \    Convert the source files to a new target format. Same\n                   \
  \     extensions as above.\n  --recursive           recursive search\n  --dryrun\
  \              Do not execute anything\n\nJOBS RELATED (threads/cores):\n  --threads\
  \ THREADS     Maximum number of threads to use per task (4).\n  --jobs JOBS    \
  \       Maximum number of cores to use at the same time (4).\n  --bypass-job-limit\
  \    The number of jobs is limited to 20 to limit IO. If\n                     \
  \   you want to bypass this limitation, use this option.\n\nSNAKEMAKE RELATED:\n\
  \  --unlock              If you stopped the application, the underlying\n      \
  \                  snakemake process are interrupted and directories were\n    \
  \                    snakemake was launch will be locked. If so please use\n   \
  \                     this option using the --source and --target as when\n    \
  \                    you got the error message\n  --snakemake-options SNAKEMAKE\n\
  \                        Any valid list of options accepted by snakemake except\n\
  \                        -s and -j (for -j, use our --jobs argument). Note that\n\
  \                        by default --keep-going is used ; If you set this\n   \
  \                     argument yourself, you have to add --keep-going as\n     \
  \                   well otherwise it stops at the first error encountered\n\nCLUSTER:\n\
  \  --snakemake-cluster CLUSTER\n                        a valid snakemake option\
  \ dedicated to a cluster.  \n                        e.g on LSF cluster use:\n \
  \                           --cluster 'qsub -cwd -q<QUEUE> '\n                 \
  \       \n                        On a SLURM system use for example:\n         \
  \               \n                            --cluster 'sbatch --qos normal'\n\
  \                        \n"
generated_using:
- --help
