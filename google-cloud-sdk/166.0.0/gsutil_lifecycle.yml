&id004 !Command
positional: []
named: []
command:
- gsutil
- lifecycle
parent: &id001 !Command
  positional: []
  named:
  - !Flag
    description: ''
    synonyms:
    - -D
    args: !EmptyFlagArg {}
    optional: true
  - !Flag
    description: ''
    synonyms:
    - -DD
    args: !EmptyFlagArg {}
    optional: true
  - !Flag
    description: ''
    synonyms:
    - -h
    args: !SimpleFlagArg
      name: header
    optional: true
  command:
  - gsutil
  parent:
  subcommands:
  - !Command
    positional: []
    named:
    - !Flag
      description: Ends each output line with a 0 byte rather than a newline. This
        can be useful to make the output more easily machine-readable.
      synonyms:
      - '-0'
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Includes non-current object versions / generations in the listing
        (only useful with a versioning-enabled bucket). Also prints generation and
        metageneration for each listed object.
      synonyms:
      - -a
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Includes a grand total at the end of the output.
      synonyms:
      - -c
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'A pattern to exclude from reporting. Example: -e "*.o" would exclude
        any object that ends in ".o". Can be specified multiple times.'
      synonyms:
      - -e
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Displays only the grand total for each argument.
      synonyms:
      - -s
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Similar to -e, but excludes patterns from the given file. The patterns
        to exclude should be one per line.
      synonyms:
      - -X
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - du
    parent: *id001
    subcommands: []
    help_flag: !Flag
      description: Prints object sizes in human-readable format (e.g., 1 KiB, 234
        MiB, 2GiB, etc.)
      synonyms:
      - -h
      args: !EmptyFlagArg {}
      optional: true
    usage_flag:
    version_flag:
    help_text: "NAME\n  du - Display object size usage\n\n\nSYNOPSIS\n\n  gsutil du\
      \ url...\n\n\n\nDESCRIPTION\n  The du command displays the amount of space (in\
      \ bytes) being used by the\n  objects in the file or object hierarchy under\
      \ a given URL. The syntax emulates\n  the Linux du command (which stands for\
      \ disk usage). For example, the command:\n\n  gsutil du -s gs://your-bucket/dir\n\
      \n  will report the total space used by all objects under gs://your-bucket/dir\
      \ and\n  any sub-directories.\n\n\nOPTIONS\n  -0          Ends each output line\
      \ with a 0 byte rather than a newline. This\n              can be useful to\
      \ make the output more easily machine-readable.\n\n  -a          Includes non-current\
      \ object versions / generations in the listing\n              (only useful with\
      \ a versioning-enabled bucket). Also prints\n              generation and metageneration\
      \ for each listed object.\n\n  -c          Includes a grand total at the end\
      \ of the output.\n\n  -e          A pattern to exclude from reporting. Example:\
      \ -e \"*.o\" would\n              exclude any object that ends in \".o\". Can\
      \ be specified multiple\n              times.\n\n  -h          Prints object\
      \ sizes in human-readable format (e.g., 1 KiB,\n              234 MiB, 2GiB,\
      \ etc.)\n\n  -s          Displays only the grand total for each argument.\n\n\
      \  -X          Similar to -e, but excludes patterns from the given file. The\n\
      \              patterns to exclude should be one per line.\n\n\nEXAMPLES\n \
      \ To list the size of all objects in a bucket:\n\n    gsutil du gs://bucketname\n\
      \n  To list the size of all objects underneath a prefix:\n\n    gsutil du gs://bucketname/prefix/*\n\
      \n  To print the total number of bytes in a bucket, in human-readable form:\n\
      \n    gsutil du -ch gs://bucketname\n\n  To see a summary of the total bytes\
      \ in the two given buckets:\n\n    gsutil du -s gs://bucket1 gs://bucket2\n\n\
      \  To list the size of all objects in a versioned bucket, including objects\
      \ that\n  are not the latest:\n\n    gsutil du -a gs://bucketname\n\n  To list\
      \ all objects in a bucket, except objects that end in \".bak\",\n  with each\
      \ object printed ending in a null byte:\n\n    gsutil du -e \"*.bak\" -0 gs://bucketname\n\
      \n  To get a total of all buckets in a project with a grand total for an entire\n\
      \  project:\n\n      gsutil -o GSUtil:default_project_id=project-name du -shc\n"
    generated_using: &id003
    - --help
  - &id002 !Command
    positional: []
    named:
    - !Flag
      description: ''
      synonyms:
      - -c
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -m
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - hash
    parent: *id001
    subcommands:
    - !Command
      positional: []
      named:
      - !Flag
        description: Calculate a CRC32c hash for the file.
        synonyms:
        - -c
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: Calculate a MD5 hash for the file.
        synonyms:
        - -m
        args: !EmptyFlagArg {}
        optional: true
      command:
      - gsutil
      - hash
      - filename...
      parent: *id002
      subcommands: []
      help_flag: !Flag
        description: Output hashes in hex format. By default, gsutil uses base64.
        synonyms:
        - -h
        args: !EmptyFlagArg {}
        optional: true
      usage_flag:
      version_flag:
      help_text: "NAME\n  hash - Calculate file hashes\n\n\nSYNOPSIS\n\n  gsutil hash\
        \ [-c] [-h] [-m] filename...\n\n\n\nDESCRIPTION\n  The hash command calculates\
        \ hashes on a local file that can be used to compare\n  with gsutil ls -L\
        \ output. If a specific hash option is not provided, this\n  command calculates\
        \ all gsutil-supported hashes for the file.\n\n  Note that gsutil automatically\
        \ performs hash validation when uploading or\n  downloading files, so this\
        \ command is only needed if you want to write a\n  script that separately\
        \ checks the hash for some reason.\n\n  If you calculate a CRC32c hash for\
        \ the file without a precompiled crcmod\n  installation, hashing will be very\
        \ slow. See \"gsutil help crcmod\" for details.\n\nOPTIONS\n  -c         \
        \ Calculate a CRC32c hash for the file.\n\n  -h          Output hashes in\
        \ hex format. By default, gsutil uses base64.\n\n  -m          Calculate a\
        \ MD5 hash for the file.\n"
      generated_using: *id003
    help_flag: !Flag
      description: ''
      synonyms:
      - -h
      args: !EmptyFlagArg {}
      optional: true
    usage_flag:
    version_flag:
    help_text: "CommandException: The hash command requires at least 1 argument. Usage:\n\
      \n  gsutil hash [-c] [-h] [-m] filename...\n\nFor additional help run:\n  gsutil\
      \ help hash\n"
    generated_using: &id005
    - -h
  - !Command
    positional: []
    named:
    - !Flag
      description: Performs "iam set" recursively to all objects under the specified
        bucket.
      synonyms:
      - -R
      - -r
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Performs "iam set" request on all object versions.
      synonyms:
      - -a
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Performs the precondition check on each object with the specified
        etag before setting the policy.
      synonyms:
      - -e
      args: !SimpleFlagArg
        name: etag
      optional: true
    - !Flag
      description: Default gsutil error handling is fail-fast. This flag changes the
        request to fail-silent mode. This is implicitly set when invoking the gsutil
        -m option.
      synonyms:
      - -f
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - iam
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  iam - Get, set, or change bucket and/or object IAM permissions.\n\
      \n\nSYNOPSIS\n  gsutil iam set [-afRr] [-e <etag>] file url ...\n  gsutil iam\
      \ get url\n  gsutil iam ch [-fRr] binding ...\n\n  where each binding is of\
      \ the form:\n\n      [-d] (\"user\"|\"serviceAccount\"|\"domain\"|\"group\"\
      ):id:role[,...]\n      [-d] (\"allUsers\"|\"allAuthenticatedUsers\"):role[,...]\n\
      \      -d (\"user\"|\"serviceAccount\"|\"domain\"|\"group\"):id\n      -d (\"\
      allUsers\"|\"allAuthenticatedUsers\")\n\n\n\nDESCRIPTION\n  The iam command\
      \ has three sub-commands:\n\nGET\n  The \"iam get\" command gets the IAM policy\
      \ for a bucket or object, which you\n  can save and edit for use with the \"\
      iam set\" command.\n\n  For example:\n\n    gsutil iam get gs://example > bucket_iam.txt\n\
      \    gsutil iam get gs://example/important.txt > object_iam.txt\n\n  The IAM\
      \ policy returned by \"iam get\" includes the etag of the IAM policy and\n \
      \ will be used in the precondition check for \"iam set\", unless the etag is\n\
      \  overridden by setting the \"iam set\" -e option.\n\n\nSET\n  The \"iam set\"\
      \ command sets the IAM policy for one or more buckets and / or\n  objects. It\
      \ overwrites the current IAM policy that exists on a bucket (or\n  object) with\
      \ the policy specified in the input file. The \"iam set\" command\n  takes as\
      \ input a file with an IAM policy in the format of the output\n  generated by\
      \ \"iam get\".\n\n  The \"iam ch\" command can be used to edit an existing policy.\
      \ It works\n  correctly in the presence of concurrent updates. You may also\
      \ do this\n  manually by using the -e flag and overriding the etag returned\
      \ in \"iam get\".\n  Specifying -e with an empty string (i.e. \"gsutil iam set\
      \ -e '' ...\") will\n  instruct gsutil to skip the precondition check when setting\
      \ the IAM policy.\n\n  If you wish to set an IAM policy on a large number of\
      \ objects, you may want\n  to use the gsutil -m option for concurrent processing.\
      \ The following command\n  will apply iam.txt to all objects in the \"cats\"\
      \ bucket.\n\n    gsutil -m iam set -r iam.txt gs://cats\n\n  Note that only\
      \ object-level IAM applications are parallelized; you do not\n  gain any additional\
      \ performance when applying an IAM policy to a large\n  number of buckets with\
      \ the -m flag.\n\nSET OPTIONS\n  The \"set\" sub-command has the following options\n\
      \n    -R, -r      Performs \"iam set\" recursively to all objects under the\n\
      \                specified bucket.\n\n    -a          Performs \"iam set\" request\
      \ on all object versions.\n\n    -e <etag>   Performs the precondition check\
      \ on each object with the\n                specified etag before setting the\
      \ policy.\n\n    -f          Default gsutil error handling is fail-fast. This\
      \ flag\n                changes the request to fail-silent mode. This is implicitly\n\
      \                set when invoking the gsutil -m option.\n\n\nCH\n  The \"iam\
      \ ch\" command incrementally updates IAM policies. You may specify\n  multiple\
      \ access grants and removals in a single command invocation, which\n  will be\
      \ batched and applied as a whole to each url via an IAM patch.\n  The patch\
      \ will be constructed by applying each access grant or removal in the\n  order\
      \ in which they appear in the command line arguments. Each access change\n \
      \ specifies a member and the role that will be either granted or revoked.\n\n\
      \  The gsutil -m option may be set to handle object-level operations more\n\
      \  efficiently.\n\nCH EXAMPLES\n  Examples for the \"ch\" sub-command:\n\n \
      \ To grant a single role to a single member for some targets:\n\n    gsutil\
      \ iam ch user:john.doe@example.com:objectCreator gs://ex-bucket\n\n  To make\
      \ a bucket's objects publically readable:\n\n    gsutil iam ch allUsers:objectViewer\
      \ gs://ex-bucket\n\n  To grant multiple bindings to a bucket:\n\n    gsutil\
      \ iam ch user:john.doe@example.com:objectCreator \\\n                  domain:www.my-domain.org:objectViewer\
      \ gs://ex-bucket\n\n  To specify more than one role for a particular member:\n\
      \n    gsutil iam ch user:john.doe@example.com:objectCreator,objectViewer \\\n\
      \                  gs://ex-bucket\n\n  To apply a grant and simultaneously remove\
      \ a binding to a bucket:\n\n    gsutil iam ch -d group:readers@example.com:legacyBucketReader\
      \ \\\n                  group:viewers@example.com:objectViewer gs://ex-bucket\n\
      \n  To remove a user from all roles on a bucket:\n\n    gsutil iam ch -d user:john.doe@example.com\
      \ gs://ex-bucket\n\nCH OPTIONS\n  The \"ch\" sub-command has the following options\n\
      \n    -R, -r      Performs \"iam ch\" recursively to all objects under the\n\
      \                specified bucket.\n\n    -f          Default gsutil error handling\
      \ is fail-fast. This flag\n                changes the request to fail-silent\
      \ mode. This is implicitly\n                set when invoking the gsutil -m\
      \ option.\n"
    generated_using: *id003
  - !Command
    positional: []
    named:
    - !Flag
      description: Add or update a label with the specified key and value.
      synonyms:
      - -l
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Remove the label with the specified key.
      synonyms:
      - -d
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - label
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  label - Get, set, or change the label configuration of a bucket.\n\
      \n\nSYNOPSIS\n  gsutil label set label-json-file url...\n  gsutil label get\
      \ url\n  gsutil label ch <label_modifier>... url...\n\n  where each <label_modifier>\
      \ is one of the following forms:\n\n    -l <key>:<value>\n    -d <key>\n\n\n\
      \nDESCRIPTION\n  Gets, sets, or changes the label configuration (also called\
      \ the tagging\n  configuration by other storage providers) of one or more buckets.\
      \ An example\n  label JSON document looks like the following:\n\n    {\n   \
      \   \"your_label_key\": \"your_label_value\",\n      \"your_other_label_key\"\
      : \"your_other_label_value\"\n    }\n\n  The label command has three sub-commands:\n\
      \nGET\n  The \"label get\" command gets the\n  `labels <https://cloud.google.com/storage/docs/key-terms#bucket-labels>`_\n\
      \  applied to a bucket, which you can save and edit for use with the \"label\
      \ set\"\n  command.\n\nSET\n  The \"label set\" command allows you to set the\
      \ labels on one or more\n  buckets. You can retrieve a bucket's labels using\
      \ the \"label get\" command,\n  save the output to a file, edit the file, and\
      \ then use the \"label set\"\n  command to apply those labels to the specified\
      \ bucket(s). For\n  example:\n\n    gsutil label get gs://bucket > labels.json\n\
      \n  Make changes to labels.json, such as adding an additional label, then:\n\
      \n    gsutil label set labels.json gs://example-bucket\n\n  Note that you can\
      \ set these labels on multiple buckets at once:\n\n    gsutil label set labels.json\
      \ gs://bucket-foo gs://bucket-bar\n\nCH\n  The \"label ch\" command updates\
      \ a bucket's label configuration, applying the\n  label changes specified by\
      \ the -l and -d flags. You can specify multiple\n  label changes in a single\
      \ command run; all changes will be made atomically to\n  each bucket.\n\nCH\
      \ EXAMPLES\n  Examples for \"ch\" sub-command:\n\n  Add the label \"key-foo:value-bar\"\
      \ to the bucket \"example-bucket\":\n\n    gsutil label ch -l key-foo:value-bar\
      \ gs://example-bucket\n\n  Change the above label to have a new value:\n\n \
      \   gsutil label ch -l key-foo:other-value gs://example-bucket\n\n  Add a new\
      \ label and delete the old one from above:\n\n    gsutil label ch -l new-key:new-value\
      \ -d key-foo gs://example-bucket\n\nCH OPTIONS\n  The \"ch\" sub-command has\
      \ the following options\n\n    -l          Add or update a label with the specified\
      \ key and value.\n\n    -d          Remove the label with the specified key.\n"
    generated_using: *id003
  - *id004
  - !Command
    positional:
    - !Positional
      description: ''
      position: 0
      name: set
      optional: false
    - !Positional
      description: ''
      position: 1
      name: on
      optional: false
    - !Positional
      description: ''
      position: 2
      name: url...
      optional: false
    named:
    - !Flag
      description: ''
      synonyms:
      - -b
      args: !SimpleFlagArg
        name: logging_bucket
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -o
      args: !SimpleFlagArg
        name: log_object_prefix
      optional: true
    command:
    - gsutil
    - logging
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ logging set on -b logging_bucket [-o log_object_prefix] url...\n  gsutil logging\
      \ set off url...\n  gsutil logging get url\n\n\nFor additional help run:\n \
      \ gsutil help logging\n"
    generated_using: *id005
  - !Command
    positional: []
    named:
    - !Flag
      description: Prints long listing (owner, length).
      synonyms:
      - -l
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'Prints even more detail than -l.  Note: If you use this option
        with the (non-default) XML API it will generate an additional request per
        object being listed, which makes the -L option run much more slowly (and cost
        more) using the XML API than the default JSON API.'
      synonyms:
      - -L
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: List matching subdirectory names instead of contents, and do not
        recurse into matching subdirectories even if the -R option is specified.
      synonyms:
      - -d
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Prints info about the bucket when used with a bucket URL.
      synonyms:
      - -b
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specifies the project ID to use for listing buckets.
      synonyms:
      - -p
      args: !SimpleFlagArg
        name: proj_id
      optional: true
    - !Flag
      description: Requests a recursive listing, performing at least one listing operation
        per subdirectory. If you have a large number of subdirectories and do not
        require recursive-style output ordering, you may be able to instead use wildcards
        to perform a flat listing, e.g.  `gsutil ls gs://mybucket/**`, which will
        generally perform fewer listing operations.
      synonyms:
      - -R
      - -r
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Includes non-current object versions / generations in the listing
        (only useful with a versioning-enabled bucket). If combined with -l option
        also prints metageneration for each listed object.
      synonyms:
      - -a
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Include ETag in long listing (-l) output.
      synonyms:
      - -e
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - ls
    parent: *id001
    subcommands: []
    help_flag: !Flag
      description: When used with -l, prints object sizes in human readable format
        (e.g., 1 KiB, 234 MiB, 2 GiB, etc.)
      synonyms:
      - -h
      args: !EmptyFlagArg {}
      optional: true
    usage_flag:
    version_flag:
    help_text: "NAME\n  ls - List providers, buckets, or objects\n\n\nSYNOPSIS\n\n\
      \  gsutil ls [-a] [-b] [-d] [-l] [-L] [-r] [-p proj_id] url...\n\n\n\nLISTING\
      \ PROVIDERS, BUCKETS, SUBDIRECTORIES, AND OBJECTS\n  If you run gsutil ls without\
      \ URLs, it lists all of the Google Cloud Storage\n  buckets under your default\
      \ project ID:\n\n    gsutil ls\n\n  (For details about projects, see \"gsutil\
      \ help projects\" and also the -p\n  option in the OPTIONS section below.)\n\
      \n  If you specify one or more provider URLs, gsutil ls will list buckets at\n\
      \  each listed provider:\n\n    gsutil ls gs://\n\n  If you specify bucket URLs,\
      \ gsutil ls will list objects at the top level of\n  each bucket, along with\
      \ the names of each subdirectory. For example:\n\n    gsutil ls gs://bucket\n\
      \n  might produce output like:\n\n    gs://bucket/obj1.htm\n    gs://bucket/obj2.htm\n\
      \    gs://bucket/images1/\n    gs://bucket/images2/\n\n  The \"/\" at the end\
      \ of the last 2 URLs tells you they are subdirectories,\n  which you can list\
      \ using:\n\n    gsutil ls gs://bucket/images*\n\n  If you specify object URLs,\
      \ gsutil ls will list the specified objects. For\n  example:\n\n    gsutil ls\
      \ gs://bucket/*.txt\n\n  will list all files whose name matches the above wildcard\
      \ at the top level\n  of the bucket.\n\n  See \"gsutil help wildcards\" for\
      \ more details on working with wildcards.\n\n\nDIRECTORY BY DIRECTORY, FLAT,\
      \ and RECURSIVE LISTINGS\n  Listing a bucket or subdirectory (as illustrated\
      \ near the end of the previous\n  section) only shows the objects and names\
      \ of subdirectories it contains. You\n  can list all objects in a bucket by\
      \ using the -r option. For example:\n\n    gsutil ls -r gs://bucket\n\n  will\
      \ list the top-level objects and buckets, then the objects and\n  buckets under\
      \ gs://bucket/images1, then those under gs://bucket/images2, etc.\n\n  If you\
      \ want to see all objects in the bucket in one \"flat\" listing use the\n  recursive\
      \ (\"**\") wildcard, like:\n\n    gsutil ls -r gs://bucket/**\n\n  or, for a\
      \ flat listing of a subdirectory:\n\n    gsutil ls -r gs://bucket/dir/**\n\n\
      \  If you want to see only the subdirectory itself, use the -d option:\n\n \
      \   gsutil ls -d gs://bucket/dir\n\n\nLISTING OBJECT DETAILS\n  If you specify\
      \ the -l option, gsutil will output additional information\n  about each matching\
      \ provider, bucket, subdirectory, or object. For example:\n\n    gsutil ls -l\
      \ gs://bucket/*.txt\n\n  will print the object size, creation time stamp, and\
      \ name of each matching\n  object, along with the total count and sum of sizes\
      \ of all matching objects:\n\n       2276224  2012-03-02T19:25:17Z  gs://bucket/obj1\n\
      \       3914624  2012-03-02T19:30:27Z  gs://bucket/obj2\n    TOTAL: 2 objects,\
      \ 6190848 bytes (5.9 MiB)\n\n  Note that the total listed in parentheses above\
      \ is in mebibytes (or gibibytes,\n  tebibytes, etc.), which corresponds to the\
      \ unit of billing measurement for\n  Google Cloud Storage.\n\n  You can get\
      \ a listing of all the objects in the top-level bucket directory\n  (along with\
      \ the total count and sum of sizes) using a command like:\n\n    gsutil ls -l\
      \ gs://bucket\n\n  To print additional detail about objects and buckets use\
      \ the gsutil ls -L\n  option. For example:\n\n    gsutil ls -L gs://bucket/obj1\n\
      \n  will print something like:\n\n    gs://bucket/obj1:\n            Creation\
      \ time:                    Fri, 21 Oct 2016 19:25:17 GMT\n            Update\
      \ time:                      Fri, 21 Oct 2016 21:17:59 GMT\n            Storage\
      \ class update time:        Fri, 21 Oct 2016 22:12:32 GMT\n            Size:\
      \                             2276224\n            Cache-Control:          \
      \          private, max-age=0\n            Content-Type:                   \
      \  application/x-executable\n            ETag:                             5ca6796417570a586723b7344afffc81\n\
      \            Generation:                       1378862725952000\n          \
      \  Metageneration:                   1\n            ACL:\n    [\n      {\n \
      \       \"entity\": \"group-00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70\"\
      ,\n        \"entityId\": \"00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70\"\
      ,\n        \"role\": \"OWNER\"\n      }\n    ]\n    TOTAL: 1 objects, 2276224\
      \ bytes (2.17 MiB)\n\n  Note that some fields above (time updated, storage class\
      \ update time) are\n  not available with the (non-default) XML API.\n\n  Also\
      \ note that the Storage class update time field does not display unless it\n\
      \  differs from Creation time.\n\n  See also \"gsutil help acl\" for getting\
      \ a more readable version of the ACL.\n\n\nLISTING BUCKET DETAILS\n  If you\
      \ want to see information about the bucket itself, use the -b\n  option. For\
      \ example:\n\n    gsutil ls -L -b gs://bucket\n\n  will print something like:\n\
      \n    gs://bucket/ :\n            Storage class:                MULTI_REGIONAL\n\
      \            Location constraint:          US\n            Versioning enabled:\
      \           True\n            Logging configuration:        None\n         \
      \   Website configuration:        None\n            CORS configuration:    \
      \       Present\n            Lifecycle configuration:      None\n          \
      \  Labels:                       None\n            Time created:           \
      \      Fri, 21 Oct 2016 19:25:17 GMT\n            Time updated:            \
      \     Fri, 21 Oct 2016 21:17:59 GMT\n            Metageneration:           \
      \    1\n            ACL:\n    [\n      {\n        \"entity\": \"group-00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70\"\
      ,\n        \"entityId\": \"00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70\"\
      ,\n        \"role\": \"OWNER\"\n      }\n    ]\n            Default ACL:\n \
      \   [\n      {\n        \"entity\": \"group-00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70\"\
      ,\n        \"entityId\": \"00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70\"\
      ,\n        \"role\": \"OWNER\"\n      }\n    ]\n\n  Note that some fields above\
      \ (time created, time updated, metageneration) are\n  not available with the\
      \ (non-default) XML API.\n\n\nOPTIONS\n  -l          Prints long listing (owner,\
      \ length).\n\n  -L          Prints even more detail than -l.  Note: If you use\
      \ this option\n              with the (non-default) XML API it will generate\
      \ an additional\n              request per object being listed, which makes\
      \ the -L option run\n              much more slowly (and cost more) using the\
      \ XML API than the\n              default JSON API.\n\n  -d          List matching\
      \ subdirectory names instead of contents, and do not\n              recurse\
      \ into matching subdirectories even if the -R option is\n              specified.\n\
      \n  -b          Prints info about the bucket when used with a bucket URL.\n\n\
      \  -h          When used with -l, prints object sizes in human readable format\n\
      \              (e.g., 1 KiB, 234 MiB, 2 GiB, etc.)\n\n  -p proj_id  Specifies\
      \ the project ID to use for listing buckets.\n\n  -R, -r      Requests a recursive\
      \ listing, performing at least one listing\n              operation per subdirectory.\
      \ If you have a large number of\n              subdirectories and do not require\
      \ recursive-style output ordering,\n              you may be able to instead\
      \ use wildcards to perform a flat\n              listing, e.g.  `gsutil ls gs://mybucket/**`,\
      \ which will generally\n              perform fewer listing operations.\n\n\
      \  -a          Includes non-current object versions / generations in the listing\n\
      \              (only useful with a versioning-enabled bucket). If combined with\n\
      \              -l option also prints metageneration for each listed object.\n\
      \n  -e          Include ETag in long listing (-l) output.\n"
    generated_using: *id003
  - !Command
    positional: []
    named:
    - !Flag
      description: Specifies the default storage class. Default is "Standard".
      synonyms:
      - -c
      args: !SimpleFlagArg
        name: class
      optional: true
    - !Flag
      description: Can be any multi-regional or regional location. See https://cloud.google.com/storage/docs/storage-classes
        for a discussion of this distinction. Default is US. Locations are case insensitive.
      synonyms:
      - -l
      args: !SimpleFlagArg
        name: location
      optional: true
    - !Flag
      description: Specifies the project ID under which to create the bucket.
      synonyms:
      - -p
      args: !SimpleFlagArg
        name: proj_id
      optional: true
    - !Flag
      description: Same as -c.
      synonyms:
      - -s
      args: !SimpleFlagArg
        name: class
      optional: true
    command:
    - gsutil
    - mb
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  mb - Make buckets\n\n\nSYNOPSIS\n\n  gsutil mb [-c class]\
      \ [-l location] [-p proj_id] url...\n\n\n\nDESCRIPTION\n  The mb command creates\
      \ a new bucket. Google Cloud Storage has a single\n  namespace, so you are not\
      \ allowed to create a bucket with a name already\n  in use by another user.\
      \ You can, however, carve out parts of the bucket name\n  space corresponding\
      \ to your company's domain name (see \"gsutil help naming\").\n\n  If you don't\
      \ specify a project ID using the -p option, the bucket is created\n  using the\
      \ default project ID specified in your gsutil configuration file\n  (see \"\
      gsutil help config\"). For more details about projects see \"gsutil help\n \
      \ projects\".\n\n  The -c and -l options specify the storage class and location,\
      \ respectively,\n  for the bucket. Once a bucket is created in a given location\
      \ and with a\n  given storage class, it cannot be moved to a different location,\
      \ and the\n  storage class cannot be changed. Instead, you would need to create\
      \ a new\n  bucket and move the data over and then delete the original bucket.\n\
      \n\nBUCKET STORAGE CLASSES\n  You can specify one of the `storage classes\n\
      \  <https://cloud.google.com/storage/docs/storage-classes>`_ for a bucket\n\
      \  with the -c option.\n\n  Example:\n\n    gsutil mb -c nearline gs://some-bucket\n\
      \n  See online documentation for\n  `pricing <https://cloud.google.com/storage/pricing>`_\
      \ and\n  `SLA <https://cloud.google.com/storage/sla>`_ details.\n\n  If you\
      \ don't specify a -c option, the bucket is created with the\n  default storage\
      \ class Standard Storage, which is equivalent to Multi-Regional\n  Storage or\
      \ Regional Storage, depending on whether the bucket was created in\n  a multi-regional\
      \ location or regional location, respectively.\n\nBUCKET LOCATIONS\n  You can\
      \ specify one of the 'available locations\n  <https://cloud.google.com/storage/docs/bucket-locations>`_\
      \ for a bucket\n  with the -l option.\n\n  Examples:\n\n    gsutil mb -l asia\
      \ gs://some-bucket\n\n    gsutil mb -c regional -l us-east1 gs://some-bucket\n\
      \n  If you don't specify a -l option, the bucket is created in the default\n\
      \  location (US).\n\nOPTIONS\n  -c class          Specifies the default storage\
      \ class. Default is \"Standard\".\n\n  -l location       Can be any multi-regional\
      \ or regional location. See\n                    https://cloud.google.com/storage/docs/storage-classes\n\
      \                    for a discussion of this distinction. Default is US.\n\
      \                    Locations are case insensitive.\n\n  -p proj_id       \
      \ Specifies the project ID under which to create the bucket.\n\n  -s class \
      \         Same as -c.\n"
    generated_using: *id003
  - !Command
    positional:
    - !Positional
      description: ''
      position: 0
      name: src_url
      optional: false
    - !Positional
      description: ''
      position: 1
      name: dst_url
      optional: false
    named:
    - !Flag
      description: ''
      synonyms:
      - -p
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - mv
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ mv [-p] src_url dst_url\n  gsutil mv [-p] src_url... dst_url\n  gsutil mv\
      \ [-p] -I dst_url\n\nFor additional help run:\n  gsutil help mv\n"
    generated_using: *id005
  - !Command
    positional: []
    named:
    - !Flag
      description: 'Specify an event type filter for this notification config. Cloud
        Storage will only send notifications of this type. You may specify this parameter
        multiple times to allow multiple event types. If not specified, Cloud Storage
        will send notifications for all event types. The valid types are: OBJECT_FINALIZE
        - An object has been created. OBJECT_METADATA_UPDATE - The metadata of an
        object has changed. OBJECT_DELETE - An object has been permanently deleted.
        OBJECT_ARCHIVE - A live Cloud Storage object has been archived.'
      synonyms:
      - -e
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specifies the payload format of notification messages. Must be
        either "json" for a payload matches the object metadata for the JSON API,
        or "none" to specify no payload at all. In either case, notification details
        are available in the message attributes.
      synonyms:
      - -f
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specifies a key:value attribute that will be appended to the set
        of attributes sent to Cloud Pub/Sub for all events associated with this notification
        config. You may specify this parameter multiple times to set multiple attributes.
      synonyms:
      - -m
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specifies a prefix path filter for this notification config. Cloud
        Storage will only send notifications for objects in this bucket whose names
        begin with the specified prefix.
      synonyms:
      - -p
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Skips creation and permission assignment of the Cloud Pub/Sub topic.
        This is useful if the caller does not have permission to access the topic
        in question, or if the topic already exists and has the appropriate publish
        permission assigned.
      synonyms:
      - -s
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: The Cloud Pub/Sub topic to which notifications should be sent.
        If not specified, this command will choose a topic whose project is your default
        project and whose ID is the same as the Cloud Storage bucket name.
      synonyms:
      - -t
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - notification
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  notification - Configure object change notification\n\n\n\
      SYNOPSIS\n  gsutil notification create -f (json|none) [-p prefix] [-t topic]\
      \ \\\n      [-m key:value]... [-e eventType]... bucket_url\n  gsutil notification\
      \ delete (notificationConfigName|bucket_url)...\n  gsutil notification list\
      \ bucket_url...\n\n  gsutil notification watchbucket [-i id] [-t token] app_url\
      \ bucket_url\n  gsutil notification stopchannel channel_id resource_id\n\n\n\
      DESCRIPTION\n  The notification command is used to configure Google Cloud Storage\
      \ support for\n  sending notifications to Cloud Pub/Sub as well as to configure\
      \ the object\n  change notification feature.\n\nCLOUD PUB/SUB\n  The \"create\"\
      , \"list\", and \"delete\" sub-commands deal with configuring Cloud\n  Storage\
      \ integration with Google Cloud Pub/Sub.\n\nCREATE\n  The create sub-command\
      \ creates a notification config on a bucket, establishing\n  a flow of event\
      \ notifications from Cloud Storage to a Cloud Pub/Sub topic. As\n  part of creating\
      \ this flow, the create command also verifies that the\n  destination Cloud\
      \ Pub/Sub topic exists, creating it if necessary, and verifies\n  that the Cloud\
      \ Storage bucket has permission to publish events to that topic,\n  granting\
      \ the permission if necessary.\n\n  If a destination Cloud Pub/Sub topic is\
      \ not specified with the -t flag, Cloud\n  Storage will by default choose a\
      \ topic name in the default project whose ID is\n  the same the bucket name.\
      \ For example, if the default project ID specified is\n  'default-project' and\
      \ the bucket being configured is gs://example-bucket, the\n  create command\
      \ will use the Cloud Pub/Sub topic\n  \"projects/default-project/topics/example-bucket\"\
      .\n\n  In order to enable notifications, a special Cloud Storage service account\n\
      \  unique to each project must have the IAM permission \"projects.topics.publish\"\
      .\n  This command will check to see if that permission exists and, if not, will\n\
      \  attempt to grant it.\n\n  You can create multiple notification configurations\
      \ for a bucket, but their\n  triggers cannot overlap such that a single event\
      \ could send multiple\n  notifications. Attempting to create a notification\
      \ configuration that\n  overlaps with an exisitng notification configuration\
      \ results in an error.\n\nCREATE EXAMPLES\n  Begin sending notifications of\
      \ all changes to the bucket example-bucket\n  to the Cloud Pub/Sub topic projects/default-project/topics/example-bucket:\n\
      \n    gsutil notification create -f json gs://example-bucket\n\n  The same as\
      \ above, but specifies the destination topic ID 'files-to-process'\n  in the\
      \ default project:\n\n    gsutil notification create -f json \\\n      -t files-to-process\
      \ gs://example-bucket\n\n  The same as above, but specifies a Cloud Pub/Sub\
      \ topic belonging to the\n  specific cloud project 'example-project':\n\n  \
      \  gsutil notification create -f json \\\n      -t projects/example-project/topics/files-to-process\
      \ gs://example-bucket\n\n  Create a notification config that will only send\
      \ an event when a new object\n  has been created:\n\n    gsutil notification\
      \ create -f json -t OBJECT_FINALIZE gs://example-bucket\n\n  Create a topic\
      \ and notification config that will only send an event when\n  an object beginning\
      \ with \"photos/\" is affected:\n\n    gsutil notification create -p photos/\
      \ gs://example-bucket\n\n  List all of the notificationConfigs in bucket example-bucket:\n\
      \n    gsutil notification list gs://example-bucket\n\n  Delete all notitificationConfigs\
      \ for bucket example-bucket:\n\n    gsutil notification delete gs://example-bucket\n\
      \n  Delete one specific notificationConfig for bucket example-bucket:\n\n  \
      \  gsutil notification delete \\\n      projects/_/buckets/example-bucket/notificationConfigs/1\n\
      \nOPTIONS\n  The create sub-command has the following options\n\n  -e      \
      \  Specify an event type filter for this notification config. Cloud\n      \
      \      Storage will only send notifications of this type. You may specify\n\
      \            this parameter multiple times to allow multiple event types. If\
      \ not\n            specified, Cloud Storage will send notifications for all\
      \ event\n            types. The valid types are:\n\n              OBJECT_FINALIZE\
      \ - An object has been created.\n              OBJECT_METADATA_UPDATE - The\
      \ metadata of an object has changed.\n              OBJECT_DELETE - An object\
      \ has been permanently deleted.\n              OBJECT_ARCHIVE - A live Cloud\
      \ Storage object has been archived.\n\n  -f        Specifies the payload format\
      \ of notification messages. Must be\n            either \"json\" for a payload\
      \ matches the object metadata for the\n            JSON API, or \"none\" to\
      \ specify no payload at all. In either case,\n            notification details\
      \ are available in the message attributes.\n\n  -m        Specifies a key:value\
      \ attribute that will be appended to the set\n            of attributes sent\
      \ to Cloud Pub/Sub for all events associated with\n            this notification\
      \ config. You may specify this parameter multiple\n            times to set\
      \ multiple attributes.\n\n  -p        Specifies a prefix path filter for this\
      \ notification config. Cloud\n            Storage will only send notifications\
      \ for objects in this bucket\n            whose names begin with the specified\
      \ prefix.\n\n  -s        Skips creation and permission assignment of the Cloud\
      \ Pub/Sub topic.\n            This is useful if the caller does not have permission\
      \ to access\n            the topic in question, or if the topic already exists\
      \ and has the\n            appropriate publish permission assigned.\n\n  -t\
      \        The Cloud Pub/Sub topic to which notifications should be sent. If\n\
      \            not specified, this command will choose a topic whose project is\n\
      \            your default project and whose ID is the same as the Cloud Storage\n\
      \            bucket name.\n\nLIST\n  The list sub-command provides a list of\
      \ notification configs belonging to a\n  given bucket. The listed name of each\
      \ notification config can be used with\n  the delete sub-command to delete that\
      \ specific notification config.\n\n  No object change notifications will be\
      \ listed. Only Cloud Pub/Sub notification\n  subscription configs will be listed.\n\
      \nLIST EXAMPLES\n  Fetch the list of notification configs for the bucket example-bucket:\n\
      \n    gsutil notification list gs://example-bucket\n\n  Fetch the notification\
      \ configs in all buckets matching a wildcard:\n\n    gsutil notification list\
      \ gs://example-*\n\n  Fetch all of the notification configs for buckets in the\
      \ default project:\n\n    gsutil notification list gs://*\n\nDELETE\n  The delete\
      \ sub-command deletes notification configs from a bucket. If a\n  notification\
      \ config name is passed as a parameter, that notification config\n  alone will\
      \ be deleted. If a bucket name is passed, all notification configs\n  associated\
      \ with that bucket will be deleted.\n\n  Cloud Pub/Sub topics associated with\
      \ this notification config will not be\n  deleted by this command. Those must\
      \ be deleted separately, for example with\n  the gcloud command `gcloud beta\
      \ pubsub topics delete`.\n\n  Object Change Notification subscriptions cannot\
      \ be deleted with this command.\n  For that, see the command `gsutil notification\
      \ stopchannel`.\n\nDELETE EXAMPLES\n  Delete a single notification config (with\
      \ ID 3) in the bucket example-bucket:\n\n    gsutil notification delete projects/_/buckets/example-bucket/notificationConfigs/3\n\
      \n  Delete all notification configs in the bucket example-bucket:\n\n    gsutil\
      \ notification delete gs://example-bucket\n\nOBJECT CHANGE NOTIFICATIONS\n \
      \ For more information on the Object Change Notification feature, please see:\n\
      \  https://cloud.google.com/storage/docs/object-change-notification\n\n  The\
      \ \"watchbucket\" and \"stopchannel\" sub-commands enable and disable Object\n\
      \  Change Notifications.\n\nWATCHBUCKET\n  The watchbucket sub-command can be\
      \ used to watch a bucket for object changes.\n  A service account must be used\
      \ when running this command.\n\n  The app_url parameter must be an HTTPS URL\
      \ to an application that will be\n  notified of changes to any object in the\
      \ bucket. The URL endpoint must be\n  a verified domain on your project. See\n\
      \  `Notification Authorization <https://cloud.google.com/storage/docs/object-change-notification#_Authorization>`_\n\
      \  for details.\n\n  The optional id parameter can be used to assign a unique\
      \ identifier to the\n  created notification channel. If not provided, a random\
      \ UUID string will be\n  generated.\n\n  The optional token parameter can be\
      \ used to validate notifications events.\n  To do this, set this custom token\
      \ and store it to later verify that\n  notification events contain the client\
      \ token you expect.\n\nWATCHBUCKET EXAMPLES\n  Watch the bucket example-bucket\
      \ for changes and send notifications to an\n  application server running at\
      \ example.com:\n\n    gsutil notification watchbucket https://example.com/notify\
      \ \\\n      gs://example-bucket\n\n  Assign identifier my-channel-id to the\
      \ created notification channel:\n\n    gsutil notification watchbucket -i my-channel-id\
      \ \\\n      https://example.com/notify gs://example-bucket\n\n  Set a custom\
      \ client token that will be included with each notification event:\n\n    gsutil\
      \ notification watchbucket -t my-client-token \\\n      https://example.com/notify\
      \ gs://example-bucket\n\nSTOPCHANNEL\n  The stopchannel sub-command can be used\
      \ to stop sending change events to a\n  notification channel.\n\n  The channel_id\
      \ and resource_id parameters should match the values from the\n  response of\
      \ a bucket watch request.\n\nSTOPCHANNEL EXAMPLES\n  Stop the notification event\
      \ channel with channel identifier channel1 and\n  resource identifier SoGqan08XDIFWr1Fv_nGpRJBHh8:\n\
      \n    gsutil notification stopchannel channel1 SoGqan08XDIFWr1Fv_nGpRJBHh8\n\
      \nNOTIFICATIONS AND PARALLEL COMPOSITE UPLOADS\n  By default, gsutil enables\
      \ parallel composite uploads for large files (see\n  \"gsutil help cp\"), which\
      \ means that an upload of a large object can result\n  in multiple temporary\
      \ component objects being uploaded before the actual\n  intended object is created.\
      \ Any subscriber to notifications for this bucket\n  will then see a notification\
      \ for each of these components being created and\n  deleted. If this is a concern\
      \ for you, note that parallel composite uploads\n  can be disabled by setting\
      \ \"parallel_composite_upload_threshold = 0\" in your\n  boto config file.\n"
    generated_using: *id003
  - !Command
    positional: []
    named:
    - !Flag
      description: Sets the number of objects to use when downloading and uploading
        files during tests. Defaults to 5.
      synonyms:
      - -n
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Sets the number of processes to use while running throughput experiments.
        The default value is 1.
      synonyms:
      - -c
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'Sets the number of threads per process to use while running throughput
        experiments. Each process will receive an equal number of threads. The default
        value is 1. Note: All specified threads and processes will be created, but
        may not by saturated with work if too few objects (specified with -n) and
        too few components (specified with -y) are specified.'
      synonyms:
      - -k
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'Sets the type of parallelism to be used (only applicable when
        threads or processes are specified and threads * processes > 1). The default
        is to use fan. Must be one of the following: fan Use one thread per object.
        This is akin to using gsutil -m cp, with sliced object download / parallel
        composite upload disabled. slice Use Y (specified with -y) threads for each
        object, transferring one object at a time. This is akin to using parallel
        object download / parallel composite upload, without -m. Sliced uploads not
        supported for s3. both Use Y (specified with -y) threads for each object,
        transferring multiple objects at a time. This is akin to simultaneously using
        sliced object download / parallel composite upload and gsutil -m cp. Sliced
        uploads not supported for s3.'
      synonyms:
      - -p
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Sets the number of slices to divide each file/object into while
        transferring data. Only applicable with the slice (or both) parallelism type.
        The default is 4 slices.
      synonyms:
      - -y
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'Sets the size (in bytes) for each of the N (set with -n) objects
        used in the read and write throughput tests. The default is 1 MiB. This can
        also be specified using byte suffixes such as 500K or 1M. Note: these values
        are interpreted as multiples of 1024 (K=1024, M=1024*1024, etc.) Note: If
        rthru_file or wthru_file are performed, N (set with -n) times as much disk
        space as specified will be required for the operation.'
      synonyms:
      - -s
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Sets the directory to store temporary local files in. If not specified,
        a default temporary directory will be used.
      synonyms:
      - -d
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'Sets the list of diagnostic tests to perform. The default is to
        run the lat, rthru, and wthru diagnostic tests. Must be a comma-separated
        list containing one or more of the following: lat For N (set with -n) objects,
        write the object, retrieve its metadata, read the object, and finally delete
        the object. Record the latency of each operation. list Write N (set with -n)
        objects to the bucket, record how long it takes for the eventually consistent
        listing call to return the N objects in its result, delete the N objects,
        then record how long it takes listing to stop returning the N objects. rthru
        Runs N (set with -n) read operations, with at most C (set with -c) reads outstanding
        at any given time. rthru_file The same as rthru, but simultaneously writes
        data to the disk, to gauge the performance impact of the local disk on downloads.
        wthru Runs N (set with -n) write operations, with at most C (set with -c)
        writes outstanding at any given time. wthru_file The same as wthru, but simultaneously
        reads data from the disk, to gauge the performance impact of the local disk
        on uploads.'
      synonyms:
      - -t
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: 'Adds metadata to the result JSON file. Multiple -m values can
        be specified. Example: gsutil perfdiag -m "key1:val1" -m "key2:val2" gs://bucketname
        Each metadata key will be added to the top-level "metadata" dictionary in
        the output JSON file.'
      synonyms:
      - -m
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Writes the results of the diagnostic to an output file. The output
        is a JSON file containing system information and performance diagnostic results.
        The file can be read and reported later using the -i option.
      synonyms:
      - -o
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Reads the JSON output file created using the -o command and prints
        a formatted description of the results.
      synonyms:
      - -i
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - perfdiag
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  perfdiag - Run performance diagnostic\n\n\nSYNOPSIS\n\n  gsutil\
      \ perfdiag [-i in.json]\n  gsutil perfdiag [-o out.json] [-n objects] [-c processes]\n\
      \      [-k threads] [-p parallelism type] [-y slices] [-s size] [-d directory]\n\
      \      [-t tests] url...\n\n\n\nDESCRIPTION\n  The perfdiag command runs a suite\
      \ of diagnostic tests for a given Google\n  Storage bucket.\n\n  The 'url' parameter\
      \ must name an existing bucket (e.g. gs://foo) to which\n  the user has write\
      \ permission. Several test files will be uploaded to and\n  downloaded from\
      \ this bucket. All test files will be deleted at the completion\n  of the diagnostic\
      \ if it finishes successfully.\n\n  gsutil performance can be impacted by many\
      \ factors at the client, server,\n  and in-between, such as: CPU speed; available\
      \ memory; the access path to the\n  local disk; network bandwidth; contention\
      \ and error rates along the path\n  between gsutil and Google; operating system\
      \ buffering configuration; and\n  firewalls and other network elements. The\
      \ perfdiag command is provided so\n  that customers can run a known measurement\
      \ suite when troubleshooting\n  performance problems.\n\n\nPROVIDING DIAGNOSTIC\
      \ OUTPUT TO GOOGLE CLOUD STORAGE TEAM\n  If the Google Cloud Storage Team asks\
      \ you to run a performance diagnostic\n  please use the following command, and\
      \ email the output file (output.json)\n  to gs-team@google.com:\n\n    gsutil\
      \ perfdiag -o output.json gs://your-bucket\n\n\nOPTIONS\n  -n          Sets\
      \ the number of objects to use when downloading and uploading\n            \
      \  files during tests. Defaults to 5.\n\n  -c          Sets the number of processes\
      \ to use while running throughput\n              experiments. The default value\
      \ is 1.\n\n  -k          Sets the number of threads per process to use while\
      \ running\n              throughput experiments. Each process will receive an\
      \ equal number\n              of threads. The default value is 1.\n\n      \
      \        Note: All specified threads and processes will be created, but may\n\
      \              not by saturated with work if too few objects (specified with\
      \ -n)\n              and too few components (specified with -y) are specified.\n\
      \n  -p          Sets the type of parallelism to be used (only applicable when\n\
      \              threads or processes are specified and threads * processes >\
      \ 1).\n              The default is to use fan. Must be one of the following:\n\
      \n              fan\n                 Use one thread per object. This is akin\
      \ to using gsutil -m cp,\n                 with sliced object download / parallel\
      \ composite upload\n                 disabled.\n\n              slice\n    \
      \             Use Y (specified with -y) threads for each object, transferring\n\
      \                 one object at a time. This is akin to using parallel object\n\
      \                 download / parallel composite upload, without -m. Sliced\n\
      \                 uploads not supported for s3.\n\n              both\n    \
      \             Use Y (specified with -y) threads for each object, transferring\n\
      \                 multiple objects at a time. This is akin to simultaneously\n\
      \                 using sliced object download / parallel composite upload and\n\
      \                 gsutil -m cp. Sliced uploads not supported for s3.\n\n  -y\
      \          Sets the number of slices to divide each file/object into while\n\
      \              transferring data. Only applicable with the slice (or both)\n\
      \              parallelism type. The default is 4 slices.\n\n  -s          Sets\
      \ the size (in bytes) for each of the N (set with -n) objects\n            \
      \  used in the read and write throughput tests. The default is 1 MiB.\n    \
      \          This can also be specified using byte suffixes such as 500K or 1M.\n\
      \              Note: these values are interpreted as multiples of 1024 (K=1024,\n\
      \              M=1024*1024, etc.)\n              Note: If rthru_file or wthru_file\
      \ are performed, N (set with -n)\n              times as much disk space as\
      \ specified will be required for the\n              operation.\n\n  -d     \
      \     Sets the directory to store temporary local files in. If not\n       \
      \       specified, a default temporary directory will be used.\n\n  -t     \
      \     Sets the list of diagnostic tests to perform. The default is to\n    \
      \          run the lat, rthru, and wthru diagnostic tests. Must be a\n     \
      \         comma-separated list containing one or more of the following:\n\n\
      \              lat\n                 For N (set with -n) objects, write the\
      \ object, retrieve its\n                 metadata, read the object, and finally\
      \ delete the object.\n                 Record the latency of each operation.\n\
      \n              list\n                 Write N (set with -n) objects to the\
      \ bucket, record how long\n                 it takes for the eventually consistent\
      \ listing call to return\n                 the N objects in its result, delete\
      \ the N objects, then record\n                 how long it takes listing to\
      \ stop returning the N objects.\n\n              rthru\n                 Runs\
      \ N (set with -n) read operations, with at most C\n                 (set with\
      \ -c) reads outstanding at any given time.\n\n              rthru_file\n   \
      \              The same as rthru, but simultaneously writes data to the disk,\n\
      \                 to gauge the performance impact of the local disk on downloads.\n\
      \n              wthru\n                 Runs N (set with -n) write operations,\
      \ with at most C\n                 (set with -c) writes outstanding at any given\
      \ time.\n\n              wthru_file\n                 The same as wthru, but\
      \ simultaneously reads data from the disk,\n                 to gauge the performance\
      \ impact of the local disk on uploads.\n\n  -m          Adds metadata to the\
      \ result JSON file. Multiple -m values can be\n              specified. Example:\n\
      \n                  gsutil perfdiag -m \"key1:val1\" -m \"key2:val2\" gs://bucketname\n\
      \n              Each metadata key will be added to the top-level \"metadata\"\
      \n              dictionary in the output JSON file.\n\n  -o          Writes\
      \ the results of the diagnostic to an output file. The output\n            \
      \  is a JSON file containing system information and performance\n          \
      \    diagnostic results. The file can be read and reported later using\n   \
      \           the -i option.\n\n  -i          Reads the JSON output file created\
      \ using the -o command and prints\n              a formatted description of\
      \ the results.\n\n\nMEASURING AVAILABILITY\n  The perfdiag command ignores the\
      \ boto num_retries configuration parameter.\n  Instead, it always retries on\
      \ HTTP errors in the 500 range and keeps track of\n  how many 500 errors were\
      \ encountered during the test. The availability\n  measurement is reported at\
      \ the end of the test.\n\n  Note that HTTP responses are only recorded when\
      \ the request was made in a\n  single process. When using multiple processes\
      \ or threads, read and write\n  throughput measurements are performed in an\
      \ external process, so the\n  availability numbers reported won't include the\
      \ throughput measurements.\n\n\nNOTE\n  The perfdiag command collects system\
      \ information. It collects your IP address,\n  executes DNS queries to Google\
      \ servers and collects the results, and collects\n  network statistics information\
      \ from the output of netstat -s. It will also\n  attempt to connect to your\
      \ proxy server if you have one configured. None of\n  this information will\
      \ be sent to Google unless you choose to send it.\n"
    generated_using: *id003
  - &id006 !Command
    positional: []
    named:
    - !Flag
      description: ''
      synonyms:
      - -f
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - rb
    parent: *id001
    subcommands:
    - !Command
      positional: []
      named:
      - !Flag
        description: Continues silently (without printing error messages) despite
          errors when removing buckets. If some buckets couldn't be removed, gsutil's
          exit status will be non-zero even if this flag is set.
        synonyms:
        - -f
        args: !EmptyFlagArg {}
        optional: true
      command:
      - gsutil
      - rb
      - url...
      parent: *id006
      subcommands: []
      help_flag:
      usage_flag:
      version_flag:
      help_text: "NAME\n  rb - Remove buckets\n\n\nSYNOPSIS\n\n  gsutil rb [-f] url...\n\
        \n\n\nDESCRIPTION\n  The rb command deletes a bucket. Buckets must be empty\
        \ before you can delete\n  them.\n\n  Be certain you want to delete a bucket\
        \ before you do so, as once it is\n  deleted the name becomes available and\
        \ another user may create a bucket with\n  that name. (But see also \"DOMAIN\
        \ NAMED BUCKETS\" under \"gsutil help naming\"\n  for help carving out parts\
        \ of the bucket name space.)\n\n\nOPTIONS\n  -f          Continues silently\
        \ (without printing error messages) despite\n              errors when removing\
        \ buckets. If some buckets couldn't be removed,\n              gsutil's exit\
        \ status will be non-zero even if this flag is set.\n"
      generated_using: *id003
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ rb [-f] url...\n\nFor additional help run:\n  gsutil help rb\n"
    generated_using: *id005
  - !Command
    positional: []
    named:
    - !Flag
      description: Continues silently (without printing error messages) despite errors
        when rewriting multiple objects. If some of the objects could not be rewritten,
        gsutil's exit status will be non-zero even if this flag is set. This option
        is implicitly set when running "gsutil -m rewrite ...".
      synonyms:
      - -f
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Causes gsutil to read the list of objects to rewrite from stdin.
        This allows you to run a program that generates the list of objects to rewrite.
      synonyms:
      - -I
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Rewrite the objects to the current encryption key specific in your
        boto configuration file. If encryption_key is specified, encrypt all objects
        with this key. If encryption_key is unspecified, decrypt all objects. See
        `gsutil help encryption` for details on encryption configuration.
      synonyms:
      - -k
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Rewrite objects with the bucket's default object ACL instead of
        the existing object ACL. This is needed if you do not have OWNER permission
        on the object.
      synonyms:
      - -O
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: The -R and -r options are synonymous. Causes bucket or bucket subdirectory
        contents to be rewritten recursively.
      synonyms:
      - -R
      - -r
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Rewrite objects using the specified storage class.
      synonyms:
      - -s
      args: !SimpleFlagArg
        name: class
      optional: true
    command:
    - gsutil
    - rewrite
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  rewrite - Rewrite objects\n\n\nSYNOPSIS\n\n  gsutil rewrite\
      \ -k [-f] [-r] url...\n  gsutil rewrite -k [-f] [-r] -I\n\n\n\nDESCRIPTION\n\
      \  The gsutil rewrite command rewrites cloud objects, applying the specified\n\
      \  transformations to them. The transformation(s) are atomic and\n  applied\
      \ based on the input transformation flags. Object metadata values are\n  preserved\
      \ unless altered by a transformation.\n\n  The -k flag is supported to add,\
      \ rotate, or remove encryption keys on\n  objects.  For example, the command:\n\
      \n    gsutil rewrite -k gs://bucket/**\n\n  will update all objects in gs://bucket\
      \ with the current encryption key\n  from your boto config file.\n\n  You can\
      \ also use the -r option to specify recursive object transform; this is\n  synonymous\
      \ with the ** wildcard. Thus, either of the following two commands\n  will perform\
      \ encryption key transforms on gs://bucket/subdir and all objects\n  and subdirectories\
      \ under it:\n\n    gsutil rewrite -k gs://bucket/subdir**\n    gsutil rewrite\
      \ -k -r gs://bucket/subdir\n\n  The rewrite command acts only on live object\
      \ versions, so specifying a\n  URL with a generation will fail. If you want\
      \ to rewrite an archived\n  generation, first copy it to the live version, then\
      \ rewrite it, for example:\n\n    gsutil cp gs://bucket/object#123 gs://bucket/object\n\
      \    gsutil rewrite -k gs://bucket/object\n\n  You can use the -s option to\
      \ specify a new storage class for objects.  For\n  example, the command:\n\n\
      \    gsutil rewrite -s nearline gs://bucket/foo\n\n  will rewrite the object,\
      \ changing its storage class to nearline.\n\n  The rewrite command will skip\
      \ objects that are already in the desired state.\n  For example, if you run:\n\
      \n    gsutil rewrite -k gs://bucket/**\n\n  and gs://bucket contains objects\
      \ that already match the encryption\n  configuration, gsutil will skip rewriting\
      \ those objects and only rewrite\n  objects that do not match the encryption\
      \ configuration. If you specify\n  multiple transformations, gsutil will only\
      \ skip those that would not change\n  the object's state. For example, if you\
      \ run:\n\n    gsutil rewrite -s nearline -k gs://bucket/**\n\n  and gs://bucket\
      \ contains objects that already match the encryption\n  configuration but have\
      \ a storage class of standard, the only transformation\n  applied to those objects\
      \ would be the change in storage class.\n\n  You can pass a list of URLs (one\
      \ per line) to rewrite on stdin instead of as\n  command line arguments by using\
      \ the -I option. This allows you to use gsutil\n  in a pipeline to rewrite objects\
      \ identified by a program, such as:\n\n    some_program | gsutil -m rewrite\
      \ -k -I\n\n  The contents of stdin can name cloud URLs and wildcards of cloud\
      \ URLs.\n\n  The rewrite command requires OWNER permissions on each object to\
      \ preserve\n  object ACLs. You can bypass this by using the -O flag, which will\
      \ cause\n  gsutil not to read the object's ACL and instead apply the default\
      \ object ACL\n  to the rewritten object:\n\n    gsutil rewrite -k -O gs://bucket/**\n\
      \n\nOPTIONS\n  -f          Continues silently (without printing error messages)\
      \ despite\n              errors when rewriting multiple objects. If some of\
      \ the objects\n              could not be rewritten, gsutil's exit status will\
      \ be non-zero\n              even if this flag is set. This option is implicitly\
      \ set when\n              running \"gsutil -m rewrite ...\".\n\n  -I       \
      \   Causes gsutil to read the list of objects to rewrite from stdin.\n     \
      \         This allows you to run a program that generates the list of\n    \
      \          objects to rewrite.\n\n  -k          Rewrite the objects to the current\
      \ encryption key specific in\n              your boto configuration file. If\
      \ encryption_key is specified,\n              encrypt all objects with this\
      \ key. If encryption_key is\n              unspecified, decrypt all objects.\
      \ See `gsutil help encryption`\n              for details on encryption configuration.\n\
      \n  -O          Rewrite objects with the bucket's default object ACL instead\
      \ of\n              the existing object ACL. This is needed if you do not have\n\
      \              OWNER permission on the object.\n\n  -R, -r      The -R and -r\
      \ options are synonymous. Causes bucket or bucket\n              subdirectory\
      \ contents to be rewritten recursively.\n\n  -s <class>  Rewrite objects using\
      \ the specified storage class.\n"
    generated_using: *id003
  - !Command
    positional: []
    named:
    - !Flag
      description: Continues silently (without printing error messages) despite errors
        when removing multiple objects. If some of the objects could not be removed,
        gsutil's exit status will be non-zero even if this flag is set. Execution
        will still halt if an inaccessible bucket is encountered. This option is implicitly
        set when running "gsutil -m rm ...".
      synonyms:
      - -f
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Causes gsutil to read the list of objects to remove from stdin.
        This allows you to run a program that generates the list of objects to remove.
      synonyms:
      - -I
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: The -R and -r options are synonymous. Causes bucket or bucket subdirectory
        contents (all objects and subdirectories that it contains) to be removed recursively.
        If used with a bucket-only URL (like gs://bucket), after deleting objects
        and subdirectories gsutil will delete the bucket. This option implies the
        -a option and will delete all object versions.
      synonyms:
      - -R
      - -r
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Delete all versions of an object.
      synonyms:
      - -a
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - rm
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  rm - Remove objects\n\n\nSYNOPSIS\n\n  gsutil rm [-f] [-r]\
      \ url...\n  gsutil rm [-f] [-r] -I\n\n\n\nDESCRIPTION\n  The gsutil rm command\
      \ removes objects.\n  For example, the command:\n\n    gsutil rm gs://bucket/subdir/*\n\
      \n  will remove all objects in gs://bucket/subdir, but not in any of its\n \
      \ sub-directories. In contrast:\n\n    gsutil rm gs://bucket/subdir/**\n\n \
      \ will remove all objects under gs://bucket/subdir or any of its\n  subdirectories.\n\
      \n  You can also use the -r option to specify recursive object deletion. Thus,\
      \ for\n  example, either of the following two commands will remove gs://bucket/subdir\n\
      \  and all objects and subdirectories under it:\n\n    gsutil rm gs://bucket/subdir**\n\
      \    gsutil rm -r gs://bucket/subdir\n\n  The -r option will also delete all\
      \ object versions in the subdirectory for\n  versioning-enabled buckets, whereas\
      \ the ** command will only delete the live\n  version of each object in the\
      \ subdirectory.\n\n  Running gsutil rm -r on a bucket will delete all versions\
      \ of all objects in\n  the bucket, and then delete the bucket:\n\n    gsutil\
      \ rm -r gs://bucket\n\n  If you want to delete all objects in the bucket, but\
      \ not the bucket itself,\n  this command will work:\n\n    gsutil rm gs://bucket/**\n\
      \n  If you have a large number of objects to remove you might want to use the\n\
      \  gsutil -m option, to perform parallel (multi-threaded/multi-processing)\n\
      \  removes:\n\n    gsutil -m rm -r gs://my_bucket/subdir\n\n  You can pass a\
      \ list of URLs (one per line) to remove on stdin instead of as\n  command line\
      \ arguments by using the -I option. This allows you to use gsutil\n  in a pipeline\
      \ to remove objects identified by a program, such as:\n\n    some_program |\
      \ gsutil -m rm -I\n\n  The contents of stdin can name cloud URLs and wildcards\
      \ of cloud URLs.\n\n  Note that gsutil rm will refuse to remove files from the\
      \ local\n  file system. For example this will fail:\n\n    gsutil rm *.txt\n\
      \n  WARNING: Object removal cannot be undone. Google Cloud Storage is designed\n\
      \  to give developers a high amount of flexibility and control over their data,\n\
      \  and Google maintains strict controls over the processing and purging of\n\
      \  deleted data. To protect yourself from mistakes, you can configure object\n\
      \  versioning on your bucket(s). See 'gsutil help versions' for details.\n\n\
      \nDATA RESTORATION FROM ACCIDENTAL DELETION OR OVERWRITES\nGoogle Cloud Storage\
      \ does not provide support for restoring data lost\nor overwritten due to customer\
      \ errors. If you have concerns that your\napplication software (or your users)\
      \ may at some point erroneously delete or\noverwrite data, you can protect yourself\
      \ from that risk by enabling Object\nVersioning (see \"gsutil help versioning\"\
      ). Doing so increases storage costs,\nwhich can be partially mitigated by configuring\
      \ Lifecycle Management to delete\nolder object versions (see \"gsutil help lifecycle\"\
      ).\n\n\nOPTIONS\n  -f          Continues silently (without printing error messages)\
      \ despite\n              errors when removing multiple objects. If some of the\
      \ objects\n              could not be removed, gsutil's exit status will be\
      \ non-zero even\n              if this flag is set. Execution will still halt\
      \ if an inaccessible\n              bucket is encountered. This option is implicitly\
      \ set when running\n              \"gsutil -m rm ...\".\n\n  -I          Causes\
      \ gsutil to read the list of objects to remove from stdin.\n              This\
      \ allows you to run a program that generates the list of\n              objects\
      \ to remove.\n\n  -R, -r      The -R and -r options are synonymous. Causes bucket\
      \ or bucket\n              subdirectory contents (all objects and subdirectories\
      \ that it\n              contains) to be removed recursively. If used with a\
      \ bucket-only\n              URL (like gs://bucket), after deleting objects\
      \ and subdirectories\n              gsutil will delete the bucket. This option\
      \ implies the -a option\n              and will delete all object versions.\n\
      \n  -a          Delete all versions of an object.\n"
    generated_using: *id003
  - &id007 !Command
    positional: []
    named:
    - !Flag
      description: ''
      synonyms:
      - -a
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -c
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -C
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -d
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -e
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -n
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -p
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -r
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -U
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -x
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - rsync
    parent: *id001
    subcommands:
    - !Command
      positional: []
      named:
      - !Flag
        description: Sets named canned_acl when uploaded objects created. See "gsutil
          help acls" for further details. Note that rsync will decide whether or not
          to perform a copy based only on object size and modification time, not current
          ACL state. Also see the -p option below.
        synonyms:
        - -a
        args: !SimpleFlagArg
          name: canned_acl
        optional: true
      - !Flag
        description: Causes the rsync command to compute and compare checksums (instead
          of comparing mtime) for files if the size of source and destination as well
          as mtime (if available) match. This option increases local disk I/O and
          run time if either src_url or dst_url are on the local file system.
        synonyms:
        - -c
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: "If an error occurs, continue to attempt to copy the remaining\
          \ files. If errors occurred, gsutil's exit status will be non-zero even\
          \ if this flag is set. This option is implicitly set when running \"gsutil\
          \ -m rsync...\".  Note: -C only applies to the actual copying operation.\
          \ If an error occurs while iterating over the files in the local directory\
          \ (e.g., invalid Unicode file name) gsutil will print an error message and\
          \ abort."
        synonyms:
        - -C
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: 'Delete extra files under dst_url not found under src_url. By
          default extra files are not deleted. Note: this option can delete data quickly
          if you specify the wrong source/destination combination. See the help section
          above, "BE CAREFUL WHEN USING -d OPTION!".'
        synonyms:
        - -d
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: Exclude symlinks. When specified, symbolic links will be ignored.
          Note that gsutil does not follow directory symlinks, regardless of whether
          -e is specified.
        synonyms:
        - -e
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: Causes rsync to run in "dry run" mode, i.e., just outputting
          what would be copied or deleted without actually doing any copying/deleting.
        synonyms:
        - -n
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: Causes ACLs to be preserved when objects are copied. Note that
          rsync will decide whether or not to perform a copy based only on object
          size and modification time, not current ACL state. Thus, if the source and
          destination differ in size or modification time and you run gsutil rsync
          -p, the file will be copied and ACL preserved. However, if the source and
          destination don't differ in size or checksum but have different ACLs, running
          gsutil rsync -p will have no effect. Note that this option has performance
          and cost implications when using the XML API, as it requires separate HTTP
          calls for interacting with ACLs. The performance issue can be mitigated
          to some degree by using gsutil -m rsync to cause parallel synchronization.
          Also, this option only works if you have OWNER access to all of the objects
          that are copied. You can avoid the additional performance and cost of using
          rsync -p if you want all objects in the destination bucket to end up with
          the same ACL by setting a default object ACL on that bucket instead of using
          rsync -p. See 'gsutil help defacl'.
        synonyms:
        - -p
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: Causes POSIX attributes to be preserved when objects are copied.
          With this feature enabled, gsutil rsync will copy fields provided by stat.
          These are the user ID of the owner, the group ID of the owning group, the
          mode (permissions) of the file, and the access/modification time of the
          file. For downloads, these attributes will only be set if the source objects
          were uploaded with this flag enabled. On Windows, this flag will only set
          and restore access time and modification time. This is because Windows doesn't
          have a notion of POSIX uid/gid/mode.
        synonyms:
        - -P
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: The -R and -r options are synonymous. Causes directories, buckets,
          and bucket subdirectories to be synchronized recursively. If you neglect
          to use this option gsutil will make only the top-level directory in the
          source and destination URLs match, skipping any sub-directories.
        synonyms:
        - -R
        - -r
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: Skip objects with unsupported object types instead of failing.
          Unsupported object types are Amazon S3 Objects in the GLACIER storage class.
        synonyms:
        - -U
        args: !EmptyFlagArg {}
        optional: true
      - !Flag
        description: 'Causes files/objects matching pattern to be excluded, i.e.,
          any matching files/objects will not be copied or deleted. Note that the
          pattern is a Python regular expression, not a wildcard (so, matching any
          string ending in "abc" would be specified using ".*abc$" rather than "*abc").
          Note also that the exclude path is always relative (similar to Unix rsync
          or tar exclude options). For example, if you run the command: gsutil rsync
          -x "data./.*\.txt$" dir gs://my-bucket it will skip the file dir/data1/a.txt.
          You can use regex alternation to specify multiple exclusions, for example:
          gsutil rsync -x ".*\.txt$|.*\.jpg$" dir gs://my-bucket NOTE: While it will
          work to surround the regular expression with either single or double quotes
          on Linux and MacOS, on Windows you need to use double quotes.'
        synonyms:
        - -x
        args: !SimpleFlagArg
          name: pattern
        optional: true
      command:
      - gsutil
      - rsync
      - src_url
      parent: *id007
      subcommands: []
      help_flag:
      usage_flag:
      version_flag:
      help_text: "NAME\n  rsync - Synchronize content of two buckets/directories\n\
        \n\nSYNOPSIS\n\n  gsutil rsync [-a] [-c] [-C] [-d] [-e] [-n] [-p] [-r] [-U]\
        \ [-x] src_url dst_url\n\n\n\nDESCRIPTION\n  The gsutil rsync command makes\
        \ the contents under dst_url the same as the\n  contents under src_url, by\
        \ copying any missing files/objects (or those whose\n  data has changed),\
        \ and (if the -d option is specified) deleting any extra\n  files/objects.\
        \ src_url must specify a directory, bucket, or bucket\n  subdirectory. For\
        \ example, to make gs://mybucket/data match the contents of\n  the local directory\
        \ \"data\" you could do:\n\n    gsutil rsync -d data gs://mybucket/data\n\n\
        \  To recurse into directories use the -r option:\n\n    gsutil rsync -d -r\
        \ data gs://mybucket/data\n\n  To copy only new/changed files without deleting\
        \ extra files from\n  gs://mybucket/data leave off the -d option:\n\n    gsutil\
        \ rsync -r data gs://mybucket/data\n\n  If you have a large number of objects\
        \ to synchronize you might want to use the\n  gsutil -m option, to perform\
        \ parallel (multi-threaded/multi-processing)\n  synchronization:\n\n    gsutil\
        \ -m rsync -d -r data gs://mybucket/data\n\n  The -m option typically will\
        \ provide a large performance boost if either the\n  source or destination\
        \ (or both) is a cloud URL. If both source and\n  destination are file URLs\
        \ the -m option will typically thrash the disk and\n  slow synchronization\
        \ down.\n\n  To make the local directory \"data\" the same as the contents\
        \ of\n  gs://mybucket/data:\n\n    gsutil rsync -d -r gs://mybucket/data data\n\
        \n  To make the contents of gs://mybucket2 the same as gs://mybucket1:\n\n\
        \    gsutil rsync -d -r gs://mybucket1 gs://mybucket2\n\n  You can also mirror\
        \ data across local directories:\n\n    gsutil rsync -d -r dir1 dir2\n\n \
        \ To mirror your content across clouds:\n\n    gsutil rsync -d -r gs://my-gs-bucket\
        \ s3://my-s3-bucket\n\n  Note: If you are synchronizing a large amount of\
        \ data between clouds you might\n  consider setting up a\n  `Google Compute\
        \ Engine <https://cloud.google.com/products/compute-engine>`_\n  account and\
        \ running gsutil there. Since cross-provider gsutil data transfers\n  flow\
        \ through the machine where gsutil is running, doing this can make your\n\
        \  transfer run significantly faster than running gsutil on your local\n \
        \ workstation.\n\n\nBE CAREFUL WHEN USING -d OPTION!\n  The rsync -d option\
        \ is very useful and commonly used, because it provides a\n  means of making\
        \ the contents of a destination bucket or directory match those\n  of a source\
        \ bucket or directory. However, please exercise caution when you\n  use this\
        \ option: It's possible to delete large amounts of data accidentally\n  if,\
        \ for example, you erroneously reverse source and destination. For example,\n\
        \  if you meant to synchronize a local directory from a bucket in the cloud\
        \ but\n  instead run the command:\n\n    gsutil -m rsync -r -d ./your-dir\
        \ gs://your-bucket\n\n  and your-dir is currently empty, you will quickly\
        \ delete all of the objects in\n  gs://your-bucket.\n\n  You can also cause\
        \ large amounts of data to be lost quickly by specifying a\n  subdirectory\
        \ of the destination as the source of an rsync. For example, the\n  command:\n\
        \n    gsutil -m rsync -r -d gs://your-bucket/data gs://your-bucket\n\n  would\
        \ cause most or all of the objects in gs://your-bucket to be deleted\n  (some\
        \ objects may survive if there are any with names that sort lower than\n \
        \ \"data\" under gs://your-bucket/data).\n\n  In addition to paying careful\
        \ attention to the source and destination you\n  specify with the rsync command,\
        \ there are two more safety measures your can\n  take when using gsutil rsync\
        \ -d:\n\n  1. Try running the command with the rsync -n option first, to see\
        \ what it\n     would do without actually performing the operations. For example,\
        \ if\n     you run the command:\n\n       gsutil -m rsync -r -d -n gs://your-bucket/data\
        \ gs://your-bucket\n\n     it will be immediately evident that running that\
        \ command without the -n\n     option would cause many objects to be deleted.\n\
        \n  2. Enable object versioning in your bucket, which will allow you to restore\n\
        \     objects if you accidentally delete them. For more details see\n    \
        \ \"gsutil help versions\".\n\n\nIMPACT OF OBJECT LISTING EVENTUAL CONSISTENCY\n\
        \  The rsync command operates by listing the source and destination URLs,\
        \ and\n  then performing copy and remove operations according to the differences\n\
        \  between these listings. Because object listing is eventually (not strongly)\n\
        \  consistent within multi-regional locations, if you upload new objects or\n\
        \  delete objects from a bucket in a multi-regional location and then\n  immediately\
        \ run gsutil rsync with that bucket as the source or destination,\n  it's\
        \ possible the rsync command will not see the recent updates and thus\n  synchronize\
        \ incorrectly. For example, if you rsync to a ``US`` bucket\n  immediately\
        \ after uploading to or deleting objects from that bucket, it's\n  possible\
        \ gsutil will re-upload objects that have already been uploaded or\n  attempt\
        \ to delete objects that were already deleted. A more troublesome\n  problem\
        \ can occur if you run gsutil rsync, specifying a bucket as the\n  source\
        \ immediately after uploading to or deleting objects from that bucket.\n \
        \ In that case it's possible rsync will miss copying objects to, or deleting\n\
        \  objects from, the destination. If this happens you can rerun the rsync\n\
        \  operation again later (after the object listing has \"caught up\"), to\
        \ cause\n  the missing objects to be copied and extra objects to be deleted.\n\
        \n\nCHECKSUM VALIDATION AND FAILURE HANDLING\n  At the end of every upload\
        \ or download, the gsutil rsync command validates\n  that the checksum of\
        \ the source file/object matches the checksum of the\n  destination file/object.\
        \ If the checksums do not match, gsutil will delete\n  the invalid copy and\
        \ print a warning message. This very rarely happens, but\n  if it does, please\
        \ contact gs-team@google.com.\n\n  The rsync command will retry when failures\
        \ occur, but if enough failures\n  happen during a particular copy or delete\
        \ operation the command will fail.\n\n  If the -C option is provided, the\
        \ command will instead skip the failing\n  object and move on. At the end\
        \ of the synchronization run if any failures\n  were not successfully retried,\
        \ the rsync command will report the count of\n  failures, and exit with non-zero\
        \ status. At this point you can run the rsync\n  command again, and it will\
        \ attempt any remaining needed copy and/or delete\n  operations.\n\n  Note\
        \ that there are cases where retrying will never succeed, such as if you\n\
        \  don't have write permission to the destination bucket or if the destination\n\
        \  path for some objects is longer than the maximum allowed length.\n\n  For\
        \ more details about gsutil's retry handling, please see\n  \"gsutil help\
        \ retries\".\n\n\nCHANGE DETECTION ALGORITHM\n  To determine if a file or\
        \ object has changed, gsutil rsync first checks\n  whether the file modification\
        \ time (mtime) of both the source and destination\n  is available. If mtime\
        \ is available at both source and destination, and the\n  destination mtime\
        \ is different than the source, or if the source and\n  destination file size\
        \ differ, gsutil rsync will update the destination. If the\n  source is a\
        \ cloud bucket and the destination is a local file system, and if\n  mtime\
        \ is not available for the source, gsutil rsync will use the time created\n\
        \  for the cloud object as a substitute for mtime. Otherwise, if mtime is\
        \ not\n  available for either the source or the destination, gsutil rsync\
        \ will fall\n  back to using checksums. If the source and destination are\
        \ both cloud buckets\n  with checksums available, gsutil rsync will use these\
        \ hashes instead of mtime.\n  However, gsutil rsync will still update mtime\
        \ at the destination if it is not\n  present. If the source and destination\
        \ have matching checksums and only the\n  source has an mtime, gsutil rsync\
        \ will copy the mtime to the destination. If\n  neither mtime nor checksums\
        \ are available, gsutil rsync will resort to\n  comparing file sizes.\n\n\
        \  Checksums will not be available when comparing composite Google Cloud Storage\n\
        \  objects with objects at a cloud provider that does not support CRC32C (which\n\
        \  is the only checksum available for composite objects). See 'gsutil help\n\
        \  compose' for details about composite objects.\n\n\nCOPYING IN THE CLOUD\
        \ AND METADATA PRESERVATION\n  If both the source and destination URL are\
        \ cloud URLs from the same provider,\n  gsutil copies data \"in the cloud\"\
        \ (i.e., without downloading to and uploading\n  from the machine where you\
        \ run gsutil). In addition to the performance and\n  cost advantages of doing\
        \ this, copying in the cloud preserves metadata (like\n  Content-Type and\
        \ Cache-Control). In contrast, when you download data from the\n  cloud it\
        \ ends up in a file, which has no associated metadata, other than file\n \
        \ modification time (mtime). Thus, unless you have some way to hold on to\
        \ or\n  re-create that metadata, synchronizing a bucket to a directory in\
        \ the local\n  file system will not retain the metadata other than mtime.\n\
        \n  Note that by default, the gsutil rsync command does not copy the ACLs\
        \ of\n  objects being synchronized and instead will use the default bucket\
        \ ACL (see\n  \"gsutil help defacl\"). You can override this behavior with\
        \ the -p option (see\n  OPTIONS below).\n\n\nSLOW CHECKSUMS\n  If you find\
        \ that CRC32C checksum computation runs slowly, this is likely\n  because\
        \ you don't have a compiled CRC32c on your system. Try running:\n\n    gsutil\
        \ ver -l\n\n  If the output contains:\n\n    compiled crcmod: False\n\n  you\
        \ are running a Python library for computing CRC32C, which is much slower\n\
        \  than using the compiled code. For information on getting a compiled CRC32C\n\
        \  implementation, see 'gsutil help crc32c'.\n\n\nLIMITATIONS\n\n  1. The\
        \ gsutil rsync command will only allow non-negative file modification\n  \
        \   times to be used in its comparisons. This means gsutil rsync will resort\
        \ to\n     using checksums for any file with a timestamp before 1970-01-01\
        \ UTC.\n\n  2. The gsutil rsync command considers only the current object\
        \ generations in\n     the source and destination buckets when deciding what\
        \ to copy / delete. If\n     versioning is enabled in the destination bucket\
        \ then gsutil rsync's\n     overwriting or deleting objects will end up creating\
        \ versions, but the\n     command doesn't try to make the archived generations\
        \ match in the source\n     and destination buckets.\n\n  3. The gsutil rsync\
        \ command does not support copying special file types\n     such as sockets,\
        \ device files, named pipes, or any other non-standard\n     files intended\
        \ to represent an operating system resource. If you run\n     gsutil rsync\
        \ on a source directory that includes such files (for example,\n     copying\
        \ the root directory on Linux that includes /dev ), you should use\n     the\
        \ -x flag to exclude these files. Otherwise, gsutil rsync may fail or\n  \
        \   hang.\n\n  4. The gsutil rsync command copies changed files in their entirety\
        \ and does\n     not employ the\n     `rsync delta-transfer algorithm <https://rsync.samba.org/tech_report/>`_\n\
        \     to transfer portions of a changed file. This is because cloud objects\
        \ are\n     immutable and no facility exists to read partial cloud object\
        \ checksums or\n     perform partial overwrites.\n\nOPTIONS\n  -a canned_acl\
        \ Sets named canned_acl when uploaded objects created. See\n             \
        \   \"gsutil help acls\" for further details. Note that rsync will\n     \
        \           decide whether or not to perform a copy based only on object size\n\
        \                and modification time, not current ACL state. Also see the\
        \ -p\n                option below.\n\n  -c            Causes the rsync command\
        \ to compute and compare checksums\n                (instead of comparing\
        \ mtime) for files if the size of source and\n                destination\
        \ as well as mtime (if available) match. This option\n                increases\
        \ local disk I/O and run time if either src_url or\n                dst_url\
        \ are on the local file system.\n\n  -C            If an error occurs, continue\
        \ to attempt to copy the remaining\n                files. If errors occurred,\
        \ gsutil's exit status will be non-zero\n                even if this flag\
        \ is set. This option is implicitly set when\n                running \"gsutil\
        \ -m rsync...\".  Note: -C only applies to the\n                actual copying\
        \ operation. If an error occurs while iterating\n                over the\
        \ files in the local directory (e.g., invalid Unicode\n                file\
        \ name) gsutil will print an error message and abort.\n\n  -d            Delete\
        \ extra files under dst_url not found under src_url. By\n                default\
        \ extra files are not deleted. Note: this option can\n                delete\
        \ data quickly if you specify the wrong source/destination\n             \
        \   combination. See the help section above,\n                \"BE CAREFUL\
        \ WHEN USING -d OPTION!\".\n\n  -e            Exclude symlinks. When specified,\
        \ symbolic links will be\n                ignored. Note that gsutil does not\
        \ follow directory symlinks,\n                regardless of whether -e is\
        \ specified.\n\n  -n            Causes rsync to run in \"dry run\" mode, i.e.,\
        \ just outputting\n                what would be copied or deleted without\
        \ actually doing any\n                copying/deleting.\n\n  -p          \
        \  Causes ACLs to be preserved when objects are copied. Note that\n      \
        \          rsync will decide whether or not to perform a copy based only\n\
        \                on object size and modification time, not current ACL state.\n\
        \                Thus, if the source and destination differ in size or\n \
        \               modification time and you run gsutil rsync -p, the file will\
        \ be\n                copied and ACL preserved. However, if the source and\
        \ destination\n                don't differ in size or checksum but have different\
        \ ACLs,\n                running gsutil rsync -p will have no effect.\n\n\
        \                Note that this option has performance and cost implications\
        \ when\n                using the XML API, as it requires separate HTTP calls\
        \ for\n                interacting with ACLs. The performance issue can be\
        \ mitigated to\n                some degree by using gsutil -m rsync to cause\
        \ parallel\n                synchronization. Also, this option only works\
        \ if you have OWNER\n                access to all of the objects that are\
        \ copied.\n\n                You can avoid the additional performance and\
        \ cost of using\n                rsync -p if you want all objects in the destination\
        \ bucket to\n                end up with the same ACL by setting a default\
        \ object ACL on that\n                bucket instead of using rsync -p. See\
        \ 'gsutil help defacl'.\n\n  -P            Causes POSIX attributes to be preserved\
        \ when objects are copied.\n                With this feature enabled, gsutil\
        \ rsync will copy fields\n                provided by stat. These are the\
        \ user ID of the owner, the group\n                ID of the owning group,\
        \ the mode (permissions) of the file, and\n                the access/modification\
        \ time of the file. For downloads, these\n                attributes will\
        \ only be set if the source objects were uploaded\n                with this\
        \ flag enabled.\n\n                On Windows, this flag will only set and\
        \ restore access time and\n                modification time. This is because\
        \ Windows doesn't have a notion\n                of POSIX uid/gid/mode.\n\n\
        \  -R, -r        The -R and -r options are synonymous. Causes directories,\n\
        \                buckets, and bucket subdirectories to be synchronized\n \
        \               recursively. If you neglect to use this option gsutil will\
        \ make\n                only the top-level directory in the source and destination\
        \ URLs\n                match, skipping any sub-directories.\n\n  -U     \
        \       Skip objects with unsupported object types instead of failing.\n \
        \               Unsupported object types are Amazon S3 Objects in the GLACIER\n\
        \                storage class.\n\n  -x pattern    Causes files/objects matching\
        \ pattern to be excluded, i.e., any\n                matching files/objects\
        \ will not be copied or deleted. Note that\n                the pattern is\
        \ a Python regular expression, not a wildcard (so,\n                matching\
        \ any string ending in \"abc\" would be specified using\n                \"\
        .*abc$\" rather than \"*abc\"). Note also that the exclude path is\n     \
        \           always relative (similar to Unix rsync or tar exclude options).\n\
        \                For example, if you run the command:\n\n                \
        \  gsutil rsync -x \"data./.*\\.txt$\" dir gs://my-bucket\n\n            \
        \    it will skip the file dir/data1/a.txt.\n\n                You can use\
        \ regex alternation to specify multiple exclusions,\n                for example:\n\
        \n                  gsutil rsync -x \".*\\.txt$|.*\\.jpg$\" dir gs://my-bucket\n\
        \n                NOTE: While it will work to surround the regular expression\
        \ with\n                either single or double quotes on Linux and MacOS,\
        \ on Windows\n                you need to use double quotes.\n"
      generated_using: *id003
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ rsync [-a] [-c] [-C] [-d] [-e] [-n] [-p] [-r] [-U] [-x] src_url dst_url\n\n\
      For additional help run:\n  gsutil help rsync\n"
    generated_using: *id005
  - !Command
    positional: []
    named:
    - !Flag
      description: Specifies the HTTP method to be authorized for use with the signed
        url, default is GET. You may also specify RESUMABLE to create a signed resumable
        upload start URL. When using a signed URL to start a resumable upload session,
        you will need to specify the 'x-goog-resumable:start' header in the request
        or else signature validation will fail.
      synonyms:
      - -m
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specifies the duration that the signed url should be valid for,
        default duration is 1 hour. Times may be specified with no suffix (default
        hours), or with s = seconds, m = minutes, h = hours, d = days. This option
        may be specified multiple times, in which case the duration the link remains
        valid is the sum of all the duration options.
      synonyms:
      - -d
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specifies the content type for which the signed url is valid for.
      synonyms:
      - -c
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Specify the keystore password instead of prompting.
      synonyms:
      - -p
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - signurl
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  signurl - Create a signed url\n\n\nSYNOPSIS\n\n  gsutil signurl\
      \ [-c content_type] [-d duration] [-m http_method] \\\n      [-p password] keystore-file\
      \ url...\n\n\n\nDESCRIPTION\n  The signurl command will generate signed urls\
      \ that can be used to access\n  the specified objects without authentication\
      \ for a specific period of time.\n\n  Please see the `Signed URLs documentation\n\
      \  <https://cloud.google.com/storage/docs/access-control/signed-urls>`_ for\n\
      \  background about signed URLs.\n\n  Multiple gs:// urls may be provided and\
      \ may contain wildcards.  A signed url\n  will be produced for each provided\
      \ url, authorized\n  for the specified HTTP method and valid for the given duration.\n\
      \n  Note: Unlike the gsutil ls command, the signurl command does not support\n\
      \  operations on sub-directories. For example, if you run the command:\n\n \
      \   gsutil signurl <private-key-file> gs://some-bucket/some-object/\n\n  The\
      \ signurl command uses the private key for a  service account (the\n  '<private-key-file>'\
      \ argument) to generate the cryptographic\n  signature for the generated URL.\
      \ The private key file must be in PKCS12\n  or JSON format. If the private key\
      \ is encrypted the signed url command will\n  prompt for the passphrase used\
      \ to protect the private key file\n  (default 'notasecret').  For more information\
      \ regarding generating a private\n  key for use with the signurl command please\
      \ see the `Authentication\n  documentation.\n  <https://cloud.google.com/storage/docs/authentication#generating-a-private-key>`_\n\
      \n  gsutil will look up information about the object \"some-object/\" (with\
      \ a\n  trailing slash) inside bucket \"some-bucket\", as opposed to operating\
      \ on\n  objects nested under gs://some-bucket/some-object. Unless you actually\n\
      \  have an object with that name, the operation will fail.\n\nOPTIONS\n  -m\
      \          Specifies the HTTP method to be authorized for use\n            \
      \  with the signed url, default is GET. You may also specify\n             \
      \ RESUMABLE to create a signed resumable upload start URL. When\n          \
      \    using a signed URL to start a resumable upload session, you will\n    \
      \          need to specify the 'x-goog-resumable:start' header in the\n    \
      \          request or else signature validation will fail.\n\n  -d         \
      \ Specifies the duration that the signed url should be valid\n             \
      \ for, default duration is 1 hour.\n\n              Times may be specified with\
      \ no suffix (default hours), or\n              with s = seconds, m = minutes,\
      \ h = hours, d = days.\n\n              This option may be specified multiple\
      \ times, in which case\n              the duration the link remains valid is\
      \ the sum of all the\n              duration options.\n\n  -c          Specifies\
      \ the content type for which the signed url is\n              valid for.\n\n\
      \  -p          Specify the keystore password instead of prompting.\n\nUSAGE\n\
      \  Create a signed url for downloading an object valid for 10 minutes:\n\n \
      \   gsutil signurl -d 10m <private-key-file> gs://<bucket>/<object>\n\n  Create\
      \ a signed url, valid for one hour, for uploading a plain text\n  file via HTTP\
      \ PUT:\n\n    gsutil signurl -m PUT -d 1h -c text/plain <private-key-file> \\\
      \n        gs://<bucket>/<obj>\n\n  To construct a signed URL that allows anyone\
      \ in possession of\n  the URL to PUT to the specified bucket for one day, creating\n\
      \  an object of Content-Type image/jpg, run:\n\n    gsutil signurl -m PUT -d\
      \ 1d -c image/jpg <private-key-file> \\\n        gs://<bucket>/<obj>\n\n  To\
      \ construct a signed URL that allows anyone in possession of\n  the URL to POST\
      \ a resumable upload to the specified bucket for one day,\n  creating an object\
      \ of Content-Type image/jpg, run:\n\n    gsutil signurl -m RESUMABLE -d 1d -c\
      \ image/jpg <private-key-file> \\\n        gs://bucket/<obj>\n"
    generated_using: *id003
  - !Command
    positional:
    - !Positional
      description: ''
      position: 0
      name: url...
      optional: false
    named: []
    command:
    - gsutil
    - stat
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ stat url...\n\nFor additional help run:\n  gsutil help stat\n"
    generated_using: *id005
  - !Command
    positional: []
    named:
    - !Flag
      description: Run tests against multi-regional US buckets. By default, tests
        run against regional buckets in us-central1.
      synonyms:
      - -b
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Output coverage information.
      synonyms:
      - -c
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Exit on first sequential test failure.
      synonyms:
      - -f
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: List available tests.
      synonyms:
      - -l
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Run at most N tests in parallel. The default value is 5.
      synonyms:
      - -p
      args: !SimpleFlagArg
        name: N
      optional: true
    - !Flag
      description: Run tests against S3 instead of GS.
      synonyms:
      - -s
      args: !EmptyFlagArg {}
      optional: true
    - !Flag
      description: Only run unit tests.
      synonyms:
      - -u
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - test
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  test - Run gsutil unit/integration tests (for developers)\n\
      \n\nSYNOPSIS\n\n  gsutil test [-l] [-u] [-f] [command command...]\n\n\n\nDESCRIPTION\n\
      \  The gsutil test command runs the gsutil unit tests and integration tests.\n\
      \  The unit tests use an in-memory mock storage service implementation, while\n\
      \  the integration tests send requests to the production service using the\n\
      \  preferred API set in the boto configuration file (see \"gsutil help apis\"\
      \ for\n  details).\n\n  To run both the unit tests and integration tests, run\
      \ the command with no\n  arguments:\n\n    gsutil test\n\n  To run the unit\
      \ tests only (which run quickly):\n\n    gsutil test -u\n\n  Tests run in parallel\
      \ regardless of whether the top-level -m flag is\n  present. To limit the number\
      \ of tests run in parallel to 10 at a time:\n\n    gsutil test -p 10\n\n  To\
      \ force tests to run sequentially:\n\n    gsutil test -p 1    \n\n  To have\
      \ sequentially-run tests stop running immediately when an error occurs:\n\n\
      \    gsutil test -f\n\n  To run tests for one or more individual commands add\
      \ those commands as\n  arguments. For example, the following command will run\
      \ the cp and mv command\n  tests:\n\n    gsutil test cp mv\n\n  To list available\
      \ tests, run the test command with the -l argument:\n\n    gsutil test -l\n\n\
      \  The tests are defined in the code under the gslib/tests module. Each test\n\
      \  file is of the format test_[name].py where [name] is the test name you can\n\
      \  pass to this command. For example, running \"gsutil test ls\" would run the\n\
      \  tests in \"gslib/tests/test_ls.py\".\n\n  You can also run an individual\
      \ test class or function name by passing the\n  test module followed by the\
      \ class name and optionally a test name. For\n  example, to run the an entire\
      \ test class by name:\n\n    gsutil test naming.GsutilNamingTests\n\n  or an\
      \ individual test function:\n\n    gsutil test cp.TestCp.test_streaming\n\n\
      \  You can list the available tests under a module or class by passing arguments\n\
      \  with the -l option. For example, to list all available test functions in\
      \ the\n  cp module:\n\n    gsutil test -l cp\n\n  To output test coverage:\n\
      \n    gsutil test -c -p 500\n    coverage html\n\n  This will output an HTML\
      \ report to a directory named 'htmlcov'.\n\n  Test coverage is compatible with\
      \ v4.1 of the coverage module\n  (https://pypi.python.org/pypi/coverage).\n\n\
      \nOPTIONS\n  -b          Run tests against multi-regional US buckets. By default,\n\
      \              tests run against regional buckets in us-central1.\n\n  -c  \
      \        Output coverage information.\n\n  -f          Exit on first sequential\
      \ test failure.\n\n  -l          List available tests.\n\n  -p N        Run\
      \ at most N tests in parallel. The default value is 5.\n\n  -s          Run\
      \ tests against S3 instead of GS.\n\n  -u          Only run unit tests.\n"
    generated_using: *id003
  - !Command
    positional: []
    named:
    - !Flag
      description: Prints additional information, such as the version of Python being
        used, the version of the Boto library, a checksum of the code, the path to
        gsutil, and the path to gsutil's configuration file.
      synonyms:
      - -l
      args: !EmptyFlagArg {}
      optional: true
    command:
    - gsutil
    - version
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "NAME\n  version - Print version info about gsutil\n\n\nSYNOPSIS\n\n\
      \  gsutil version\n\n\n\nDESCRIPTION\n  Prints information about the version\
      \ of gsutil.\n\nOPTIONS\n  -l          Prints additional information, such as\
      \ the version of Python\n              being used, the version of the Boto library,\
      \ a checksum of the\n              code, the path to gsutil, and the path to\
      \ gsutil's configuration\n              file.\n"
    generated_using: *id003
  - &id008 !Command
    positional: []
    named: []
    command:
    - gsutil
    - versioning
    parent: *id001
    subcommands:
    - !Command
      positional:
      - !Positional
        description: ''
        position: 0
        name: on|off
        optional: true
      - !Positional
        description: ''
        position: 1
        name: bucket_url...
        optional: false
      named: []
      command:
      - gsutil
      - versioning
      - set
      parent: *id008
      subcommands: []
      help_flag:
      usage_flag:
      version_flag:
      help_text: "CommandException: The versioning command requires at least 2 arguments.\
        \ Usage:\n\n  gsutil versioning set [on|off] bucket_url...\n  gsutil versioning\
        \ get bucket_url...\n\nFor additional help run:\n  gsutil help versioning\n"
      generated_using: &id009 []
    - !Command
      positional:
      - !Positional
        description: ''
        position: 0
        name: gsutil
        optional: false
      - !Positional
        description: ''
        position: 1
        name: versioning
        optional: false
      - !Positional
        description: ''
        position: 2
        name: set
        optional: false
      - !Positional
        description: ''
        position: 3
        name: on|off
        optional: true
      - !Positional
        description: ''
        position: 4
        name: bucket_url...
        optional: false
      named: []
      command:
      - gsutil
      - versioning
      - on|off
      parent: *id008
      subcommands: []
      help_flag:
      usage_flag:
      version_flag:
      help_text: "CommandException: The versioning command requires at least 2 arguments.\
        \ Usage:\n\n  gsutil versioning set [on|off] bucket_url...\n  gsutil versioning\
        \ get bucket_url...\n\nFor additional help run:\n  gsutil help versioning\n"
      generated_using: *id009
    - !Command
      positional:
      - !Positional
        description: ''
        position: 0
        name: gsutil
        optional: false
      - !Positional
        description: ''
        position: 1
        name: versioning
        optional: false
      - !Positional
        description: ''
        position: 2
        name: set
        optional: false
      - !Positional
        description: ''
        position: 3
        name: on|off
        optional: true
      - !Positional
        description: ''
        position: 4
        name: bucket_url...
        optional: false
      named: []
      command:
      - gsutil
      - versioning
      - bucket_url...
      parent: *id008
      subcommands: []
      help_flag:
      usage_flag:
      version_flag:
      help_text: "CommandException: The versioning command requires at least 2 arguments.\
        \ Usage:\n\n  gsutil versioning set [on|off] bucket_url...\n  gsutil versioning\
        \ get bucket_url...\n\nFor additional help run:\n  gsutil help versioning\n"
      generated_using: *id009
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ versioning set [on|off] bucket_url...\n  gsutil versioning get bucket_url...\n\
      \nFor additional help run:\n  gsutil help versioning\n"
    generated_using: *id005
  - !Command
    positional:
    - !Positional
      description: ''
      position: 0
      name: set
      optional: false
    - !Positional
      description: ''
      position: 1
      name: bucket_url...
      optional: false
    named:
    - !Flag
      description: ''
      synonyms:
      - -m
      args: !SimpleFlagArg
        name: main_page_suffix
      optional: true
    - !Flag
      description: ''
      synonyms:
      - -e
      args: !SimpleFlagArg
        name: error_page
      optional: true
    command:
    - gsutil
    - web
    parent: *id001
    subcommands: []
    help_flag:
    usage_flag:
    version_flag:
    help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil\
      \ web set [-m main_page_suffix] [-e error_page] bucket_url...\n  gsutil web\
      \ get bucket_url\n\nFor additional help run:\n  gsutil help web\n"
    generated_using: *id005
  help_flag:
  usage_flag:
  version_flag:
  help_text: "Usage: gsutil [-D] [-DD] [-h header]... [-m] [-o] [-q] [command [opts...]\
    \ args...]\nAvailable commands:\n  acl             Get, set, or change bucket\
    \ and/or object ACLs\n  cat             Concatenate object content to stdout\n\
    \  compose         Concatenate a sequence of objects into a new composite object.\n\
    \  config          Obtain credentials and create configuration file\n  cors  \
    \          Get or set a CORS JSON document for one or more buckets\n  cp     \
    \         Copy files and objects\n  defacl          Get, set, or change default\
    \ ACL on buckets\n  defstorageclass Get or set the default storage class on buckets\n\
    \  du              Display object size usage\n  hash            Calculate file\
    \ hashes\n  help            Get help about commands and topics\n  iam        \
    \     Get, set, or change bucket and/or object IAM permissions.\n  label     \
    \      Get, set, or change the label configuration of a bucket.\n  lifecycle \
    \      Get or set lifecycle configuration for a bucket\n  logging         Configure\
    \ or retrieve logging on buckets\n  ls              List providers, buckets, or\
    \ objects\n  mb              Make buckets\n  mv              Move/rename objects\
    \ and/or subdirectories\n  notification    Configure object change notification\n\
    \  perfdiag        Run performance diagnostic\n  rb              Remove buckets\n\
    \  rewrite         Rewrite objects\n  rm              Remove objects\n  rsync\
    \           Synchronize content of two buckets/directories\n  setmeta        \
    \ Set metadata on already uploaded objects\n  signurl         Create a signed\
    \ url\n  stat            Display object status\n  test            Run gsutil unit/integration\
    \ tests (for developers)\n  update          Update to the latest gsutil release\n\
    \  version         Print version info about gsutil\n  versioning      Enable or\
    \ suspend versioning for one or more buckets\n  web             Set a main page\
    \ and/or error page for one or more buckets\n\nAdditional help topics:\n  acls\
    \            Working With Access Control Lists\n  anon            Accessing Public\
    \ Data Without Credentials\n  apis            Cloud Storage APIs\n  crc32c   \
    \       CRC32C and Installing crcmod\n  creds           Credential Types Supporting\
    \ Various Use Cases\n  csek            Supplying Your Own Encryption Keys\n  dev\
    \             Contributing Code to gsutil\n  encoding        Filename encoding\
    \ and interoperability problems\n  metadata        Working With Object Metadata\n\
    \  naming          Object and Bucket Naming\n  options         Top-Level Command-Line\
    \ Options\n  prod            Scripting Production Transfers\n  projects      \
    \  Working With Projects\n  retries         Retry Handling Strategy\n  security\
    \        Security and Privacy Considerations\n  subdirs         How Subdirectories\
    \ Work\n  support         Google Cloud Storage Support\n  throttling      Throttling\
    \ gsutil\n  versions        Object Versioning and Concurrency Control\n  wildcards\
    \       Wildcard Names\n\nUse gsutil help <command or topic> for detailed help.\n"
  generated_using: *id009
subcommands:
- !Command
  positional:
  - !Positional
    description: ''
    position: 0
    name: url
    optional: false
  named: []
  command:
  - gsutil
  - lifecycle
  - get
  parent: *id004
  subcommands: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "CommandException: The lifecycle command requires at least 2 arguments.\
    \ Usage:\n\n  gsutil lifecycle get url\n  gsutil lifecycle set config-json-file\
    \ url...\n\n\nFor additional help run:\n  gsutil help lifecycle\n"
  generated_using: *id009
- !Command
  positional:
  - !Positional
    description: ''
    position: 0
    name: gsutil
    optional: false
  - !Positional
    description: ''
    position: 1
    name: lifecycle
    optional: false
  - !Positional
    description: ''
    position: 2
    name: get
    optional: false
  - !Positional
    description: ''
    position: 3
    name: url
    optional: false
  named: []
  command:
  - gsutil
  - lifecycle
  - url
  parent: *id004
  subcommands: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "CommandException: The lifecycle command requires at least 2 arguments.\
    \ Usage:\n\n  gsutil lifecycle get url\n  gsutil lifecycle set config-json-file\
    \ url...\n\n\nFor additional help run:\n  gsutil help lifecycle\n"
  generated_using: *id009
help_flag:
usage_flag:
version_flag:
help_text: "CommandException: Incorrect option(s) specified. Usage:\n\n  gsutil lifecycle\
  \ get url\n  gsutil lifecycle set config-json-file url...\n\n\nFor additional help\
  \ run:\n  gsutil help lifecycle\n"
generated_using: *id005
