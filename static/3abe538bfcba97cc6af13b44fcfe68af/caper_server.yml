!Command
command:
- caper
- server
positional: []
named:
- !Flag
  optional: true
  synonyms:
  - -c
  - --conf
  description: Specify config file
  args: !SimpleFlagArg
    name: CONF
- !Flag
  optional: true
  synonyms:
  - -D
  - --debug
  description: Prints all logs >= DEBUG level
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --gcp-service-account-key-json
  description: "Secret key JSON file for Google Cloud Platform service\naccount. This\
    \ service account should have enough\npermission to Storage for client functions\
    \ and\nStorage/Compute Engine/Genomics API/Life Sciences API\nfor server/runner\
    \ functions."
  args: !SimpleFlagArg
    name: GCP_SERVICE_ACCOUNT_KEY_JSON
- !Flag
  optional: true
  synonyms:
  - --port
  description: Port for Caper server
  args: !SimpleFlagArg
    name: PORT
- !Flag
  optional: true
  synonyms:
  - --no-server-heartbeat
  description: Disable server heartbeat file.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --server-heartbeat-file
  description: "Heartbeat file for Caper clients to get IP and port of\na server"
  args: !SimpleFlagArg
    name: SERVER_HEARTBEAT_FILE
- !Flag
  optional: true
  synonyms:
  - --server-heartbeat-timeout
  description: "Timeout for a heartbeat file in Milliseconds. A\nheartbeat file older\
    \ than this interval will be\nignored."
  args: !SimpleFlagArg
    name: SERVER_HEARTBEAT_TIMEOUT
- !Flag
  optional: true
  synonyms:
  - --java-heap-server
  description: Cromwell Java heap size for "server" mode (java -Xmx)
  args: !SimpleFlagArg
    name: JAVA_HEAP_SERVER
- !Flag
  optional: true
  synonyms:
  - --cromwell-stdout
  description: "Local file to write STDOUT of Cromwell Java process\nto. This is for\
    \ Cromwell (not for Caper's logging\nsystem). Note that STDERR is redirected to\
    \ STDOUT."
  args: !SimpleFlagArg
    name: CROMWELL_STDOUT
- !Flag
  optional: true
  synonyms:
  - -b
  - --backend
  description: Backend to run a workflow
  args: !SimpleFlagArg
    name: BACKEND
- !Flag
  optional: true
  synonyms:
  - --dry-run
  description: "Caper localizes remote files and validates WDL but\ndoes not run/submit\
    \ a pipeline."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --local-loc-dir
  - --tmp-dir
  description: "Temporary directory to store Cromwell's intermediate\nbackend files.\
    \ These files include backend.conf,\nworkflow_opts.json, imports.zip. and localized\
    \ input\nJSON files due to deepcopying (recursive\nlocalization). Cromwell's MySQL/PostgreSQL\
    \ DB password\ncan be exposed on backend.conf on this directory.\nTherefore, DO\
    \ NOT USE /tmp HERE. This directory is\nalso used for storing cached files for\n\
    local/slurm/sge/pbs backends."
  args: !SimpleFlagArg
    name: LOCAL_LOC_DIR
- !Flag
  optional: true
  synonyms:
  - --gcp-loc-dir
  - --tmp-gcs-bucket
  description: "Temporary directory to store cached files for gcp\nbackend. e.g. gs://my-bucket/caper-cache-dir."
  args: !SimpleFlagArg
    name: GCP_LOC_DIR
- !Flag
  optional: true
  synonyms:
  - --aws-loc-dir
  - --tmp-s3-bucket
  description: "Temporary directory to store cached files for aws\nbackend. e.g. s3://my-bucket/caper-cache-dir."
  args: !SimpleFlagArg
    name: AWS_LOC_DIR
- !Flag
  optional: true
  synonyms:
  - --db
  description: Cromwell metadata database type
  args: !SimpleFlagArg
    name: DB
- !Flag
  optional: true
  synonyms:
  - --db-timeout
  description: Milliseconds to wait for DB connection.
  args: !SimpleFlagArg
    name: DB_TIMEOUT
- !Flag
  optional: true
  synonyms:
  - --file-db
  - -d
  description: "Default DB file for Cromwell's built-in HyperSQL\ndatabase."
  args: !SimpleFlagArg
    name: FILE_DB
- !Flag
  optional: true
  synonyms:
  - --mysql-db-ip
  description: MySQL Database IP address (e.g. localhost)
  args: !SimpleFlagArg
    name: MYSQL_DB_IP
- !Flag
  optional: true
  synonyms:
  - --mysql-db-port
  description: MySQL Database TCP/IP port (e.g. 3306)
  args: !SimpleFlagArg
    name: MYSQL_DB_PORT
- !Flag
  optional: true
  synonyms:
  - --mysql-db-user
  description: MySQL DB username
  args: !SimpleFlagArg
    name: MYSQL_DB_USER
- !Flag
  optional: true
  synonyms:
  - --mysql-db-password
  description: MySQL DB password
  args: !SimpleFlagArg
    name: MYSQL_DB_PASSWORD
- !Flag
  optional: true
  synonyms:
  - --mysql-db-name
  description: MySQL DB name for Cromwell
  args: !SimpleFlagArg
    name: MYSQL_DB_NAME
- !Flag
  optional: true
  synonyms:
  - --postgresql-db-ip
  description: PostgreSQL DB IP address (e.g. localhost)
  args: !SimpleFlagArg
    name: POSTGRESQL_DB_IP
- !Flag
  optional: true
  synonyms:
  - --postgresql-db-port
  description: PostgreSQL DB TCP/IP port (e.g. 5432)
  args: !SimpleFlagArg
    name: POSTGRESQL_DB_PORT
- !Flag
  optional: true
  synonyms:
  - --postgresql-db-user
  description: PostgreSQL DB username
  args: !SimpleFlagArg
    name: POSTGRESQL_DB_USER
- !Flag
  optional: true
  synonyms:
  - --postgresql-db-password
  description: PostgreSQL DB password
  args: !SimpleFlagArg
    name: POSTGRESQL_DB_PASSWORD
- !Flag
  optional: true
  synonyms:
  - --postgresql-db-name
  description: PostgreSQL DB name for Cromwell
  args: !SimpleFlagArg
    name: POSTGRESQL_DB_NAME
- !Flag
  optional: true
  synonyms:
  - --cromwell
  description: Path or URL for Cromwell JAR file
  args: !SimpleFlagArg
    name: CROMWELL
- !Flag
  optional: true
  synonyms:
  - --max-concurrent-tasks
  description: "Number of concurrent tasks. \"config.concurrent-job-\nlimit\" in Cromwell\
    \ backend configuration for each\nbackend"
  args: !SimpleFlagArg
    name: MAX_CONCURRENT_TASKS
- !Flag
  optional: true
  synonyms:
  - --max-concurrent-workflows
  description: "Number of concurrent workflows. \"system.max-\nconcurrent-workflows\"\
    \ in backend configuration"
  args: !SimpleFlagArg
    name: MAX_CONCURRENT_WORKFLOWS
- !Flag
  optional: true
  synonyms:
  - --disable-call-caching
  description: "Disable Cromwell's call caching, which re-uses outputs\nfrom previous\
    \ workflows"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --backend-file
  description: "Custom Cromwell backend configuration file to override\nall"
  args: !SimpleFlagArg
    name: BACKEND_FILE
- !Flag
  optional: true
  synonyms:
  - --soft-glob-output
  description: "Use soft-linking when globbing outputs for a\nfilesystem that does\
    \ not allow hard-linking. e.g.\nbeeGFS. This flag does not work with backends\
    \ based on\na Docker container. i.e. gcp and aws. Also, it does\nnot work with\
    \ local backends (local/slurm/sge/pbs)\nwith --. However, it works fine with --singularity."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --local-hash-strat
  description: "{file,path,path+modtime}\nFile hashing strategy for call caching.\
    \ For local\nbackends (local/slurm/sge/pbs) only. file: use md5sum\nhash (slow),\
    \ path: use path only, path+modtime\n(default): use path + mtime."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --local-out-dir
  - --out-dir
  description: "Output directory path for local backend. Cloud\nbackends (gcp, aws)\
    \ use different output directories.\nFor gcp, define --gcp-out-dir. For aws, define\
    \ --aws-\nout-dir."
  args: !SimpleFlagArg
    name: LOCAL_OUT_DIR
- !Flag
  optional: true
  synonyms:
  - --gcp-prj
  description: GC project
  args: !SimpleFlagArg
    name: GCP_PRJ
- !Flag
  optional: true
  synonyms:
  - --gcp-memory-retry-error-keys
  description: "If an error caught by these comma-separated keys\noccurs, then increase\
    \ memory by --gcp-memory-retry-\nmultiplier for retrials controlled by --max-retries.\n\
    See https://cromwell.readthedocs.io/en/stable/backends\n/Google/ for details."
  args: !SimpleFlagArg
    name: GCP_MEMORY_RETRY_ERROR_KEYS
- !Flag
  optional: true
  synonyms:
  - --gcp-memory-retry-multiplier
  description: "If an error caught by --gcp-memory-retry-error-keys\noccurs, then\
    \ increase memory by this for retrials\ncontrolled by --max-retries. See https://cromwell.read\n\
    thedocs.io/en/stable/backends/Google/ for details."
  args: !SimpleFlagArg
    name: GCP_MEMORY_RETRY_MULTIPLIER
- !Flag
  optional: true
  synonyms:
  - --gcp-region
  description: "GCP region for Google Cloud Life Sciences API. This is\nused only\
    \ when --use-google-cloud-life-sciences is\ndefined."
  args: !SimpleFlagArg
    name: GCP_REGION
- !Flag
  optional: true
  synonyms:
  - --gcp-call-caching-dup-strat
  description: "Duplication strategy for call-cached outputs for GCP\nbackend: copy:\
    \ make a copy, reference: refer to old\noutput in metadata.json."
  args: !ChoiceFlagArg
    choices: !!set
      reference:
- !Flag
  optional: true
  synonyms:
  - --gcp-out-dir
  - --out-gcs-bucket
  description: "Output directory path for GCP backend. e.g. gs://my-\nbucket/my-output."
  args: !SimpleFlagArg
    name: GCP_OUT_DIR
- !Flag
  optional: true
  synonyms:
  - --aws-batch-arn
  description: ARN for AWS Batch
  args: !SimpleFlagArg
    name: AWS_BATCH_ARN
- !Flag
  optional: true
  synonyms:
  - --aws-region
  description: AWS region (e.g. us-west-1)
  args: !SimpleFlagArg
    name: AWS_REGION
- !Flag
  optional: true
  synonyms:
  - --aws-out-dir
  - --out-s3-bucket
  description: "Output path on S3 bucket for AWS backend. e.g.\ns3://my-bucket/my-output."
  args: !SimpleFlagArg
    name: AWS_OUT_DIR
- !Flag
  optional: true
  synonyms:
  - --use-google-cloud-life-sciences
  description: "Use Google Cloud Life Sciences API (v2beta) instead of\ndeprecated\
    \ Genomics API (v2alpha1).Life Sciences API\nrequires only one region specified\
    \ withgcp-region.\ngcp-zones will be ignored since it is for Genomics\nAPI.See\
    \ https://cloud.google.com/life-\nsciences/docs/concepts/locations for supported\n\
    regions."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --gcp-zones
  description: "Comma-separated GCP zones used for Genomics API. (e.g.\nus-west1-b,us-central1-b).\
    \ If you use --use-google-\ncloud-life-sciences then define --gcp-region instead.\n"
  args: !SimpleFlagArg
    name: GCP_ZONES
parent:
subcommands: []
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag:
help_text: "usage: caper server [-h] [-c CONF] [-D]\n                    [--gcp-service-account-key-json\
  \ GCP_SERVICE_ACCOUNT_KEY_JSON]\n                    [--local-loc-dir LOCAL_LOC_DIR]\n\
  \                    [--gcp-loc-dir GCP_LOC_DIR] [--aws-loc-dir AWS_LOC_DIR]\n \
  \                   [--port PORT] [--no-server-heartbeat]\n                    [--server-heartbeat-file\
  \ SERVER_HEARTBEAT_FILE]\n                    [--server-heartbeat-timeout SERVER_HEARTBEAT_TIMEOUT]\n\
  \                    [--java-heap-server JAVA_HEAP_SERVER]\n                   \
  \ [--cromwell-stdout CROMWELL_STDOUT] [--db DB]\n                    [--db-timeout\
  \ DB_TIMEOUT] [--file-db FILE_DB]\n                    [--mysql-db-ip MYSQL_DB_IP]\n\
  \                    [--mysql-db-port MYSQL_DB_PORT]\n                    [--mysql-db-user\
  \ MYSQL_DB_USER]\n                    [--mysql-db-password MYSQL_DB_PASSWORD]\n\
  \                    [--mysql-db-name MYSQL_DB_NAME]\n                    [--postgresql-db-ip\
  \ POSTGRESQL_DB_IP]\n                    [--postgresql-db-port POSTGRESQL_DB_PORT]\n\
  \                    [--postgresql-db-user POSTGRESQL_DB_USER]\n               \
  \     [--postgresql-db-password POSTGRESQL_DB_PASSWORD]\n                    [--postgresql-db-name\
  \ POSTGRESQL_DB_NAME]\n                    [--cromwell CROMWELL]\n             \
  \       [--max-concurrent-tasks MAX_CONCURRENT_TASKS]\n                    [--max-concurrent-workflows\
  \ MAX_CONCURRENT_WORKFLOWS]\n                    [--disable-call-caching] [--backend-file\
  \ BACKEND_FILE]\n                    [--soft-glob-output]\n                    [--local-hash-strat\
  \ {file,path,path+modtime}]\n                    [--local-out-dir LOCAL_OUT_DIR]\
  \ [--gcp-prj GCP_PRJ]\n                    [--gcp-memory-retry-error-keys GCP_MEMORY_RETRY_ERROR_KEYS]\n\
  \                    [--gcp-memory-retry-multiplier GCP_MEMORY_RETRY_MULTIPLIER]\n\
  \                    [--gcp-region GCP_REGION]\n                    [--gcp-call-caching-dup-strat\
  \ {reference,reference}]\n                    [--gcp-out-dir GCP_OUT_DIR]\n    \
  \                [--aws-batch-arn AWS_BATCH_ARN] [--aws-region AWS_REGION]\n   \
  \                 [--aws-out-dir AWS_OUT_DIR] [-b BACKEND] [--dry-run]\n       \
  \             [--use-google-cloud-life-sciences] [--gcp-zones GCP_ZONES]\n\noptional\
  \ arguments:\n  -h, --help            show this help message and exit\n  -c CONF,\
  \ --conf CONF  Specify config file\n  -D, --debug           Prints all logs >= DEBUG\
  \ level\n  --gcp-service-account-key-json GCP_SERVICE_ACCOUNT_KEY_JSON\n       \
  \                 Secret key JSON file for Google Cloud Platform service\n     \
  \                   account. This service account should have enough\n         \
  \               permission to Storage for client functions and\n               \
  \         Storage/Compute Engine/Genomics API/Life Sciences API\n              \
  \          for server/runner functions.\n  --port PORT           Port for Caper\
  \ server\n  --no-server-heartbeat\n                        Disable server heartbeat\
  \ file.\n  --server-heartbeat-file SERVER_HEARTBEAT_FILE\n                     \
  \   Heartbeat file for Caper clients to get IP and port of\n                   \
  \     a server\n  --server-heartbeat-timeout SERVER_HEARTBEAT_TIMEOUT\n        \
  \                Timeout for a heartbeat file in Milliseconds. A\n             \
  \           heartbeat file older than this interval will be\n                  \
  \      ignored.\n  --java-heap-server JAVA_HEAP_SERVER\n                       \
  \ Cromwell Java heap size for \"server\" mode (java -Xmx)\n  --cromwell-stdout CROMWELL_STDOUT\n\
  \                        Local file to write STDOUT of Cromwell Java process\n \
  \                       to. This is for Cromwell (not for Caper's logging\n    \
  \                    system). Note that STDERR is redirected to STDOUT.\n  -b BACKEND,\
  \ --backend BACKEND\n                        Backend to run a workflow\n  --dry-run\
  \             Caper localizes remote files and validates WDL but\n             \
  \           does not run/submit a pipeline.\n\ncache directories for localization:\n\
  \  --local-loc-dir LOCAL_LOC_DIR, --tmp-dir LOCAL_LOC_DIR\n                    \
  \    Temporary directory to store Cromwell's intermediate\n                    \
  \    backend files. These files include backend.conf,\n                        workflow_opts.json,\
  \ imports.zip. and localized input\n                        JSON files due to deepcopying\
  \ (recursive\n                        localization). Cromwell's MySQL/PostgreSQL\
  \ DB password\n                        can be exposed on backend.conf on this directory.\n\
  \                        Therefore, DO NOT USE /tmp HERE. This directory is\n  \
  \                      also used for storing cached files for\n                \
  \        local/slurm/sge/pbs backends.\n  --gcp-loc-dir GCP_LOC_DIR, --tmp-gcs-bucket\
  \ GCP_LOC_DIR\n                        Temporary directory to store cached files\
  \ for gcp\n                        backend. e.g. gs://my-bucket/caper-cache-dir.\n\
  \  --aws-loc-dir AWS_LOC_DIR, --tmp-s3-bucket AWS_LOC_DIR\n                    \
  \    Temporary directory to store cached files for aws\n                       \
  \ backend. e.g. s3://my-bucket/caper-cache-dir.\n\nGeneral DB settings (for both\
  \ file DB and MySQL DB):\n  --db DB               Cromwell metadata database type\n\
  \  --db-timeout DB_TIMEOUT\n                        Milliseconds to wait for DB\
  \ connection.\n\nHyperSQL file DB arguments (unstable, not recommended):\n  --file-db\
  \ FILE_DB, -d FILE_DB\n                        Default DB file for Cromwell's built-in\
  \ HyperSQL\n                        database.\n\nMySQL DB arguments:\n  --mysql-db-ip\
  \ MYSQL_DB_IP\n                        MySQL Database IP address (e.g. localhost)\n\
  \  --mysql-db-port MYSQL_DB_PORT\n                        MySQL Database TCP/IP\
  \ port (e.g. 3306)\n  --mysql-db-user MYSQL_DB_USER\n                        MySQL\
  \ DB username\n  --mysql-db-password MYSQL_DB_PASSWORD\n                       \
  \ MySQL DB password\n  --mysql-db-name MYSQL_DB_NAME\n                        MySQL\
  \ DB name for Cromwell\n\nPostgreSQL DB arguments:\n  --postgresql-db-ip POSTGRESQL_DB_IP\n\
  \                        PostgreSQL DB IP address (e.g. localhost)\n  --postgresql-db-port\
  \ POSTGRESQL_DB_PORT\n                        PostgreSQL DB TCP/IP port (e.g. 5432)\n\
  \  --postgresql-db-user POSTGRESQL_DB_USER\n                        PostgreSQL DB\
  \ username\n  --postgresql-db-password POSTGRESQL_DB_PASSWORD\n                \
  \        PostgreSQL DB password\n  --postgresql-db-name POSTGRESQL_DB_NAME\n   \
  \                     PostgreSQL DB name for Cromwell\n\nCromwell settings:\n  --cromwell\
  \ CROMWELL   Path or URL for Cromwell JAR file\n  --max-concurrent-tasks MAX_CONCURRENT_TASKS\n\
  \                        Number of concurrent tasks. \"config.concurrent-job-\n\
  \                        limit\" in Cromwell backend configuration for each\n  \
  \                      backend\n  --max-concurrent-workflows MAX_CONCURRENT_WORKFLOWS\n\
  \                        Number of concurrent workflows. \"system.max-\n       \
  \                 concurrent-workflows\" in backend configuration\n  --disable-call-caching\n\
  \                        Disable Cromwell's call caching, which re-uses outputs\n\
  \                        from previous workflows\n  --backend-file BACKEND_FILE\n\
  \                        Custom Cromwell backend configuration file to override\n\
  \                        all\n  --soft-glob-output    Use soft-linking when globbing\
  \ outputs for a\n                        filesystem that does not allow hard-linking.\
  \ e.g.\n                        beeGFS. This flag does not work with backends based\
  \ on\n                        a Docker container. i.e. gcp and aws. Also, it does\n\
  \                        not work with local backends (local/slurm/sge/pbs)\n  \
  \                      with --. However, it works fine with --singularity.\n  --local-hash-strat\
  \ {file,path,path+modtime}\n                        File hashing strategy for call\
  \ caching. For local\n                        backends (local/slurm/sge/pbs) only.\
  \ file: use md5sum\n                        hash (slow), path: use path only, path+modtime\n\
  \                        (default): use path + mtime.\n\nlocal backend arguments:\n\
  \  --local-out-dir LOCAL_OUT_DIR, --out-dir LOCAL_OUT_DIR\n                    \
  \    Output directory path for local backend. Cloud\n                        backends\
  \ (gcp, aws) use different output directories.\n                        For gcp,\
  \ define --gcp-out-dir. For aws, define --aws-\n                        out-dir.\n\
  \nGCP backend arguments for server/runner:\n  --gcp-prj GCP_PRJ     GC project\n\
  \  --gcp-memory-retry-error-keys GCP_MEMORY_RETRY_ERROR_KEYS\n                 \
  \       If an error caught by these comma-separated keys\n                     \
  \   occurs, then increase memory by --gcp-memory-retry-\n                      \
  \  multiplier for retrials controlled by --max-retries.\n                      \
  \  See https://cromwell.readthedocs.io/en/stable/backends\n                    \
  \    /Google/ for details.\n  --gcp-memory-retry-multiplier GCP_MEMORY_RETRY_MULTIPLIER\n\
  \                        If an error caught by --gcp-memory-retry-error-keys\n \
  \                       occurs, then increase memory by this for retrials\n    \
  \                    controlled by --max-retries. See https://cromwell.read\n  \
  \                      thedocs.io/en/stable/backends/Google/ for details.\n  --gcp-region\
  \ GCP_REGION\n                        GCP region for Google Cloud Life Sciences\
  \ API. This is\n                        used only when --use-google-cloud-life-sciences\
  \ is\n                        defined.\n  --gcp-call-caching-dup-strat {reference,reference}\n\
  \                        Duplication strategy for call-cached outputs for GCP\n\
  \                        backend: copy: make a copy, reference: refer to old\n \
  \                       output in metadata.json.\n  --gcp-out-dir GCP_OUT_DIR, --out-gcs-bucket\
  \ GCP_OUT_DIR\n                        Output directory path for GCP backend. e.g.\
  \ gs://my-\n                        bucket/my-output.\n\nAWS backend arguments:\n\
  \  --aws-batch-arn AWS_BATCH_ARN\n                        ARN for AWS Batch\n  --aws-region\
  \ AWS_REGION\n                        AWS region (e.g. us-west-1)\n  --aws-out-dir\
  \ AWS_OUT_DIR, --out-s3-bucket AWS_OUT_DIR\n                        Output path\
  \ on S3 bucket for AWS backend. e.g.\n                        s3://my-bucket/my-output.\n\
  \nGCP backend arguments for server/runner/client:\n  --use-google-cloud-life-sciences\n\
  \                        Use Google Cloud Life Sciences API (v2beta) instead of\n\
  \                        deprecated Genomics API (v2alpha1).Life Sciences API\n\
  \                        requires only one region specified withgcp-region.\n  \
  \                      gcp-zones will be ignored since it is for Genomics\n    \
  \                    API.See https://cloud.google.com/life-\n                  \
  \      sciences/docs/concepts/locations for supported\n                        regions.\n\
  \  --gcp-zones GCP_ZONES\n                        Comma-separated GCP zones used\
  \ for Genomics API. (e.g.\n                        us-west1-b,us-central1-b). If\
  \ you use --use-google-\n                        cloud-life-sciences then define\
  \ --gcp-region instead.\n"
generated_using:
- --help
docker_image: quay.io/biocontainers/caper:1.1.0--py_0
