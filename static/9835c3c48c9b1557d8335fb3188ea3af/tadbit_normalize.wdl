version 1.0

task TadbitNormalize {
  input {
    File? workdir
    Int? resolution
    File? bam
    Int? jobid
    Int? max_n_jobs
    Boolean? force
    File? tmp_db
    Int? cpus
    Boolean? normalize_only
    Boolean? nox
    Float? perc_zeros
    Int? min_count
    Int? min_perc
    Int? max_perc
    Boolean? filter_only
    Boolean? fast_filter
    Int? pospos_extra_regions
    Array[Int] filter
    Boolean? valid
    String? normalization
    File? biases_path
    File? mapp_ability
    File? fast_a
    String? renz
    Int? factor
    Float? prop_data
    Int? seed
  }
  command <<<
    tadbit normalize \
      ~{if defined(workdir) then ("--workdir " +  '"' + workdir + '"') else ""} \
      ~{if defined(resolution) then ("--resolution " +  '"' + resolution + '"') else ""} \
      ~{if defined(bam) then ("--bam " +  '"' + bam + '"') else ""} \
      ~{if defined(jobid) then ("--jobid " +  '"' + jobid + '"') else ""} \
      ~{if defined(max_n_jobs) then ("--max_njobs " +  '"' + max_n_jobs + '"') else ""} \
      ~{if (force) then "--force" else ""} \
      ~{if defined(tmp_db) then ("--tmpdb " +  '"' + tmp_db + '"') else ""} \
      ~{if defined(cpus) then ("--cpus " +  '"' + cpus + '"') else ""} \
      ~{if (normalize_only) then "--normalize_only" else ""} \
      ~{if (nox) then "--noX" else ""} \
      ~{if defined(perc_zeros) then ("--perc_zeros " +  '"' + perc_zeros + '"') else ""} \
      ~{if defined(min_count) then ("--min_count " +  '"' + min_count + '"') else ""} \
      ~{if defined(min_perc) then ("--min_perc " +  '"' + min_perc + '"') else ""} \
      ~{if defined(max_perc) then ("--max_perc " +  '"' + max_perc + '"') else ""} \
      ~{if (filter_only) then "--filter_only" else ""} \
      ~{if (fast_filter) then "--fast_filter" else ""} \
      ~{if defined(pospos_extra_regions) then ("-B " +  '"' + pospos_extra_regions + '"') else ""} \
      ~{if defined(filter) then ("--filter " +  '"' + filter + '"') else ""} \
      ~{if (valid) then "--valid" else ""} \
      ~{if defined(normalization) then ("--normalization " +  '"' + normalization + '"') else ""} \
      ~{if defined(biases_path) then ("--biases_path " +  '"' + biases_path + '"') else ""} \
      ~{if defined(mapp_ability) then ("--mappability " +  '"' + mapp_ability + '"') else ""} \
      ~{if defined(fast_a) then ("--fasta " +  '"' + fast_a + '"') else ""} \
      ~{if defined(renz) then ("--renz " +  '"' + renz + '"') else ""} \
      ~{if defined(factor) then ("--factor " +  '"' + factor + '"') else ""} \
      ~{if defined(prop_data) then ("--prop_data " +  '"' + prop_data + '"') else ""} \
      ~{if defined(seed) then ("--seed " +  '"' + seed + '"') else ""}
  >>>
  parameter_meta {
    workdir: "path to working directory (generated with the tool tadbit mapper)"
    resolution: "resolution at which to output matrices"
    bam: "path to a TADbit-generated BAM file with all reads (other wise the\\ntool will guess from the working directory database)"
    jobid: "Use as input data generated by a job with a given jobid. Use tadbit\\ndescribe to find out which."
    max_n_jobs: "[100] Define maximum number of jobs for reading BAM file (set to\\nhigher numbers for large files and low RAM memory)."
    force: "overwrite previously run job"
    tmp_db: "if provided uses this directory to manipulate the database"
    cpus: "[8] Maximum number of CPU cores available in the execution host. If\\nhigher than 1, tasks with multi-threading capabilities will enabled\\n(if 0 all available) cores will be used"
    normalize_only: "skip calculation of Cis-percentage and decay"
    nox: "no display server (X screen)"
    perc_zeros: "[95%] maximum percentage of zeroes allowed per column."
    min_count: "[None] minimum number of reads mapped to a bin (recommended value\\ncould be 2500). If set this option overrides the perc_zero\\nfiltering... This option is slightly slower."
    min_perc: "[None] lower percentile from which consider bins as good."
    max_perc: "[None] upper percentile until which consider bins as good."
    filter_only: "skip normalization"
    fast_filter: "only filter according to the percentage of zero count or minimum\\ncount of reads"
    pospos_extra_regions: ":POS1-POS2 [CHR:POS1-POS2 ...], --badcols CHR:POS1-POS2 [CHR:POS1-POS2 ...]\\nextra regions to be added to bad-columns (ingenomic position). e.g.:\\n--badcols 1:150000000-160000000 2:1200000-1300000"
    filter: "[[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set os valid\\npair of reads e.g.: '--apply 1 2 3 4 8 9 10'. Where these\\nnumberscorrespond to: 1: self-circle, 2: dangling-end, 3: error, 4:\\nextra dangling-end, 5: too close from RES, 6: too short, 7: too\\nlarge, 8: over-represented, 9: duplicated, 10: random breaks, 11:\\ntrans-chromosomic"
    valid: "input BAM file contains only valid pairs (already filtered)."
    normalization: "[Vanilla] normalization(s) to apply. Order matters. Choices:\\nVanilla, ICE, SQRT, oneD, custom"
    biases_path: "biases file to compute decay. REQUIRED with \\\"custom\\\" normalization.\\nFormat: single column with header"
    mapp_ability: "Path to mappability bedGraph file, required for oneD normalization.\\nMappability file can be generated with GEM (example from the genomic FASTA file hg38.fa):\\ngem-indexer -i hg38.fa -o hg38\\ngem-mappability -I hg38.gem -l 50 -o hg38.50mer -T 8\\ngem-2-wig -I hg38.gem -i hg38.50mer.mappability -o hg38.50mer\\nwigToBigWig hg38.50mer.wig hg38.50mer.sizes hg38.50mer.bw\\nbigWigToBedGraph hg38.50mer.bw  hg38.50mer.bedGraph"
    fast_a: "Path to FASTA file with genome sequence, to compute GC content and\\nnumber of restriction sites per bin. Required for oneD normalization"
    renz: "restriction enzyme name(s). Required for oneD normalization"
    factor: "[1] target mean value of a cell after normalization (can be used to\\nweight experiments before merging)"
    prop_data: "[1] Only for oneD normalization: proportion of data to be used in\\nfitting (for very large datasets). Number between 0 and 1."
    seed: "[1] Only for oneD normalization: seed number for the random picking\\nof data when using the \\\"prop_data\\\" parameter\\n"
  }
  output {
    File out_stdout = stdout()
  }
}