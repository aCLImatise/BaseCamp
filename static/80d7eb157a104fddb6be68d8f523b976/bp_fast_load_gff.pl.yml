!Command
command:
- bp_fast_load_gff.pl
positional:
- !Positional
  optional: false
  position: 0
  name: NOTES
  description: "If the filename is given as \"-\" then the input is taken from standard\n\
    input. Compressed files (.gz, .Z, .bz2) are automatically uncompressed.\nFASTA\
    \ format files are distinguished from GFF files by their filename\nextensions.\
    \ Files ending in .fa, .fasta, .fast, .seq, .dna and their\nuppercase variants\
    \ are treated as FASTA files. Everything else is\ntreated as a GFF file. If you\
    \ wish to load -fasta files from STDIN, then\nuse the -f command-line swith with\
    \ an argument of '-', as in\ngunzip my_data.fa.gz | bp_fast_load_gff.pl -d test\
    \ -f -\nThe nature of the load requires that the database be on the local\nmachine\
    \ and that the indicated user have the \"file\" privilege to load\nthe tables\
    \ and have enough room in /usr/tmp (or whatever is specified by\nthe \\$TMPDIR\
    \ environment variable), to hold the tables transiently. If\nyour MySQL is version\
    \ 3.22.6 and was compiled using the \"load local\nfile\" option, then you may\
    \ be able to load remote databases with local\ndata using the --local option.\n\
    About maxfeature: the default value is 100,000,000 bases. If you have\nfeatures\
    \ that are close to or greater that 100Mb in length, then the\nvalue of maxfeature\
    \ should be increased to 1,000,000,000. This value\nmust be a power of 10.\nIf\
    \ the list of GFF or fasta files exceeds the kernel limit for the\nmaximum number\
    \ of command-line arguments, use the --long_list\n/path/to/files option.\nThe\
    \ adaptor used is dbi::mysqlopt. There is currently no way to change\nthis."
named:
- !Flag
  optional: true
  synonyms:
  - -d
  description: of --database.
  args: !SimpleFlagArg
    name: instead
- !Flag
  optional: true
  synonyms:
  - --database
  description: Mysql database name
  args: !SimpleFlagArg
    name: dsn
- !Flag
  optional: true
  synonyms:
  - --create
  description: Reinitialize/create data tables without asking
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --local
  description: Try to load a remote database using local data.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --user
  description: Username to log in as
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --fasta
  description: File or directory containing fasta files to load
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --password
  description: Password to use for authentication
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --long_list
  description: "Directory containing a very large number of\nGFF and/or FASTA files"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxfeature
  description: Set the value of the maximum feature size (default 100Mb; must be a
    power of 10)
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --group
  description: "A list of one or more tag names (comma or space separated)\nto be\
    \ used for grouping in the 9th column."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --gff3_munge
  description: Activate GFF3 name munging (see Bio::DB::GFF)
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --summary
  description: "Generate summary statistics for drawing coverage histograms.\nThis\
    \ can be run on a previously loaded database or during\nthe load."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --Temporary
  description: Location of a writable scratch directory
  args: !EmptyFlagArg {}
parent:
subcommands: []
usage: []
help_flag:
usage_flag:
version_flag:
help_text: "NAME\n    bp_fast_load_gff.pl - Fast-load a Bio::DB::GFF database from\
  \ GFF files.\n\nSYNOPSIS\n      % bp_fast_load_gff.pl -d testdb dna1.fa dna2.fa\
  \ features1.gff features2.gff ...\n\nDESCRIPTION\n    This script loads a Bio::DB::GFF\
  \ database with the features contained in\n    a list of GFF files and/or FASTA\
  \ sequence files. You must use the exact\n    variant of GFF described in Bio::DB::GFF.\
  \ Various command-line options\n    allow you to control which database to load\
  \ and whether to allow an\n    existing database to be overwritten.\n\n    This\
  \ script is similar to load_gff.pl, but is much faster. However, it\n    is hard-coded\
  \ to use MySQL and probably only works on Unix platforms due\n    to its reliance\
  \ on pipes. See bp_load_gff.pl for an incremental loader\n    that works with all\
  \ databases supported by Bio::DB::GFF, and\n    bp_bulk_load_gff.pl for a fast MySQL\
  \ loader that supports all platforms.\n\n  NOTES\n    If the filename is given as\
  \ \"-\" then the input is taken from standard\n    input. Compressed files (.gz,\
  \ .Z, .bz2) are automatically uncompressed.\n\n    FASTA format files are distinguished\
  \ from GFF files by their filename\n    extensions. Files ending in .fa, .fasta,\
  \ .fast, .seq, .dna and their\n    uppercase variants are treated as FASTA files.\
  \ Everything else is\n    treated as a GFF file. If you wish to load -fasta files\
  \ from STDIN, then\n    use the -f command-line swith with an argument of '-', as\
  \ in\n\n        gunzip my_data.fa.gz | bp_fast_load_gff.pl -d test -f -\n\n    The\
  \ nature of the load requires that the database be on the local\n    machine and\
  \ that the indicated user have the \"file\" privilege to load\n    the tables and\
  \ have enough room in /usr/tmp (or whatever is specified by\n    the \\$TMPDIR environment\
  \ variable), to hold the tables transiently. If\n    your MySQL is version 3.22.6\
  \ and was compiled using the \"load local\n    file\" option, then you may be able\
  \ to load remote databases with local\n    data using the --local option.\n\n  \
  \  About maxfeature: the default value is 100,000,000 bases. If you have\n    features\
  \ that are close to or greater that 100Mb in length, then the\n    value of maxfeature\
  \ should be increased to 1,000,000,000. This value\n    must be a power of 10.\n\
  \n    If the list of GFF or fasta files exceeds the kernel limit for the\n    maximum\
  \ number of command-line arguments, use the --long_list\n    /path/to/files option.\n\
  \n    The adaptor used is dbi::mysqlopt. There is currently no way to change\n \
  \   this.\n\nCOMMAND-LINE OPTIONS\n    Command-line options can be abbreviated to\
  \ single-letter options. e.g.\n    -d instead of --database.\n\n       --database\
  \ <dsn>      Mysql database name\n       --create              Reinitialize/create\
  \ data tables without asking\n       --local               Try to load a remote\
  \ database using local data.\n       --user                Username to log in as\n\
  \       --fasta               File or directory containing fasta files to load\n\
  \       --password            Password to use for authentication\n       --long_list\
  \           Directory containing a very large number of\n                      \
  \       GFF and/or FASTA files\n       --maxfeature          Set the value of the\
  \ maximum feature size (default 100Mb; must be a power of 10)\n       --group  \
  \             A list of one or more tag names (comma or space separated)\n     \
  \                        to be used for grouping in the 9th column.\n       --gff3_munge\
  \          Activate GFF3 name munging (see Bio::DB::GFF)\n       --summary     \
  \        Generate summary statistics for drawing coverage histograms.\n        \
  \                       This can be run on a previously loaded database or during\n\
  \                               the load.\n       --Temporary           Location\
  \ of a writable scratch directory\n\nSEE ALSO\n    Bio::DB::GFF, bulk_load_gff.pl,\
  \ load_gff.pl\n\nAUTHOR\n    Lincoln Stein, lstein@cshl.org\n\n    Copyright (c)\
  \ 2002 Cold Spring Harbor Laboratory\n\n    This library is free software; you can\
  \ redistribute it and/or modify it\n    under the same terms as Perl itself. See\
  \ DISCLAIMER.txt for disclaimers\n    of warranty.\n\n"
generated_using:
- --help
docker_image:
