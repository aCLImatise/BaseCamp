!Command
positional: []
named:
- !Flag
  description: Print help, including all details and hidden  options, and exit
  synonyms:
  - --detailed-help
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Print help, including hidden options, and exit
  synonyms:
  - --full-help
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Reference FASTA file (MUST have .fai index  file)
  synonyms:
  - -F
  - --referenceFASTA
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Matrix of *input* read-depths, where rows  (samples) and columns (targets)
    are labeled   (default=`-')
  synonyms:
  - -r
  - --readDepths
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: --targets=STRING          Input targets lists --mergedTargets=STRING    Output
    targets list  (default=`-')
  synonyms:
  - -S
  - --prepareTargets
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "--GATKdepths=STRING       GATK sample_interval_summary output file(s)\
    \ to  be merged [must have *IDENTICAL* target  lists] --GATKdepthsList=STRING\
    \   A file containing a list of GATK  sample_interval_summary output files to\
    \ be  merged [must have *IDENTICAL* target lists] --sampleIDmap=STRING      File\
    \ containing mappings of sample names to new  sample names (in columns designated\
    \ by  fromID, toID) --fromID=INT              Column number of OLD sample IDs\
    \ to map   (default=`1') --toID=INT                Column number of NEW sample\
    \ IDs to map   (default=`2') --columnSuffix=STRING     Suffix of columns to be\
    \ used for merging [where  columns are in the form: SAMPLE +  columnSuffix]  (default=`_mean_cvg')\
    \ --rdPrecision=INT         Decimal precision of read depths output   (default=`2')\
    \ --outputTargetsBySamples  Output targets x samples (instead of samples x  targets)\
    \  (default=off)"
  synonyms:
  - -A
  - --mergeGATKdepths
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: --excludeTargets=STRING   File(s) of targets to exclude --excludeChromosomeTargets=STRING
    Target chromosome(s) to exclude --excludeSamples=STRING   File(s) of samples to
    exclude --minTargetSize=INT       Minimum size of target (in bp) to process   (default=`0')
    --maxTargetSize=INT       Maximum size of target (in bp) to process --minMeanTargetRD=DOUBLE  Minimum
    per-target mean RD to require for  target to be processed --maxMeanTargetRD=DOUBLE  Maximum
    per-target mean RD to require for  target to be processed --minSdTargetRD=DOUBLE    Minimum
    per-target standard deviation of RD to  require for target to be processed   (default=`0')
    --maxSdTargetRD=DOUBLE    Maximum per-target standard deviation of RD to  require
    for target to be processed --minMeanSampleRD=DOUBLE  Minimum per-sample mean RD
    to require for  sample to be processed --maxMeanSampleRD=DOUBLE  Maximum per-sample
    mean RD to require for  sample to be processed --minSdSampleRD=DOUBLE    Minimum
    per-sample standard deviation of RD to  require for sample to be processed   (default=`0')
    --maxSdSampleRD=DOUBLE    Maximum per-sample standard deviation of RD to  require
    for sample to be processed --scaleDataBySum          After any filtering, scale
    read-depth matrix  values by sample- or target- sums (as per  --scaleDataBySumType)
    [i.e., divide by row or  column sums], but multiply by factor  specificied by
    --scaleDataBySumFactor   (default=off) --scaleDataBySumType=ENUM If --scaleDataBySum
    given, then scale the data  within this dimension  (possible  values="target",
    "sample") --scaleDataBySumFactor=DOUBLE If --scaleDataBySum given, then divide
    by  appropriate sum (but multiply by this factor)  (default=`1e6') --log10=DOUBLE            After
    any filtering and optional scaling steps  (but before any optional centering steps),  convert
    the matrix to log10 values. To deal  with non-positive and small positive values,  a
    truncation and then pseudocount approach is  taken. Specifically, denote the original  matrix
    value as x and this parameter's  pseudocount value as v (say, 0.5). The matrix  value
    used is then log10(max(x, 0) + v) --centerData              Output sample- or
    target- centered read-depth  matrix (as per --centerType)  (default=off) --centerType=ENUM         If
    --centerData given, then center the data  around this dimension  (possible  values="target",
    "sample") --zScoreData              If --centerData given, then additionally  normalize
    by standard deviation (outputting  z-scores)  (default=off) --outputExcludedTargets=STRING
    File in which to output targets excluded by  some criterion --outputExcludedSamples=STRING
    File in which to output samples excluded by  some criterion
  synonyms:
  - -M
  - --matrix
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Read-depth matrix output file  (default=`-')
  synonyms:
  - -o
  - --outputMatrix
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Matrix is read from --readDepths argument;  normalization factors sent
    to --PCAfiles  argument
  synonyms:
  - -P
  - --PCA
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "[=STRING] Should XHMM save memory by storing some of the  intermediate\
    \ PCA matrices as temporary files  on disk?  (default=`')"
  synonyms:
  - --PCA_saveMemory
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Matrix is read from --readDepths argument;  normalization factors read
    from --PCAfiles  argument
  synonyms:
  - -N
  - --normalize
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: Normalized read-depth matrix output file   (default=`-')
  synonyms:
  - -n
  - --normalizeOutput
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Method to choose which prinicipal components  are removed for data
    normalization  (possible  values="numPCtoRemove", "PVE_mean",  "PVE_contrib" default=`PVE_mean')
  synonyms:
  - --PCnormalizeMethod
  args: !SimpleFlagArg
    name: ENUM
  optional: true
- !Flag
  description: Number of highest principal components to  filter out  (default=`20')
  synonyms:
  - --numPCtoRemove
  args: !SimpleFlagArg
    name: INT
  optional: true
- !Flag
  description: Remove all principal components that  individually explain more variance
    than this  factor times the average (in the original  PCA-ed data)  (default=`0.7')
  synonyms:
  - --PVE_mean_factor
  args: !SimpleFlagArg
    name: DOUBLE
  optional: true
- !Flag
  description: Remove the smallest number of principal  components that explain this
    percent of the  variance (in the original PCA-ed data)   (default=`50')
  synonyms:
  - --PVE_contrib
  args: !SimpleFlagArg
    name: DOUBLE
  optional: true
- !Flag
  description: Base file name for 'PCA' *output*, and  'normalize' *input*
  synonyms:
  - --PCAfiles
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Matrix is read from --readDepths argument
  synonyms:
  - -D
  - --discover
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: CNV output file  (default=`-')
  synonyms:
  - -c
  - --xcnv
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Quality threshold for discovering a CNV in a  sample  (default=`30')
  synonyms:
  - -t
  - --discoverSomeQualThresh
  args: !SimpleFlagArg
    name: DOUBLE
  optional: true
- !Flag
  description: Base file name for posterior probabilities  output files; if not given,
    and --xcnv is not  '-', this will default to --xcnv argument
  synonyms:
  - -s
  - --posteriorFiles
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Matrix is read from --readDepths argument
  synonyms:
  - -G
  - --genotype
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: xhmm CNV input file to genotype in 'readDepths'  sample
  synonyms:
  - -g
  - --gxcnv
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: In addition to genotyping the intervals  specified in gxcnv, genotype
    all sub-segments  of these intervals (with  maxTargetsInSubsegment or fewer targets)   (default=off)
  synonyms:
  - --subsegments
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: When genotyping sub-segments of input  intervals, only consider sub-segments  consisting
    of this number of targets or fewer  (default=`30')
  synonyms:
  - --maxTargetsInSubsegment
  args: !SimpleFlagArg
    name: INT
  optional: true
- !Flag
  description: Quality threshold for calling a genotype, used  *ONLY* when 'gxcnv'
    does not contain the  'Q_EXACT' field for the interval being  genotyped  (default=`20')
  synonyms:
  - -T
  - --genotypeQualThresholdWhenNoExact
  args: !SimpleFlagArg
    name: DOUBLE
  optional: true
- !Flag
  description: VCF file(s) to be merged [must have *IDENTICAL*  genotyped intervals]
  synonyms:
  - --mergeVCF
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: A file containing a list of VCF files to be  merged [must have *IDENTICAL*
    genotyped  intervals]
  synonyms:
  - --mergeVCFlist
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: (Initial) model parameters file
  synonyms:
  - -p
  - --paramFile
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Value at which to cap the absolute value of  *normalized* input read
    depth values  ('readDepths')  (default=`10')
  synonyms:
  - -m
  - --maxNormalizedReadDepthVal
  args: !SimpleFlagArg
    name: DOUBLE
  optional: true
- !Flag
  description: Value at which to cap the calculated quality  scores  (default=`99')
  synonyms:
  - -q
  - --maxQualScore
  args: !SimpleFlagArg
    name: DOUBLE
  optional: true
- !Flag
  description: Decimal precision of quality scores   (default=`0')
  synonyms:
  - -e
  - --scorePrecision
  args: !SimpleFlagArg
    name: INT
  optional: true
- !Flag
  description: Auxiliary CNV output file (may be VERY LARGE in  'genotype' mode)
  synonyms:
  - -a
  - --aux_xcnv
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Number of targets to print upstream of CNV in  'auxOutput' file  (default=`2')
  synonyms:
  - -u
  - --auxUpstreamPrintTargs
  args: !SimpleFlagArg
    name: INT
  optional: true
- !Flag
  description: Number of targets to print downstream of CNV in  'auxOutput' file  (default=`2')
  synonyms:
  - -w
  - --auxDownstreamPrintTargs
  args: !SimpleFlagArg
    name: INT
  optional: true
- !Flag
  description: Matrix of unnormalized read-depths to use for  CNV annotation, where
    rows (samples) and  columns (targets) are labeled
  synonyms:
  - -R
  - --origReadDepths
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: File containing a list of samples to be  analyzed
  synonyms:
  - --keepSampleIDs
  args: !SimpleFlagArg
    name: STRING
  optional: true
- !Flag
  description: Genotyped CNV output VCF file  (default=`-')
  synonyms:
  - -v
  - --vcf
  args: !SimpleFlagArg
    name: STRING
  optional: true
command:
- xhmm
parent:
subcommands: []
help_flag: !Flag
  description: Print help and exit
  synonyms:
  - -h
  - --help
  args: !EmptyFlagArg {}
  optional: true
usage_flag:
version_flag: !Flag
  description: Print version and exit
  synonyms:
  - -V
  - --version
  args: !EmptyFlagArg {}
  optional: true
help_text: "xhmm 1.0\n\nUses principal component analysis (PCA) normalization and\
  \ a hidden Markov model \n(HMM) to detect and genotype copy number variation (CNV)\
  \ from normalized \nread-depth data from targeted sequencing experiments.\n\nUsage:\
  \ xhmm [OPTIONS]...\n\nDeveloped by Menachem Fromer and Shaun Purcell\n\n  -h, --help\
  \                    Print help and exit\n      --detailed-help           Print\
  \ help, including all details and hidden \n                                  options,\
  \ and exit\n      --full-help               Print help, including hidden options,\
  \ and exit\n  -V, --version                 Print version and exit\n\n*******************************************************************\n\
  Options for modes: 'prepareTargets', 'genotype':\n  -F, --referenceFASTA=STRING\
  \   Reference FASTA file (MUST have .fai index \n                              \
  \    file)\n\n*******************************************************************\n\
  Options for modes: 'matrix', 'PCA', 'normalize', 'discover', 'genotype':\n  -r,\
  \ --readDepths=STRING       Matrix of *input* read-depths, where rows \n       \
  \                           (samples) and columns (targets) are labeled  \n    \
  \                              (default=`-')\n*******************************************************************\n\
  \n Mode: prepareTargets\n  Sort all target intervals, merge overlapping ones, and\
  \ print the resulting \n  interval list\n  -S, --prepareTargets          \n    \
  \  --targets=STRING          Input targets lists\n      --mergedTargets=STRING \
  \   Output targets list  (default=`-')\n\n Mode: mergeGATKdepths\n  Merge the output\
  \ from GATK into a single read depth matrix of samples (rows) \n  by targets (columns)\n\
  \  -A, --mergeGATKdepths         \n      --GATKdepths=STRING       GATK sample_interval_summary\
  \ output file(s) to \n                                  be merged [must have *IDENTICAL*\
  \ target \n                                  lists]\n      --GATKdepthsList=STRING\
  \   A file containing a list of GATK \n                                  sample_interval_summary\
  \ output files to be \n                                  merged [must have *IDENTICAL*\
  \ target lists]\n      --sampleIDmap=STRING      File containing mappings of sample\
  \ names to new \n                                  sample names (in columns designated\
  \ by \n                                  fromID, toID)\n      --fromID=INT     \
  \         Column number of OLD sample IDs to map  \n                           \
  \       (default=`1')\n      --toID=INT                Column number of NEW sample\
  \ IDs to map  \n                                  (default=`2')\n      --columnSuffix=STRING\
  \     Suffix of columns to be used for merging [where \n                       \
  \           columns are in the form: SAMPLE + \n                               \
  \   columnSuffix]  (default=`_mean_cvg')\n      --rdPrecision=INT         Decimal\
  \ precision of read depths output  \n                                  (default=`2')\n\
  \      --outputTargetsBySamples  Output targets x samples (instead of samples x\
  \ \n                                  targets)  (default=off)\n\n Mode: matrix\n\
  \  Process (filter, center, etc.) a read depth matrix and output the resulting \n\
  \  matrix.  Note that first all excluded samples and targets are removed.  And,\
  \ \n  sample statistics used for filtering are calculated only *after* filtering\
  \ \n  out relevant targets.\n  -M, --matrix                  \n      --excludeTargets=STRING\
  \   File(s) of targets to exclude\n      --excludeChromosomeTargets=STRING\n   \
  \                             Target chromosome(s) to exclude\n      --excludeSamples=STRING\
  \   File(s) of samples to exclude\n      --minTargetSize=INT       Minimum size\
  \ of target (in bp) to process  \n                                  (default=`0')\n\
  \      --maxTargetSize=INT       Maximum size of target (in bp) to process\n   \
  \   --minMeanTargetRD=DOUBLE  Minimum per-target mean RD to require for \n     \
  \                             target to be processed\n      --maxMeanTargetRD=DOUBLE\
  \  Maximum per-target mean RD to require for \n                                \
  \  target to be processed\n      --minSdTargetRD=DOUBLE    Minimum per-target standard\
  \ deviation of RD to \n                                  require for target to be\
  \ processed  \n                                  (default=`0')\n      --maxSdTargetRD=DOUBLE\
  \    Maximum per-target standard deviation of RD to \n                         \
  \         require for target to be processed\n      --minMeanSampleRD=DOUBLE  Minimum\
  \ per-sample mean RD to require for \n                                  sample to\
  \ be processed\n      --maxMeanSampleRD=DOUBLE  Maximum per-sample mean RD to require\
  \ for \n                                  sample to be processed\n      --minSdSampleRD=DOUBLE\
  \    Minimum per-sample standard deviation of RD to \n                         \
  \         require for sample to be processed  \n                               \
  \   (default=`0')\n      --maxSdSampleRD=DOUBLE    Maximum per-sample standard deviation\
  \ of RD to \n                                  require for sample to be processed\n\
  \      --scaleDataBySum          After any filtering, scale read-depth matrix \n\
  \                                  values by sample- or target- sums (as per \n\
  \                                  --scaleDataBySumType) [i.e., divide by row or\
  \ \n                                  column sums], but multiply by factor \n  \
  \                                specificied by --scaleDataBySumFactor  \n     \
  \                             (default=off)\n      --scaleDataBySumType=ENUM If\
  \ --scaleDataBySum given, then scale the data \n                               \
  \   within this dimension  (possible \n                                  values=\"\
  target\", \"sample\")\n      --scaleDataBySumFactor=DOUBLE\n                   \
  \             If --scaleDataBySum given, then divide by \n                     \
  \             appropriate sum (but multiply by this factor) \n                 \
  \                  (default=`1e6')\n      --log10=DOUBLE            After any filtering\
  \ and optional scaling steps \n                                  (but before any\
  \ optional centering steps), \n                                  convert the matrix\
  \ to log10 values. To deal \n                                  with non-positive\
  \ and small positive values, \n                                  a truncation and\
  \ then pseudocount approach is \n                                  taken. Specifically,\
  \ denote the original \n                                  matrix value as x and\
  \ this parameter's \n                                  pseudocount value as v (say,\
  \ 0.5). The matrix \n                                  value used is then log10(max(x,\
  \ 0) + v)\n      --centerData              Output sample- or target- centered read-depth\
  \ \n                                  matrix (as per --centerType)  (default=off)\n\
  \      --centerType=ENUM         If --centerData given, then center the data \n\
  \                                  around this dimension  (possible \n         \
  \                         values=\"target\", \"sample\")\n      --zScoreData   \
  \           If --centerData given, then additionally \n                        \
  \          normalize by standard deviation (outputting \n                      \
  \            z-scores)  (default=off)\n      --outputExcludedTargets=STRING\n  \
  \                              File in which to output targets excluded by \n  \
  \                                some criterion\n      --outputExcludedSamples=STRING\n\
  \                                File in which to output samples excluded by \n\
  \                                  some criterion\n\nOptions for modes: 'mergeGATKdepths',\
  \ 'matrix':\n  -o, --outputMatrix=STRING     Read-depth matrix output file  (default=`-')\n\
  *******************************************************************\n\n Mode: PCA\n\
  \  Run PCA to create normalization factors for read depth matrix\n  -P, --PCA  \
  \                   Matrix is read from --readDepths argument; \n              \
  \                    normalization factors sent to --PCAfiles \n               \
  \                   argument\n      --PCA_saveMemory[=STRING] Should XHMM save memory\
  \ by storing some of the \n                                  intermediate PCA matrices\
  \ as temporary files \n                                  on disk?  (default=`')\n\
  \n Mode: normalize\n  Apply PCA factors in order to normalize read depth matrix\n\
  \  -N, --normalize               Matrix is read from --readDepths argument; \n \
  \                                 normalization factors read from --PCAfiles \n\
  \                                  argument\n  -n, --normalizeOutput=STRING  Normalized\
  \ read-depth matrix output file  \n                                  (default=`-')\n\
  \      --PCnormalizeMethod=ENUM  Method to choose which prinicipal components \n\
  \                                  are removed for data normalization  (possible\
  \ \n                                  values=\"numPCtoRemove\", \"PVE_mean\", \n\
  \                                  \"PVE_contrib\" default=`PVE_mean')\n      --numPCtoRemove=INT\
  \       Number of highest principal components to \n                           \
  \       filter out  (default=`20')\n      --PVE_mean_factor=DOUBLE  Remove all principal\
  \ components that \n                                  individually explain more\
  \ variance than this \n                                  factor times the average\
  \ (in the original \n                                  PCA-ed data)  (default=`0.7')\n\
  \      --PVE_contrib=DOUBLE      Remove the smallest number of principal \n    \
  \                              components that explain this percent of the \n  \
  \                                variance (in the original PCA-ed data)  \n    \
  \                              (default=`50')\n\nOptions for modes: 'PCA', 'normalize':\n\
  \      --PCAfiles=STRING         Base file name for 'PCA' *output*, and \n     \
  \                             'normalize' *input*\n*******************************************************************\n\
  \n Mode: discover\n  Discover CNVs from normalized read depth matrix\n  -D, --discover\
  \                Matrix is read from --readDepths argument\n  -c, --xcnv=STRING\
  \             CNV output file  (default=`-')\n  -t, --discoverSomeQualThresh=DOUBLE\n\
  \                                Quality threshold for discovering a CNV in a \n\
  \                                  sample  (default=`30')\n  -s, --posteriorFiles=STRING\
  \   Base file name for posterior probabilities \n                              \
  \    output files; if not given, and --xcnv is not \n                          \
  \        '-', this will default to --xcnv argument\n\n Mode: genotype\n  Genotype\
  \ list of CNVs from normalized read depth matrix\n  -G, --genotype             \
  \   Matrix is read from --readDepths argument\n  -g, --gxcnv=STRING            xhmm\
  \ CNV input file to genotype in 'readDepths' \n                                \
  \  sample\n      --subsegments             In addition to genotyping the intervals\
  \ \n                                  specified in gxcnv, genotype all sub-segments\
  \ \n                                  of these intervals (with \n              \
  \                    maxTargetsInSubsegment or fewer targets)  \n              \
  \                    (default=off)\n      --maxTargetsInSubsegment=INT\n       \
  \                         When genotyping sub-segments of input \n             \
  \                     intervals, only consider sub-segments \n                 \
  \                 consisting of this number of targets or fewer \n             \
  \                      (default=`30')\n  -T, --genotypeQualThresholdWhenNoExact=DOUBLE\n\
  \                                Quality threshold for calling a genotype, used\
  \ \n                                  *ONLY* when 'gxcnv' does not contain the \n\
  \                                  'Q_EXACT' field for the interval being \n   \
  \                               genotyped  (default=`20')\n\n Mode: mergeVCFs\n\
  \  Merge VCF files output by multiple runs of the 'genotype' command on the same\
  \ \n  input intervals (.xcnv file), but for different samples\n      --mergeVCFs\
  \               \n      --mergeVCF=STRING         VCF file(s) to be merged [must\
  \ have *IDENTICAL* \n                                  genotyped intervals]\n  \
  \    --mergeVCFlist=STRING     A file containing a list of VCF files to be \n  \
  \                                merged [must have *IDENTICAL* genotyped \n    \
  \                              intervals]\n\nOptions for modes: 'discover', 'genotype',\
  \ 'transition', 'printHMM':\n  -p, --paramFile=STRING        (Initial) model parameters\
  \ file\n\nOptions for modes: 'discover', 'genotype':\n  -m, --maxNormalizedReadDepthVal=DOUBLE\n\
  \                                Value at which to cap the absolute value of \n\
  \                                  *normalized* input read depth values \n     \
  \                             ('readDepths')  (default=`10')\n  -q, --maxQualScore=DOUBLE\
  \     Value at which to cap the calculated quality \n                          \
  \        scores  (default=`99')\n  -e, --scorePrecision=INT      Decimal precision\
  \ of quality scores  \n                                  (default=`0')\n  -a, --aux_xcnv=STRING\
  \         Auxiliary CNV output file (may be VERY LARGE in \n                   \
  \               'genotype' mode)\n  -u, --auxUpstreamPrintTargs=INT\n          \
  \                      Number of targets to print upstream of CNV in \n        \
  \                          'auxOutput' file  (default=`2')\n  -w, --auxDownstreamPrintTargs=INT\n\
  \                                Number of targets to print downstream of CNV in\
  \ \n                                  'auxOutput' file  (default=`2')\n  -R, --origReadDepths=STRING\
  \   Matrix of unnormalized read-depths to use for \n                           \
  \       CNV annotation, where rows (samples) and \n                            \
  \      columns (targets) are labeled\n      --keepSampleIDs=STRING    File containing\
  \ a list of samples to be \n                                  analyzed\n\nOptions\
  \ for modes: 'genotype', 'mergeVCFs':\n  -v, --vcf=STRING              Genotyped\
  \ CNV output VCF file  (default=`-')\n*******************************************************************\n\
  \n Mode: printHMM\n  Print HMM model parameters and exit\n      --printHMM     \
  \           \n\n Mode: transition\n  Print HMM transition matrix for user-requested\
  \ genomic distances\n      --transition              \n"
generated_using:
- --help
