from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import String, File, Int, Boolean

Chunkify_Py_Raw_Identity_V0_1_0 = CommandToolBuilder(tool="chunkify.py_raw_identity", base_command=["chunkify.py", "raw_identity"], inputs=[ToolInput(tag="in_alphabet", input_type=String(optional=True), prefix="--alphabet", doc=InputDocumentation(doc="Alphabet of the sequences (default: b'ACGT')")), ToolInput(tag="in_input_strand_list", input_type=File(optional=True), prefix="--input_strand_list", doc=InputDocumentation(doc="Strand summary file containing subset (default: None)")), ToolInput(tag="in_jobs", input_type=Int(optional=True), prefix="--jobs", doc=InputDocumentation(doc="Number of threads to use when processing data\n(default: 1)")), ToolInput(tag="in_km_er_len", input_type=Int(optional=True), prefix="--kmer_len", doc=InputDocumentation(doc="Length of kmer to estimate (default: 5)")), ToolInput(tag="in_limit", input_type=Int(optional=True), prefix="--limit", doc=InputDocumentation(doc="Limit number of reads to process (default: None)")), ToolInput(tag="in_no_overwrite", input_type=Boolean(optional=True), prefix="--no-overwrite", doc=InputDocumentation(doc="Whether to overwrite any output files (Default: --no-\noverwrite) (default: False)")), ToolInput(tag="in_blanks_percentile", input_type=Int(optional=True), prefix="--blanks_percentile", doc=InputDocumentation(doc="Percentile above which to filter out chunks with too\nmany blanks (default: 95)")), ToolInput(tag="in_chunk_len", input_type=Int(optional=True), prefix="--chunk_len", doc=InputDocumentation(doc="Length of each read chunk (default: 2000)")), ToolInput(tag="in_normalisation", input_type=String(optional=True), prefix="--normalisation", doc=InputDocumentation(doc="Whether to perform median-mad normalisation and with\nwhat scope (default: per-read)")), ToolInput(tag="in_trim", input_type=Int(optional=True), prefix="--trim", doc=InputDocumentation(doc="end  Number of samples to trim off start and end (default:\n(200, 50))")), ToolInput(tag="in_min_length", input_type=Int(optional=True), prefix="--min_length", doc=InputDocumentation(doc="Minimum samples in acceptable read (default: 2500)")), ToolInput(tag="in_down_sample_factor", input_type=Int(optional=True), prefix="--downsample_factor", doc=InputDocumentation(doc="Rate of label downsampling (default: 1)")), ToolInput(tag="in_no_interpolation", input_type=Boolean(optional=True), prefix="--no-interpolation", doc=InputDocumentation(doc="Interpolate reference sequence positions between\nmapped samples (Default: --no-interpolation) (default:\nFalse)\n")), ToolInput(tag="in_input_folder", input_type=String(), position=0, doc=InputDocumentation(doc="Directory containing single-read fast5 files")), ToolInput(tag="in_output", input_type=String(), position=1, doc=InputDocumentation(doc="Output HDF5 file"))], outputs=[], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Chunkify_Py_Raw_Identity_V0_1_0().translate("wdl", allow_empty_container=True)

