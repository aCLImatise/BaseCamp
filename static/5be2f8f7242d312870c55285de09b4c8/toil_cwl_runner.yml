!Command
command:
- toil-cwl-runner
positional:
- !Positional
  optional: false
  position: 0
  name: cwltool
  description: cwljob
- !Positional
  optional: false
  position: 0
  name: exit
  description: --preserve-environment VAR1 VAR2 [VAR1 VAR2 ...]
- !Positional
  optional: false
  position: 0
  name: CommandLineTools
  description: --preserve-entire-environment
- !Positional
  optional: false
  position: 0
  name: CommandLineTools.
  description: --destBucket DESTBUCKET
- !Positional
  optional: false
  position: 0
  name: only
  description: --strict-memory-limit
- !Positional
  optional: false
  position: 0
  name: jobStore
  description: "The location of the job store for the workflow. A job\nstore holds\
    \ persistent information about the jobs and\nfiles in a workflow. If the workflow\
    \ is run with a\ndistributed batch system, the job store must be\naccessible by\
    \ all worker nodes. Depending on the\ndesired job store implementation, the location\
    \ should\nbe formatted according to one of the following\nschemes: file:<path>\
    \ where <path> points to a\ndirectory on the file systen aws:<region>:<prefix>\n\
    where <region> is the name of an AWS region like us-\nwest-2 and <prefix> will\
    \ be prepended to the names of\nany top-level AWS resources in use by job store,\
    \ e.g.\nS3 buckets. google:<project_id>:<prefix> TODO: explain\nFor backwards\
    \ compatibility, you may also specify\n./foo (equivalent to file:./foo or just\
    \ file:foo) or\n/bar (equivalent to file:/bar)."
- !Positional
  optional: false
  position: 0
  name: provisioning.
  description: "--provisioner {aws,gce}\nThe provisioner for cluster auto-scaling.\
    \ The\ncurrently supported choices are'gce', or 'aws'. The\ndefault is None."
named:
- !Flag
  optional: true
  synonyms:
  - --jobStore
  - --not-strict
  - --enable-dev
  description: Enable loading and running development versions of CWL
  args: !SimpleFlagArg
    name: JOBSTORE
- !Flag
  optional: true
  synonyms:
  - --user-space-docker-cmd
  description: "(Linux/OS X only) Specify a user space docker command\n(like udocker\
    \ or dx-docker) that will be used to call\n'pull' and 'run'"
  args: !SimpleFlagArg
    name: USER_SPACE_DOCKER_CMD
- !Flag
  optional: true
  synonyms:
  - --singularity
  description: "[experimental] Use Singularity runtime for running\ncontainers. Requires\
    \ Singularity v2.6.1+ and Linux\nwith kernel version v3.18+ or with overlayfs\
    \ support\nbackported."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-container
  description: "Do not execute jobs in a Docker container, even when\n`DockerRequirement`\
    \ is specified under `hints`."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --leave-container
  description: Do not delete Docker container used by jobs after they
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --beta-dependency-resolvers-configuration
  - --beta-dependencies-directory
  - --beta-use-biocontainers
  - --beta-conda-dependencies
  - --tmpdir-prefix
  description: Path prefix for temporary directories
  args: !SimpleFlagArg
    name: BETA_DEPENDENCY_RESOLVERS_CONFIGURATION
- !Flag
  optional: true
  synonyms:
  - --tmp-outdir-prefix
  description: Path prefix for intermediate output directories
  args: !SimpleFlagArg
    name: TMP_OUTDIR_PREFIX
- !Flag
  optional: true
  synonyms:
  - --force-docker-pull
  description: Pull latest docker image even if it is locally present
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-match-user
  description: Disable passing the current uid to `docker run --user`
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-read-only
  description: Do not set root directory in the container as read-
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --relax-path-checks
  description: "Relax requirements on path names to permit spaces and\nhash characters."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --default-container
  description: "Specify a default docker container that will be used\nif the workflow\
    \ fails to specify one."
  args: !SimpleFlagArg
    name: DEFAULT_CONTAINER
- !Flag
  optional: true
  synonyms:
  - --logOff
  description: Same as --logCritical
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logCritical
  description: "Turn on logging at level CRITICAL and above. (default\nis INFO)"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logError
  description: "Turn on logging at level ERROR and above. (default is\nINFO)"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logWarning
  description: "Turn on logging at level WARNING and above. (default\nis INFO)"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logInfo
  description: "Turn on logging at level INFO and above. (default is\nINFO)"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logDebug
  description: "Turn on logging at level DEBUG and above. (default is\nINFO)"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logLevel
  description: "Log at given level (may be either OFF (or CRITICAL),\nERROR, WARN\
    \ (or WARNING), INFO or DEBUG). (default is\nINFO)"
  args: !SimpleFlagArg
    name: LOGLEVEL
- !Flag
  optional: true
  synonyms:
  - --logFile
  description: File to log in
  args: !SimpleFlagArg
    name: LOGFILE
- !Flag
  optional: true
  synonyms:
  - --rotatingLogging
  description: "Turn on rotating logging, which prevents log files\ngetting too big."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --workDir
  description: "Absolute path to directory where temporary files\ngenerated during\
    \ the Toil run should be placed.\nStandard output and error from batch system\
    \ jobs\n(unless --noStdOutErr) will be placed in this\ndirectory. A cache directory\
    \ may be placed in this\ndirectory. Temp files and folders will be placed in a\n\
    directory toil-<workflowID> within workDir. The\nworkflowID is generated by Toil\
    \ and will be reported\nin the workflow logs. Default is determined by the\nvariables\
    \ (TMPDIR, TEMP, TMP) via mkdtemp. This\ndirectory needs to exist on all machines\
    \ running jobs;\nif capturing standard output and error from batch\nsystem jobs\
    \ is desired, it will generally need to be\non a shared file system. When sharing\
    \ a cache between\ncontainers on a host, this directory must be shared\nbetween\
    \ the containers."
  args: !SimpleFlagArg
    name: WORKDIR
- !Flag
  optional: true
  synonyms:
  - --noStdOutErr
  description: "Do not capture standard output and error from batch\nsystem jobs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --stats
  description: "Records statistics about the toil workflow to be used\nby 'toil stats'."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --clean
  description: "Determines the deletion of the jobStore upon\ncompletion of the program.\
    \ Choices: 'always',\n'onError','never', 'onSuccess'. The --stats option\nrequires\
    \ information from the jobStore upon completion\nso the jobStore will never be\
    \ deleted withthat flag.\nIf you wish to be able to restart the run, choose\n\
    'never' or 'onSuccess'. Default is 'never' if stats is\nenabled, and 'onSuccess'\
    \ otherwise"
  args: !ChoiceFlagArg
    choices: !!set
      never:
      onError:
      onSuccess:
      always:
- !Flag
  optional: true
  synonyms:
  - --cleanWorkDir
  description: "Determines deletion of temporary worker directory upon\ncompletion\
    \ of a job. Choices: 'always', 'never',\n'onSuccess'. Default = always. WARNING:\
    \ This option\nshould be changed for debugging only. Running a full\npipeline\
    \ with this option could fill your disk with\nintermediate data."
  args: !ChoiceFlagArg
    choices: !!set
      never:
      onError:
      onSuccess:
      always:
- !Flag
  optional: true
  synonyms:
  - --clusterStats
  description: "[CLUSTERSTATS]\nIf enabled, writes out JSON resource usage statistics\n\
    to a file. The default location for this file is the\ncurrent working directory,\
    \ but an absolute path can\nalso be passed to specify where this file should be\n\
    written. This options only applies when using scalable\nbatch systems."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --restart
  description: "If --restart is specified then will attempt to restart\nexisting workflow\
    \ at the location pointed to by the\n--jobStore option. Will raise an exception\
    \ if the\nworkflow does not exist"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --batchSystem
  description: "The type of batch system to run the job(s) with,\ncurrently can be\
    \ one of Slurm, Torque, LSF,\nKubernetes, Mesos, HTCondor, singleMachine, parasol,\n\
    gridEngine'. default=singleMachine"
  args: !SimpleFlagArg
    name: BATCHSYSTEM
- !Flag
  optional: true
  synonyms:
  - --disableHotDeployment
  description: "Hot-deployment was renamed to auto-deployment. Option\nnow redirects\
    \ to --disableAutoDeployment. Left in for\nbackwards compatibility."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableAutoDeployment
  description: "Should auto-deployment of the user script be\ndeactivated? If True,\
    \ the user script/package should\nbe present at the same location on all workers.\n\
    default=false"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxLocalJobs
  description: "For batch systems that support a local queue for\nhousekeeping jobs\
    \ (Mesos, GridEngine, htcondor, lsf,\nslurm, torque), the maximum number of these\n\
    housekeeping jobs to run on the local system. The\ndefault (equal to the number\
    \ of cores) is a maximum of\n8 concurrent local housekeeping jobs."
  args: !SimpleFlagArg
    name: MAXLOCALJOBS
- !Flag
  optional: true
  synonyms:
  - --manualMemArgs
  description: "Do not add the default arguments: 'hv=MEMORY' &\n'h_vmem=MEMORY' to\
    \ the qsub call, and instead rely on\nTOIL_GRIDGENGINE_ARGS to supply alternative\
    \ arguments.\nRequires that TOIL_GRIDGENGINE_ARGS be set."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --runCwlInternalJobsOnWorkers
  description: "Whether to run CWL internal jobs (e.g. CWLScatter) on\nthe worker\
    \ nodes instead of the primary node. If false\n(default), then all such jobs are\
    \ run on the primary\nnode. Setting this to true can speed up the pipeline\nfor\
    \ very large workflows with many sub-workflows\nand/or scatters, provided that\
    \ the worker pool is\nlarge enough."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --parasolCommand
  description: "The name or path of the parasol program. Will be\nlooked up on PATH\
    \ unless it starts with a slash.\ndefault=parasol"
  args: !SimpleFlagArg
    name: PARASOLCOMMAND
- !Flag
  optional: true
  synonyms:
  - --parasolMaxBatches
  description: "Maximum number of job batches the Parasol batch is\nallowed to create.\
    \ One batch is created for jobs with\na a unique set of resource requirements.\
    \ default=1000"
  args: !SimpleFlagArg
    name: PARASOLMAXBATCHES
- !Flag
  optional: true
  synonyms:
  - --scale
  description: "A scaling factor to change the value of all submitted\ntasks's submitted\
    \ cores. Used in singleMachine batch\nsystem. default=1"
  args: !SimpleFlagArg
    name: SCALE
- !Flag
  optional: true
  synonyms:
  - --noLinkImports
  description: "When using a filesystem based job store, CWL input\nfiles are by default\
    \ symlinked in. Specifying this\noption instead copies the files into the job\
    \ store,\nwhich may protect them from being modified externally.\nWhen not specified\
    \ and as long as caching is enabled,\nToil will protect the file automatically\
    \ by changing\nthe permissions to read-only."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --noMoveExports
  description: "When using a filesystem based job store, output files\nare by default\
    \ moved to the output directory, and a\nsymlink to the moved exported file is\
    \ created at the\ninitial location. Specifying this option instead\ncopies the\
    \ files into the output directory. Applies to\nfilesystem-based job stores only."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --mesosMaster
  description: "The host and port of the Mesos master separated by\ncolon. (default:\
    \ 172.17.0.4:5050)"
  args: !SimpleFlagArg
    name: MESOSMASTERADDRESS
- !Flag
  optional: true
  synonyms:
  - --kubernetesHostPath
  description: "Path on Kubernetes hosts to use as shared inter-pod\ntemp directory\
    \ (default: None)"
  args: !SimpleFlagArg
    name: KUBERNETESHOSTPATH
- !Flag
  optional: true
  synonyms:
  - --nodeTypes
  description: "List of node types separated by commas. The syntax for\neach node\
    \ type depends on the provisioner used. For\nthe cgcloud and AWS provisioners\
    \ this is the name of\nan EC2 instance type, optionally followed by a colon\n\
    and the price in dollars to bid for a spot instance of\nthat type, for example\
    \ 'c3.8xlarge:0.42'.If no spot\nbid is specified, nodes of this type will be non-\n\
    preemptable.It is acceptable to specify an instance as\nboth preemptable and non-preemptable,\
    \ including it\ntwice in the list. In that case,preemptable nodes of\nthat type\
    \ will be preferred when creating new nodes\nonce the maximum number of preemptable-nodes\
    \ has\nbeenreached."
  args: !SimpleFlagArg
    name: NODETYPES
- !Flag
  optional: true
  synonyms:
  - --nodeOptions
  description: "Options for provisioning the nodes. The syntax depends\non the provisioner\
    \ used. Neither the CGCloud nor the\nAWS provisioner support any node options."
  args: !SimpleFlagArg
    name: NODEOPTIONS
- !Flag
  optional: true
  synonyms:
  - --minNodes
  description: "Mininum number of nodes of each type in the cluster,\nif using auto-scaling.\
    \ This should be provided as a\ncomma-separated list of the same length as the\
    \ list of\nnode types. default=0"
  args: !SimpleFlagArg
    name: MINNODES
- !Flag
  optional: true
  synonyms:
  - --maxNodes
  description: "Maximum number of nodes of each type in the cluster,\nif using autoscaling,\
    \ provided as a comma-separated\nlist. The first value is used as a default if\
    \ the list\nlength is less than the number of nodeTypes.\ndefault=10"
  args: !SimpleFlagArg
    name: MAXNODES
- !Flag
  optional: true
  synonyms:
  - --targetTime
  description: "Sets how rapidly you aim to complete jobs in seconds.\nShorter times\
    \ mean more aggressive parallelization.\nThe autoscaler attempts to scale up/down\
    \ so that it\nexpects all queued jobs will complete within\ntargetTime seconds.\
    \ default=1800"
  args: !SimpleFlagArg
    name: TARGETTIME
- !Flag
  optional: true
  synonyms:
  - --betaInertia
  description: "A smoothing parameter to prevent unnecessary\noscillations in the\
    \ number of provisioned nodes. This\ncontrols an exponentially weighted moving\
    \ average of\nthe estimated number of nodes. A value of 0.0 disables\nany smoothing,\
    \ and a value of 0.9 will smooth so much\nthat few changes will ever be made.\
    \ Must be between\n0.0 and 0.9. default=0.1"
  args: !SimpleFlagArg
    name: BETAINERTIA
- !Flag
  optional: true
  synonyms:
  - --scaleInterval
  description: "The interval (seconds) between assessing if the scale\nof the cluster\
    \ needs to change. default=60"
  args: !SimpleFlagArg
    name: SCALEINTERVAL
- !Flag
  optional: true
  synonyms:
  - --preemptableCompensation
  description: "The preference of the autoscaler to replace\npreemptable nodes with\
    \ non-preemptable nodes, when\npreemptable nodes cannot be started for some reason.\n\
    Defaults to 0.0. This value must be between 0.0 and\n1.0, inclusive. A value of\
    \ 0.0 disables such\ncompensation, a value of 0.5 compensates two missing\npreemptable\
    \ nodes with a non-preemptable one. A value\nof 1.0 replaces every missing pre-emptable\
    \ node with a\nnon-preemptable one."
  args: !SimpleFlagArg
    name: PREEMPTABLECOMPENSATION
- !Flag
  optional: true
  synonyms:
  - --nodeStorage
  description: "Specify the size of the root volume of worker nodes\nwhen they are\
    \ launched in gigabytes. You may want to\nset this if your jobs require a lot\
    \ of disk space. The\ndefault value is 50."
  args: !SimpleFlagArg
    name: NODESTORAGE
- !Flag
  optional: true
  synonyms:
  - --metrics
  description: "Enable the prometheus/grafana dashboard for monitoring\nCPU/RAM usage,\
    \ queue size, and issued jobs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --defaultMemory
  description: "The default amount of memory to request for a job.\nOnly applicable\
    \ to jobs that do not specify an\nexplicit value for this requirement. Standard\
    \ suffixes\nlike K, Ki, M, Mi, G or Gi are supported. Default is\n2.0 Gi"
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --defaultCores
  description: "The default number of CPU cores to dedicate a job.\nOnly applicable\
    \ to jobs that do not specify an\nexplicit value for this requirement. Fractions\
    \ of a\ncore (for example 0.1) are supported on some batch\nsystems, namely Mesos\
    \ and singleMachine. Default is\n1.0"
  args: !SimpleFlagArg
    name: FLOAT
- !Flag
  optional: true
  synonyms:
  - --defaultDisk
  description: "The default amount of disk space to dedicate a job.\nOnly applicable\
    \ to jobs that do not specify an\nexplicit value for this requirement. Standard\
    \ suffixes\nlike K, Ki, M, Mi, G or Gi are supported. Default is\n2.0 Gi"
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --defaultPreemptable
  - --maxCores
  description: "The maximum number of CPU cores to request from the\nbatch system\
    \ at any one time. Standard suffixes like\nK, Ki, M, Mi, G or Gi are supported.\
    \ Default is 8.0 Ei"
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --maxMemory
  description: "The maximum amount of memory to request from the batch\nsystem at\
    \ any one time. Standard suffixes like K, Ki,\nM, Mi, G or Gi are supported. Default\
    \ is 8.0 Ei"
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --maxDisk
  description: "The maximum amount of disk space to request from the\nbatch system\
    \ at any one time. Standard suffixes like\nK, Ki, M, Mi, G or Gi are supported.\
    \ Default is 8.0 Ei"
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --retryCount
  description: "Number of times to retry a failing job before giving\nup and labeling\
    \ job failed. default=1"
  args: !SimpleFlagArg
    name: RETRYCOUNT
- !Flag
  optional: true
  synonyms:
  - --enableUnlimitedPreemptableRetries
  description: "If set, preemptable failures (or any failure due to an\ninstance getting\
    \ unexpectedly terminated) would not\ncount towards job failures and --retryCount."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxJobDuration
  description: "Maximum runtime of a job (in seconds) before we kill\nit (this is\
    \ a lower bound, and the actual time before\nkilling the job may be longer).\n\
    default=9223372036854775807"
  args: !SimpleFlagArg
    name: MAXJOBDURATION
- !Flag
  optional: true
  synonyms:
  - --rescueJobsFrequency
  description: "Period of time to wait (in seconds) between checking\nfor missing/overlong\
    \ jobs, that is jobs which get lost\nby the batch system. Expert parameter. default=3600"
  args: !SimpleFlagArg
    name: RESCUEJOBSFREQUENCY
- !Flag
  optional: true
  synonyms:
  - --disableCaching
  description: "[DISABLECACHING]\nDisables caching in the file store. This flag must\
    \ be\nset to use a batch system that does not support\ncaching such as Grid Engine,\
    \ Parasol, LSF, or Slurm"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableChaining
  description: "Disables chaining of jobs (chaining uses one job's\nresource allocation\
    \ for its successor job if\npossible)."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableJobStoreChecksumVerification
  description: "Disables checksum verification for files transferred\nto/from the\
    \ job store. Checksum verification is a\nsafety check to ensure the data is not\
    \ corrupted\nduring transfer. Currently only supported for non-\nstreaming AWS\
    \ files."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxLogFileSize
  description: "The maximum size of a job log file to keep (in bytes),\nlog files\
    \ larger than this will be truncated to the\nlast X bytes. Setting this option\
    \ to zero will prevent\nany truncation. Setting this option to a negative\nvalue\
    \ will truncate from the beginning.Default=62.5 K"
  args: !SimpleFlagArg
    name: MAXLOGFILESIZE
- !Flag
  optional: true
  synonyms:
  - --writeLogs
  description: "[WRITELOGS]\nWrite worker logs received by the leader into their\n\
    own files at the specified path. Any non-empty\nstandard output and error from\
    \ failed batch system\njobs will also be written into files at this path. The\n\
    current working directory will be used if a path is\nnot specified explicitly.\
    \ Note: By default only the\nlogs of failed jobs are returned to leader. Set log\n\
    level to 'debug' or enable '--writeLogsFromAllJobs' to\nget logs back from successful\
    \ jobs, and adjust\n'maxLogFileSize' to control the truncation limit for\nworker\
    \ logs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --writeLogsGzip
  description: "[WRITELOGSGZIP]\nIdentical to --writeLogs except the logs files are\n\
    gzipped on the leader."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --writeLogsFromAllJobs
  description: "Whether to write logs from all jobs (including the\nsuccessful ones)\
    \ without necessarily setting the log\nlevel to 'debug'. Ensure that either --writeLogs\
    \ or\n--writeLogsGzip is set if enabling this option."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --realTimeLogging
  description: Enable real-time logging from workers to masters
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --sseKey
  description: "Path to file containing 32 character key to be used\nfor server-side\
    \ encryption on awsJobStore or\ngoogleJobStore. SSE will not be used if this flag\
    \ is\nnot passed."
  args: !SimpleFlagArg
    name: SSEKEY
- !Flag
  optional: true
  synonyms:
  - --setEnv
  description: "=VALUE or NAME, -e NAME=VALUE or NAME\nSet an environment variable\
    \ early on in the worker. If\nVALUE is omitted, it will be looked up in the current\n\
    environment. Independently of this option, the worker\nwill try to emulate the\
    \ leader's environment before\nrunning a job, except for some variables known\
    \ to vary\nacross systems. Using this option, a variable can be\ninjected into\
    \ the worker process itself before it is\nstarted."
  args: !SimpleFlagArg
    name: NAME
- !Flag
  optional: true
  synonyms:
  - --servicePollingInterval
  description: "Interval of time service jobs wait between polling for\nthe existence\
    \ of the keep-alive flag (defailt=60)"
  args: !SimpleFlagArg
    name: SERVICEPOLLINGINTERVAL
- !Flag
  optional: true
  synonyms:
  - --forceDockerAppliance
  description: "Disables sanity checking the existence of the docker\nimage specified\
    \ by TOIL_APPLIANCE_SELF, which Toil\nuses to provision mesos for autoscaling."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableProgress
  description: "Disables the progress bar shown when standard error is\na terminal."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --debugWorker
  description: "Experimental no forking mode for local debugging.\nSpecifically, workers\
    \ are not forked and stderr/stdout\nare not redirected to the log."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableWorkerOutputCapture
  description: "Let worker output go to worker's standard out/error\ninstead of per-job\
    \ logs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --badWorker
  description: "For testing purposes randomly kill 'badWorker'\nproportion of jobs\
    \ using SIGKILL, default=0.0"
  args: !SimpleFlagArg
    name: BADWORKER
- !Flag
  optional: true
  synonyms:
  - --badWorkerFailInterval
  description: "When killing the job pick uniformly within the\ninterval from 0.0\
    \ to 'badWorkerFailInterval' seconds\nafter the worker starts, default=0.01"
  args: !SimpleFlagArg
    name: BADWORKERFAILINTERVAL
- !Flag
  optional: true
  synonyms:
  - --provenance
  description: "Save provenance to specified folder as a Research\nObject that captures\
    \ and aggregates workflow execution\nand data products."
  args: !SimpleFlagArg
    name: PROVENANCE
- !Flag
  optional: true
  synonyms:
  - --enable-user-provenance
  description: Record user account info as part of provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disable-user-provenance
  description: Do not record user account info in provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --enable-host-provenance
  description: Record host info as part of provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disable-host-provenance
  description: Do not record host info in provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --orcid
  description: "Record user ORCID identifier as part of provenance,\ne.g. https://orcid.org/0000-0002-1825-0097\
    \ or\n0000-0002-1825-0097. Alternatively the environment\nvariable ORCID may be\
    \ set."
  args: !SimpleFlagArg
    name: ORCID
- !Flag
  optional: true
  synonyms:
  - --full-name
  description: "Record full name of user as part of provenance, e.g.\nJosiah Carberry.\
    \ You may need to use shell quotes to\npreserve spaces. Alternatively the environment\n\
    variable CWL_FULL_NAME may be set.\n"
  args: !SimpleFlagArg
    name: CWL_FULL_NAME
parent:
subcommands: []
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag: !Flag
  optional: true
  synonyms:
  - --quiet
  - --basedir
  - --outdir
  - --version
  description: show program's version number and exit
  args: !SimpleFlagArg
    name: BASEDIR
help_text: "usage: toil-cwl-runner [-h] [--logOff] [--logCritical] [--logError]\n\
  \                       [--logWarning] [--logInfo] [--logDebug]\n              \
  \         [--logLevel LOGLEVEL] [--logFile LOGFILE]\n                       [--rotatingLogging]\
  \ [--workDir WORKDIR] [--noStdOutErr]\n                       [--stats] [--clean\
  \ {always,onError,never,onSuccess}]\n                       [--cleanWorkDir {always,never,onSuccess,onError}]\n\
  \                       [--clusterStats [CLUSTERSTATS]] [--restart]\n          \
  \             [--batchSystem BATCHSYSTEM] [--disableHotDeployment]\n           \
  \            [--disableAutoDeployment] [--maxLocalJobs MAXLOCALJOBS]\n         \
  \              [--manualMemArgs] [--runCwlInternalJobsOnWorkers]\n             \
  \          [--parasolCommand PARASOLCOMMAND]\n                       [--parasolMaxBatches\
  \ PARASOLMAXBATCHES] [--scale SCALE]\n                       [--noLinkImports] [--noMoveExports]\n\
  \                       [--mesosMaster MESOSMASTERADDRESS]\n                   \
  \    [--kubernetesHostPath KUBERNETESHOSTPATH]\n                       [--provisioner\
  \ {aws,gce}] [--nodeTypes NODETYPES]\n                       [--nodeOptions NODEOPTIONS]\
  \ [--minNodes MINNODES]\n                       [--maxNodes MAXNODES] [--targetTime\
  \ TARGETTIME]\n                       [--betaInertia BETAINERTIA]\n            \
  \           [--scaleInterval SCALEINTERVAL]\n                       [--preemptableCompensation\
  \ PREEMPTABLECOMPENSATION]\n                       [--nodeStorage NODESTORAGE] [--metrics]\n\
  \                       [--defaultMemory INT] [--defaultCores FLOAT]\n         \
  \              [--defaultDisk INT] [--defaultPreemptable]\n                    \
  \   [--maxCores INT] [--maxMemory INT] [--maxDisk INT]\n                       [--retryCount\
  \ RETRYCOUNT]\n                       [--enableUnlimitedPreemptableRetries]\n  \
  \                     [--maxJobDuration MAXJOBDURATION]\n                      \
  \ [--rescueJobsFrequency RESCUEJOBSFREQUENCY]\n                       [--disableCaching\
  \ [DISABLECACHING]] [--disableChaining]\n                       [--disableJobStoreChecksumVerification]\n\
  \                       [--maxLogFileSize MAXLOGFILESIZE]\n                    \
  \   [--writeLogs [WRITELOGS]]\n                       [--writeLogsGzip [WRITELOGSGZIP]]\n\
  \                       [--writeLogsFromAllJobs] [--realTimeLogging]\n         \
  \              [--sseKey SSEKEY] [--setEnv NAME=VALUE or NAME]\n               \
  \        [--servicePollingInterval SERVICEPOLLINGINTERVAL]\n                   \
  \    [--forceDockerAppliance] [--disableProgress]\n                       [--debugWorker]\
  \ [--disableWorkerOutputCapture]\n                       [--badWorker BADWORKER]\n\
  \                       [--badWorkerFailInterval BADWORKERFAILINTERVAL]\n      \
  \                 [--jobStore JOBSTORE] [--not-strict] [--enable-dev]\n        \
  \               [--quiet] [--basedir BASEDIR] [--outdir OUTDIR]\n              \
  \         [--version]\n                       [--user-space-docker-cmd USER_SPACE_DOCKER_CMD\
  \ | --singularity | --no-container | --leave-container]\n                      \
  \ [--preserve-environment VAR1 VAR2 [VAR1 VAR2 ...]]\n                       [--preserve-entire-environment]\n\
  \                       [--destBucket DESTBUCKET]\n                       [--beta-dependency-resolvers-configuration\
  \ BETA_DEPENDENCY_RESOLVERS_CONFIGURATION]\n                       [--beta-dependencies-directory\
  \ BETA_DEPENDENCIES_DIRECTORY]\n                       [--beta-use-biocontainers]\
  \ [--beta-conda-dependencies]\n                       [--tmpdir-prefix TMPDIR_PREFIX]\n\
  \                       [--tmp-outdir-prefix TMP_OUTDIR_PREFIX]\n              \
  \         [--force-docker-pull] [--no-match-user]\n                       [--no-read-only]\
  \ [--strict-memory-limit]\n                       [--relax-path-checks]\n      \
  \                 [--default-container DEFAULT_CONTAINER]\n                    \
  \   [--provenance PROVENANCE] [--enable-user-provenance]\n                     \
  \  [--disable-user-provenance] [--enable-host-provenance]\n                    \
  \   [--disable-host-provenance] [--orcid ORCID]\n                       [--full-name\
  \ CWL_FULL_NAME]\n                       jobStore cwltool ...\n\npositional arguments:\n\
  \  cwltool\n  cwljob\n\noptional arguments:\n  -h, --help            show this help\
  \ message and exit\n  --jobStore JOBSTORE\n  --not-strict\n  --enable-dev      \
  \    Enable loading and running development versions of CWL\n  --quiet\n  --basedir\
  \ BASEDIR\n  --outdir OUTDIR\n  --version             show program's version number\
  \ and exit\n  --user-space-docker-cmd USER_SPACE_DOCKER_CMD\n                  \
  \      (Linux/OS X only) Specify a user space docker command\n                 \
  \       (like udocker or dx-docker) that will be used to call\n                \
  \        'pull' and 'run'\n  --singularity         [experimental] Use Singularity\
  \ runtime for running\n                        containers. Requires Singularity\
  \ v2.6.1+ and Linux\n                        with kernel version v3.18+ or with\
  \ overlayfs support\n                        backported.\n  --no-container     \
  \   Do not execute jobs in a Docker container, even when\n                     \
  \   `DockerRequirement` is specified under `hints`.\n  --leave-container     Do\
  \ not delete Docker container used by jobs after they\n                        exit\n\
  \  --preserve-environment VAR1 VAR2 [VAR1 VAR2 ...]\n                        Preserve\
  \ specified environment variables when running\n                        CommandLineTools\n\
  \  --preserve-entire-environment\n                        Preserve all environment\
  \ variable when running\n                        CommandLineTools.\n  --destBucket\
  \ DESTBUCKET\n                        Specify a cloud bucket endpoint for output\
  \ files.\n  --beta-dependency-resolvers-configuration BETA_DEPENDENCY_RESOLVERS_CONFIGURATION\n\
  \  --beta-dependencies-directory BETA_DEPENDENCIES_DIRECTORY\n  --beta-use-biocontainers\n\
  \  --beta-conda-dependencies\n  --tmpdir-prefix TMPDIR_PREFIX\n                \
  \        Path prefix for temporary directories\n  --tmp-outdir-prefix TMP_OUTDIR_PREFIX\n\
  \                        Path prefix for intermediate output directories\n  --force-docker-pull\
  \   Pull latest docker image even if it is locally present\n  --no-match-user  \
  \     Disable passing the current uid to `docker run --user`\n  --no-read-only \
  \       Do not set root directory in the container as read-\n                  \
  \      only\n  --strict-memory-limit\n                        When running with\
  \ software containers and the Docker\n                        engine, pass either\
  \ the calculated memory allocation\n                        from ResourceRequirements\
  \ or the default of 1 gigabyte\n                        to Docker's --memory option.\n\
  \  --relax-path-checks   Relax requirements on path names to permit spaces and\n\
  \                        hash characters.\n  --default-container DEFAULT_CONTAINER\n\
  \                        Specify a default docker container that will be used\n\
  \                        if the workflow fails to specify one.\n\nLogging Options:\n\
  \  Options that control logging\n\n  --logOff              Same as --logCritical\n\
  \  --logCritical         Turn on logging at level CRITICAL and above. (default\n\
  \                        is INFO)\n  --logError            Turn on logging at level\
  \ ERROR and above. (default is\n                        INFO)\n  --logWarning  \
  \        Turn on logging at level WARNING and above. (default\n                \
  \        is INFO)\n  --logInfo             Turn on logging at level INFO and above.\
  \ (default is\n                        INFO)\n  --logDebug            Turn on logging\
  \ at level DEBUG and above. (default is\n                        INFO)\n  --logLevel\
  \ LOGLEVEL   Log at given level (may be either OFF (or CRITICAL),\n            \
  \            ERROR, WARN (or WARNING), INFO or DEBUG). (default is\n           \
  \             INFO)\n  --logFile LOGFILE     File to log in\n  --rotatingLogging\
  \     Turn on rotating logging, which prevents log files\n                     \
  \   getting too big.\n\ntoil core options:\n  Options to specify the location of\
  \ the Toil workflow and turn on stats\n  collation about the performance of jobs.\n\
  \n  jobStore              The location of the job store for the workflow. A job\n\
  \                        store holds persistent information about the jobs and\n\
  \                        files in a workflow. If the workflow is run with a\n  \
  \                      distributed batch system, the job store must be\n       \
  \                 accessible by all worker nodes. Depending on the\n           \
  \             desired job store implementation, the location should\n          \
  \              be formatted according to one of the following\n                \
  \        schemes: file:<path> where <path> points to a\n                       \
  \ directory on the file systen aws:<region>:<prefix>\n                        where\
  \ <region> is the name of an AWS region like us-\n                        west-2\
  \ and <prefix> will be prepended to the names of\n                        any top-level\
  \ AWS resources in use by job store, e.g.\n                        S3 buckets. google:<project_id>:<prefix>\
  \ TODO: explain\n                        For backwards compatibility, you may also\
  \ specify\n                        ./foo (equivalent to file:./foo or just file:foo)\
  \ or\n                        /bar (equivalent to file:/bar).\n  --workDir WORKDIR\
  \     Absolute path to directory where temporary files\n                       \
  \ generated during the Toil run should be placed.\n                        Standard\
  \ output and error from batch system jobs\n                        (unless --noStdOutErr)\
  \ will be placed in this\n                        directory. A cache directory may\
  \ be placed in this\n                        directory. Temp files and folders will\
  \ be placed in a\n                        directory toil-<workflowID> within workDir.\
  \ The\n                        workflowID is generated by Toil and will be reported\n\
  \                        in the workflow logs. Default is determined by the\n  \
  \                      variables (TMPDIR, TEMP, TMP) via mkdtemp. This\n       \
  \                 directory needs to exist on all machines running jobs;\n     \
  \                   if capturing standard output and error from batch\n        \
  \                system jobs is desired, it will generally need to be\n        \
  \                on a shared file system. When sharing a cache between\n       \
  \                 containers on a host, this directory must be shared\n        \
  \                between the containers.\n  --noStdOutErr         Do not capture\
  \ standard output and error from batch\n                        system jobs.\n \
  \ --stats               Records statistics about the toil workflow to be used\n\
  \                        by 'toil stats'.\n  --clean {always,onError,never,onSuccess}\n\
  \                        Determines the deletion of the jobStore upon\n        \
  \                completion of the program. Choices: 'always',\n               \
  \         'onError','never', 'onSuccess'. The --stats option\n                 \
  \       requires information from the jobStore upon completion\n               \
  \         so the jobStore will never be deleted withthat flag.\n               \
  \         If you wish to be able to restart the run, choose\n                  \
  \      'never' or 'onSuccess'. Default is 'never' if stats is\n                \
  \        enabled, and 'onSuccess' otherwise\n  --cleanWorkDir {always,never,onSuccess,onError}\n\
  \                        Determines deletion of temporary worker directory upon\n\
  \                        completion of a job. Choices: 'always', 'never',\n    \
  \                    'onSuccess'. Default = always. WARNING: This option\n     \
  \                   should be changed for debugging only. Running a full\n     \
  \                   pipeline with this option could fill your disk with\n      \
  \                  intermediate data.\n  --clusterStats [CLUSTERSTATS]\n       \
  \                 If enabled, writes out JSON resource usage statistics\n      \
  \                  to a file. The default location for this file is the\n      \
  \                  current working directory, but an absolute path can\n       \
  \                 also be passed to specify where this file should be\n        \
  \                written. This options only applies when using scalable\n      \
  \                  batch systems.\n\ntoil options for restarting an existing workflow:\n\
  \  Allows the restart of an existing workflow\n\n  --restart             If --restart\
  \ is specified then will attempt to restart\n                        existing workflow\
  \ at the location pointed to by the\n                        --jobStore option.\
  \ Will raise an exception if the\n                        workflow does not exist\n\
  \ntoil options for specifying the batch system:\n  Allows the specification of the\
  \ batch system, and arguments to the batch\n  system/big batch system (see below).\n\
  \n  --batchSystem BATCHSYSTEM\n                        The type of batch system\
  \ to run the job(s) with,\n                        currently can be one of Slurm,\
  \ Torque, LSF,\n                        Kubernetes, Mesos, HTCondor, singleMachine,\
  \ parasol,\n                        gridEngine'. default=singleMachine\n  --disableHotDeployment\n\
  \                        Hot-deployment was renamed to auto-deployment. Option\n\
  \                        now redirects to --disableAutoDeployment. Left in for\n\
  \                        backwards compatibility.\n  --disableAutoDeployment\n \
  \                       Should auto-deployment of the user script be\n         \
  \               deactivated? If True, the user script/package should\n         \
  \               be present at the same location on all workers.\n              \
  \          default=false\n  --maxLocalJobs MAXLOCALJOBS\n                      \
  \  For batch systems that support a local queue for\n                        housekeeping\
  \ jobs (Mesos, GridEngine, htcondor, lsf,\n                        slurm, torque),\
  \ the maximum number of these\n                        housekeeping jobs to run\
  \ on the local system. The\n                        default (equal to the number\
  \ of cores) is a maximum of\n                        8 concurrent local housekeeping\
  \ jobs.\n  --manualMemArgs       Do not add the default arguments: 'hv=MEMORY' &\n\
  \                        'h_vmem=MEMORY' to the qsub call, and instead rely on\n\
  \                        TOIL_GRIDGENGINE_ARGS to supply alternative arguments.\n\
  \                        Requires that TOIL_GRIDGENGINE_ARGS be set.\n  --runCwlInternalJobsOnWorkers\n\
  \                        Whether to run CWL internal jobs (e.g. CWLScatter) on\n\
  \                        the worker nodes instead of the primary node. If false\n\
  \                        (default), then all such jobs are run on the primary\n\
  \                        node. Setting this to true can speed up the pipeline\n\
  \                        for very large workflows with many sub-workflows\n    \
  \                    and/or scatters, provided that the worker pool is\n       \
  \                 large enough.\n  --parasolCommand PARASOLCOMMAND\n           \
  \             The name or path of the parasol program. Will be\n               \
  \         looked up on PATH unless it starts with a slash.\n                   \
  \     default=parasol\n  --parasolMaxBatches PARASOLMAXBATCHES\n               \
  \         Maximum number of job batches the Parasol batch is\n                 \
  \       allowed to create. One batch is created for jobs with\n                \
  \        a a unique set of resource requirements. default=1000\n  --scale SCALE\
  \         A scaling factor to change the value of all submitted\n              \
  \          tasks's submitted cores. Used in singleMachine batch\n              \
  \          system. default=1\n  --noLinkImports       When using a filesystem based\
  \ job store, CWL input\n                        files are by default symlinked in.\
  \ Specifying this\n                        option instead copies the files into\
  \ the job store,\n                        which may protect them from being modified\
  \ externally.\n                        When not specified and as long as caching\
  \ is enabled,\n                        Toil will protect the file automatically\
  \ by changing\n                        the permissions to read-only.\n  --noMoveExports\
  \       When using a filesystem based job store, output files\n                \
  \        are by default moved to the output directory, and a\n                 \
  \       symlink to the moved exported file is created at the\n                 \
  \       initial location. Specifying this option instead\n                     \
  \   copies the files into the output directory. Applies to\n                   \
  \     filesystem-based job stores only.\n  --mesosMaster MESOSMASTERADDRESS\n  \
  \                      The host and port of the Mesos master separated by\n    \
  \                    colon. (default: 172.17.0.4:5050)\n  --kubernetesHostPath KUBERNETESHOSTPATH\n\
  \                        Path on Kubernetes hosts to use as shared inter-pod\n \
  \                       temp directory (default: None)\n\ntoil options for autoscaling\
  \ the cluster of worker nodes:\n  Allows the specification of the minimum and maximum\
  \ number of nodes in an\n  autoscaled cluster, as well as parameters to control\
  \ the level of\n  provisioning.\n\n  --provisioner {aws,gce}\n                 \
  \       The provisioner for cluster auto-scaling. The\n                        currently\
  \ supported choices are'gce', or 'aws'. The\n                        default is\
  \ None.\n  --nodeTypes NODETYPES\n                        List of node types separated\
  \ by commas. The syntax for\n                        each node type depends on the\
  \ provisioner used. For\n                        the cgcloud and AWS provisioners\
  \ this is the name of\n                        an EC2 instance type, optionally\
  \ followed by a colon\n                        and the price in dollars to bid for\
  \ a spot instance of\n                        that type, for example 'c3.8xlarge:0.42'.If\
  \ no spot\n                        bid is specified, nodes of this type will be\
  \ non-\n                        preemptable.It is acceptable to specify an instance\
  \ as\n                        both preemptable and non-preemptable, including it\n\
  \                        twice in the list. In that case,preemptable nodes of\n\
  \                        that type will be preferred when creating new nodes\n \
  \                       once the maximum number of preemptable-nodes has\n     \
  \                   beenreached.\n  --nodeOptions NODEOPTIONS\n                \
  \        Options for provisioning the nodes. The syntax depends\n              \
  \          on the provisioner used. Neither the CGCloud nor the\n              \
  \          AWS provisioner support any node options.\n  --minNodes MINNODES   Mininum\
  \ number of nodes of each type in the cluster,\n                        if using\
  \ auto-scaling. This should be provided as a\n                        comma-separated\
  \ list of the same length as the list of\n                        node types. default=0\n\
  \  --maxNodes MAXNODES   Maximum number of nodes of each type in the cluster,\n\
  \                        if using autoscaling, provided as a comma-separated\n \
  \                       list. The first value is used as a default if the list\n\
  \                        length is less than the number of nodeTypes.\n        \
  \                default=10\n  --targetTime TARGETTIME\n                       \
  \ Sets how rapidly you aim to complete jobs in seconds.\n                      \
  \  Shorter times mean more aggressive parallelization.\n                       \
  \ The autoscaler attempts to scale up/down so that it\n                        expects\
  \ all queued jobs will complete within\n                        targetTime seconds.\
  \ default=1800\n  --betaInertia BETAINERTIA\n                        A smoothing\
  \ parameter to prevent unnecessary\n                        oscillations in the\
  \ number of provisioned nodes. This\n                        controls an exponentially\
  \ weighted moving average of\n                        the estimated number of nodes.\
  \ A value of 0.0 disables\n                        any smoothing, and a value of\
  \ 0.9 will smooth so much\n                        that few changes will ever be\
  \ made. Must be between\n                        0.0 and 0.9. default=0.1\n  --scaleInterval\
  \ SCALEINTERVAL\n                        The interval (seconds) between assessing\
  \ if the scale\n                        of the cluster needs to change. default=60\n\
  \  --preemptableCompensation PREEMPTABLECOMPENSATION\n                        The\
  \ preference of the autoscaler to replace\n                        preemptable nodes\
  \ with non-preemptable nodes, when\n                        preemptable nodes cannot\
  \ be started for some reason.\n                        Defaults to 0.0. This value\
  \ must be between 0.0 and\n                        1.0, inclusive. A value of 0.0\
  \ disables such\n                        compensation, a value of 0.5 compensates\
  \ two missing\n                        preemptable nodes with a non-preemptable\
  \ one. A value\n                        of 1.0 replaces every missing pre-emptable\
  \ node with a\n                        non-preemptable one.\n  --nodeStorage NODESTORAGE\n\
  \                        Specify the size of the root volume of worker nodes\n \
  \                       when they are launched in gigabytes. You may want to\n \
  \                       set this if your jobs require a lot of disk space. The\n\
  \                        default value is 50.\n  --metrics             Enable the\
  \ prometheus/grafana dashboard for monitoring\n                        CPU/RAM usage,\
  \ queue size, and issued jobs.\n\ntoil options for cores/memory requirements:\n\
  \  The options to specify default cores/memory requirements (if not specified\n\
  \  by the jobs themselves), and to limit the total amount of memory/cores\n  requested\
  \ from the batch system.\n\n  --defaultMemory INT   The default amount of memory\
  \ to request for a job.\n                        Only applicable to jobs that do\
  \ not specify an\n                        explicit value for this requirement. Standard\
  \ suffixes\n                        like K, Ki, M, Mi, G or Gi are supported. Default\
  \ is\n                        2.0 Gi\n  --defaultCores FLOAT  The default number\
  \ of CPU cores to dedicate a job.\n                        Only applicable to jobs\
  \ that do not specify an\n                        explicit value for this requirement.\
  \ Fractions of a\n                        core (for example 0.1) are supported on\
  \ some batch\n                        systems, namely Mesos and singleMachine. Default\
  \ is\n                        1.0\n  --defaultDisk INT     The default amount of\
  \ disk space to dedicate a job.\n                        Only applicable to jobs\
  \ that do not specify an\n                        explicit value for this requirement.\
  \ Standard suffixes\n                        like K, Ki, M, Mi, G or Gi are supported.\
  \ Default is\n                        2.0 Gi\n  --defaultPreemptable\n  --maxCores\
  \ INT        The maximum number of CPU cores to request from the\n             \
  \           batch system at any one time. Standard suffixes like\n             \
  \           K, Ki, M, Mi, G or Gi are supported. Default is 8.0 Ei\n  --maxMemory\
  \ INT       The maximum amount of memory to request from the batch\n           \
  \             system at any one time. Standard suffixes like K, Ki,\n          \
  \              M, Mi, G or Gi are supported. Default is 8.0 Ei\n  --maxDisk INT\
  \         The maximum amount of disk space to request from the\n               \
  \         batch system at any one time. Standard suffixes like\n               \
  \         K, Ki, M, Mi, G or Gi are supported. Default is 8.0 Ei\n\ntoil options\
  \ for rescuing/killing/restarting jobs:\n  The options for jobs that either run\
  \ too long/fail or get lost (some batch\n  systems have issues!)\n\n  --retryCount\
  \ RETRYCOUNT\n                        Number of times to retry a failing job before\
  \ giving\n                        up and labeling job failed. default=1\n  --enableUnlimitedPreemptableRetries\n\
  \                        If set, preemptable failures (or any failure due to an\n\
  \                        instance getting unexpectedly terminated) would not\n \
  \                       count towards job failures and --retryCount.\n  --maxJobDuration\
  \ MAXJOBDURATION\n                        Maximum runtime of a job (in seconds)\
  \ before we kill\n                        it (this is a lower bound, and the actual\
  \ time before\n                        killing the job may be longer).\n       \
  \                 default=9223372036854775807\n  --rescueJobsFrequency RESCUEJOBSFREQUENCY\n\
  \                        Period of time to wait (in seconds) between checking\n\
  \                        for missing/overlong jobs, that is jobs which get lost\n\
  \                        by the batch system. Expert parameter. default=3600\n\n\
  Toil Miscellaneous Options:\n  Miscellaneous Options\n\n  --disableCaching [DISABLECACHING]\n\
  \                        Disables caching in the file store. This flag must be\n\
  \                        set to use a batch system that does not support\n     \
  \                   caching such as Grid Engine, Parasol, LSF, or Slurm\n  --disableChaining\
  \     Disables chaining of jobs (chaining uses one job's\n                     \
  \   resource allocation for its successor job if\n                        possible).\n\
  \  --disableJobStoreChecksumVerification\n                        Disables checksum\
  \ verification for files transferred\n                        to/from the job store.\
  \ Checksum verification is a\n                        safety check to ensure the\
  \ data is not corrupted\n                        during transfer. Currently only\
  \ supported for non-\n                        streaming AWS files.\n  --maxLogFileSize\
  \ MAXLOGFILESIZE\n                        The maximum size of a job log file to\
  \ keep (in bytes),\n                        log files larger than this will be truncated\
  \ to the\n                        last X bytes. Setting this option to zero will\
  \ prevent\n                        any truncation. Setting this option to a negative\n\
  \                        value will truncate from the beginning.Default=62.5 K\n\
  \  --writeLogs [WRITELOGS]\n                        Write worker logs received by\
  \ the leader into their\n                        own files at the specified path.\
  \ Any non-empty\n                        standard output and error from failed batch\
  \ system\n                        jobs will also be written into files at this path.\
  \ The\n                        current working directory will be used if a path\
  \ is\n                        not specified explicitly. Note: By default only the\n\
  \                        logs of failed jobs are returned to leader. Set log\n \
  \                       level to 'debug' or enable '--writeLogsFromAllJobs' to\n\
  \                        get logs back from successful jobs, and adjust\n      \
  \                  'maxLogFileSize' to control the truncation limit for\n      \
  \                  worker logs.\n  --writeLogsGzip [WRITELOGSGZIP]\n           \
  \             Identical to --writeLogs except the logs files are\n             \
  \           gzipped on the leader.\n  --writeLogsFromAllJobs\n                 \
  \       Whether to write logs from all jobs (including the\n                   \
  \     successful ones) without necessarily setting the log\n                   \
  \     level to 'debug'. Ensure that either --writeLogs or\n                    \
  \    --writeLogsGzip is set if enabling this option.\n  --realTimeLogging     Enable\
  \ real-time logging from workers to masters\n  --sseKey SSEKEY       Path to file\
  \ containing 32 character key to be used\n                        for server-side\
  \ encryption on awsJobStore or\n                        googleJobStore. SSE will\
  \ not be used if this flag is\n                        not passed.\n  --setEnv NAME=VALUE\
  \ or NAME, -e NAME=VALUE or NAME\n                        Set an environment variable\
  \ early on in the worker. If\n                        VALUE is omitted, it will\
  \ be looked up in the current\n                        environment. Independently\
  \ of this option, the worker\n                        will try to emulate the leader's\
  \ environment before\n                        running a job, except for some variables\
  \ known to vary\n                        across systems. Using this option, a variable\
  \ can be\n                        injected into the worker process itself before\
  \ it is\n                        started.\n  --servicePollingInterval SERVICEPOLLINGINTERVAL\n\
  \                        Interval of time service jobs wait between polling for\n\
  \                        the existence of the keep-alive flag (defailt=60)\n  --forceDockerAppliance\n\
  \                        Disables sanity checking the existence of the docker\n\
  \                        image specified by TOIL_APPLIANCE_SELF, which Toil\n  \
  \                      uses to provision mesos for autoscaling.\n  --disableProgress\
  \     Disables the progress bar shown when standard error is\n                 \
  \       a terminal.\n\ntoil debug options:\n  Debug options\n\n  --debugWorker \
  \        Experimental no forking mode for local debugging.\n                   \
  \     Specifically, workers are not forked and stderr/stdout\n                 \
  \       are not redirected to the log.\n  --disableWorkerOutputCapture\n       \
  \                 Let worker output go to worker's standard out/error\n        \
  \                instead of per-job logs.\n  --badWorker BADWORKER\n           \
  \             For testing purposes randomly kill 'badWorker'\n                 \
  \       proportion of jobs using SIGKILL, default=0.0\n  --badWorkerFailInterval\
  \ BADWORKERFAILINTERVAL\n                        When killing the job pick uniformly\
  \ within the\n                        interval from 0.0 to 'badWorkerFailInterval'\
  \ seconds\n                        after the worker starts, default=0.01\n\nOptions\
  \ for recording provenance information of the execution:\n  --provenance PROVENANCE\n\
  \                        Save provenance to specified folder as a Research\n   \
  \                     Object that captures and aggregates workflow execution\n \
  \                       and data products.\n  --enable-user-provenance\n       \
  \                 Record user account info as part of provenance.\n  --disable-user-provenance\n\
  \                        Do not record user account info in provenance.\n  --enable-host-provenance\n\
  \                        Record host info as part of provenance.\n  --disable-host-provenance\n\
  \                        Do not record host info in provenance.\n  --orcid ORCID\
  \         Record user ORCID identifier as part of provenance,\n                \
  \        e.g. https://orcid.org/0000-0002-1825-0097 or\n                       \
  \ 0000-0002-1825-0097. Alternatively the environment\n                        variable\
  \ ORCID may be set.\n  --full-name CWL_FULL_NAME\n                        Record\
  \ full name of user as part of provenance, e.g.\n                        Josiah\
  \ Carberry. You may need to use shell quotes to\n                        preserve\
  \ spaces. Alternatively the environment\n                        variable CWL_FULL_NAME\
  \ may be set.\n"
generated_using:
- --help
docker_image:
