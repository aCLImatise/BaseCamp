!Command
command:
- sequana_compressor
positional:
- !Positional
  optional: false
  position: 0
  name: Welcome
  description: ''
- !Positional
  optional: false
  position: 1
  name: to
  description: ''
- !Positional
  optional: false
  position: 2
  name: SEQUANA
  description: ''
named:
- !Flag
  optional: true
  synonyms:
  - --source
  - --target
  description: be provided but no analysis will be performed
  args: !SimpleFlagArg
    name: and
- !Flag
  optional: true
  synonyms:
  - --quiet
  description: set verbosity off
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --recursive
  description: recursive search
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --dryrun
  description: Do not execute anything
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --threads
  description: Maximum number of threads to use per task (4).
  args: !SimpleFlagArg
    name: THREADS
- !Flag
  optional: true
  synonyms:
  - --jobs
  description: Maximum number of cores to use at the same time (4).
  args: !SimpleFlagArg
    name: JOBS
- !Flag
  optional: true
  synonyms:
  - --bypass-job-limit
  description: "The number of jobs is limited to 20 to limit IO. If\nyou want to bypass\
    \ this limitation, use this option."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --unlock
  description: "If you stopped the application, the underlying\nsnakemake process\
    \ are interrupted and directories were\nsnakemake was launch will be locked. If\
    \ so please use\nthis option using the --source and --target as when\nyou got\
    \ the error message"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --snakemake-options
  description: "Any valid list of options accepted by snakemake except\n-s and -j\
    \ (for -j, use our --jobs argument). Note that\nby default --keep-going is used\
    \ ; If you set this\nargument yourself, you have to add --keep-going as\nwell\
    \ otherwise it stops at the first error encountered"
  args: !SimpleFlagArg
    name: SNAKEMAKE
- !Flag
  optional: true
  synonyms:
  - --snakemake-cluster
  description: "a valid snakemake option dedicated to a cluster.\ne.g on LSF cluster\
    \ use:\n--cluster 'qsub -cwd -q<QUEUE> '\nOn a SLURM system use for example:\n\
    --cluster 'sbatch --qos normal'\n"
  args: !SimpleFlagArg
    name: CLUSTER
parent:
subcommands: []
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag: !Flag
  optional: true
  synonyms:
  - --version
  description: print version
  args: !EmptyFlagArg {}
help_text: "usage: Welcome to SEQUANA - Fastq compression standalone\n\n    This standalone\
  \ fetches recursively all files in a given format (--source)\n    and transform\
  \ them into another format (--target)\n\n    Compression supported ar gz, bz2 and\
  \ dsrc. Note that one must add\n    \"fastq\" in the extension as shown in the following\
  \ examples:\n\n        sequana_compressor --source fastq.gz   --target fastq.bz2\n\
  \        sequana_compressor --source fastq      --target fastq.bz2\n        sequana_compressor\
  \ --source fastq.gz   --target fastq\n        sequana_compressor --source fastq.bz2\
  \  --target fastq\n\n    If your job(s) were interrupted (ctrl+C), your directories\
  \ will most\n    probably be locked. Use the --unlock option in such situations.\n\
  \n        sequana_compressor --source ... --target ... --unlock\n\n    --source\
  \ and --target must be provided but no analysis will be performed\n    at that stage.\n\
  \n    Then, type your command again.\n\n    Note for IP users: if compressor is\
  \ launch on Institut Pasteur Cluster\n        (tars), the --snakemake-options must\
  \ be used to provide the slurm\n        sbatch command (see help below for example).\n\
  \n    Note for CLUSTER usage: consider an example where we request 4 jobs (default)\
  \ \n    and 4 threads (default). Each job is laucnhed independently. Yet, with a\n\
  \    scheduler like SLURM, it is highly possible that the requested resources \n\
  \    will occur on the same node if that node has 4 cpus starting 16 threads in\n\
  \    total irrespective of the current occupation by other users. \n    For SLURM\
  \ scheduler, once can provide an option to look for nodes that have \n    at least\
  \ 4 cpus (threads) available. The option is -c. So, please use\n\n        sbatch\
  \ -c 4\n\n    in such case.\n    \n\nAUTHORS: Thomas Cokelaer\nDocumentation: http://sequana.readthedocs.io\n\
  Issues: http://github.com/sequana/sequana\n\nDESCRIPTION:\n\noptional arguments:\n\
  \  -h, --help            show this help message and exit\n  --version          \
  \   print version\n  --quiet               set verbosity off\n\nINPUT/OUTPUT:\n\
  \  --source SOURCE       Search for all source files with this extension. Valid\n\
  \                        extensions are: fastq, fastq.gz, fastq.bz2,\n         \
  \               fastq.dscr, fq, fq.gz, fq.bz2 and fq.dsrc\n  --target TARGET   \
  \    Convert the source files to a new target format. Same\n                   \
  \     extensions as above.\n  --recursive           recursive search\n  --dryrun\
  \              Do not execute anything\n\nJOBS RELATED (threads/cores):\n  --threads\
  \ THREADS     Maximum number of threads to use per task (4).\n  --jobs JOBS    \
  \       Maximum number of cores to use at the same time (4).\n  --bypass-job-limit\
  \    The number of jobs is limited to 20 to limit IO. If\n                     \
  \   you want to bypass this limitation, use this option.\n\nSNAKEMAKE RELATED:\n\
  \  --unlock              If you stopped the application, the underlying\n      \
  \                  snakemake process are interrupted and directories were\n    \
  \                    snakemake was launch will be locked. If so please use\n   \
  \                     this option using the --source and --target as when\n    \
  \                    you got the error message\n  --snakemake-options SNAKEMAKE\n\
  \                        Any valid list of options accepted by snakemake except\n\
  \                        -s and -j (for -j, use our --jobs argument). Note that\n\
  \                        by default --keep-going is used ; If you set this\n   \
  \                     argument yourself, you have to add --keep-going as\n     \
  \                   well otherwise it stops at the first error encountered\n\nCLUSTER:\n\
  \  --snakemake-cluster CLUSTER\n                        a valid snakemake option\
  \ dedicated to a cluster.  \n                        e.g on LSF cluster use:\n \
  \                           --cluster 'qsub -cwd -q<QUEUE> '\n                 \
  \       \n                        On a SLURM system use for example:\n         \
  \               \n                            --cluster 'sbatch --qos normal'\n\
  \                        \n"
generated_using:
- --help
docker_image:
