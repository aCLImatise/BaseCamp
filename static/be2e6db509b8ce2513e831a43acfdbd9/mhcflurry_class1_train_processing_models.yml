!Command
command:
- mhcflurry-class1-train-processing-models
positional:
- !Positional
  description: --max-epochs N        Max training epochs. If specified here it overrides
  position: 0
  name: train.
  optional: false
named:
- !Flag
  description: "Training data CSV. Expected columns: peptide, n_flank,\nc_flank, hit"
  synonyms:
  - --data
  args: !SimpleFlagArg
    name: FILE.csv
  optional: true
- !Flag
  description: Directory to write models and manifest
  synonyms:
  - --out-models-dir
  args: !SimpleFlagArg
    name: DIR
  optional: true
- !Flag
  description: JSON or YAML of hyperparameters
  synonyms:
  - --hyperparameters
  args: !SimpleFlagArg
    name: FILE.json
  optional: true
- !Flag
  description: Number of experiments to hold out per fold
  synonyms:
  - --held-out-samples
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: Number of training folds.
  synonyms:
  - --num-folds
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: Number of replicates per (architecture, fold) pair to
  synonyms:
  - --num-replicates
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: 'Keras verbosity. Default: 0'
  synonyms:
  - --verbosity
  args: !SimpleFlagArg
    name: VERBOSITY
  optional: true
- !Flag
  description: Launch python debugger on error
  synonyms:
  - --debug
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Continue training models from an incomplete training\nrun. If this\
    \ is specified then the only required\nargument is --out-models-dir"
  synonyms:
  - --continue-incomplete
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Do not actually train models. The initialized run can\nbe continued\
    \ later with --continue-incomplete."
  synonyms:
  - --only-initialize
  args: !EmptyFlagArg {}
  optional: true
- !Flag
  description: "Number of local processes to parallelize training\nover. Set to 0\
    \ for serial run. Default: 0."
  synonyms:
  - --num-jobs
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: "Keras backend. If not specified will use system\ndefault."
  synonyms:
  - --backend
  args: !ChoiceFlagArg
    choices: !!set
      tensorflow-gpu:
      tensorflow-default:
      tensorflow-cpu:
  optional: true
- !Flag
  description: "Number of GPUs to attempt to parallelize across.\nRequires running\
    \ in parallel."
  synonyms:
  - --gpus
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: "Maximum number of workers to assign to a GPU.\nAdditional tasks will\
    \ run on CPU."
  synonyms:
  - --max-workers-per-gpu
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: "Restart workers after N tasks. Workaround for\ntensorflow memory leaks.\
    \ Requires Python >=3.2."
  synonyms:
  - --max-tasks-per-worker
  args: !SimpleFlagArg
    name: N
  optional: true
- !Flag
  description: "Write worker stdout and stderr logs to given\ndirectory."
  synonyms:
  - --worker-log-dir
  args: !SimpleFlagArg
    name: WORKER_LOG_DIR
  optional: true
parent:
subcommands: []
usage: []
help_flag: !Flag
  description: show this help message and exit
  synonyms:
  - -h
  - --help
  args: !EmptyFlagArg {}
  optional: true
usage_flag:
version_flag:
help_text: "To show stack trace, run:\nkill -s USR1 307\nusage: \nTrain Class1 processing\
  \ models.\n\noptional arguments:\n  -h, --help            show this help message\
  \ and exit\n  --data FILE.csv       Training data CSV. Expected columns: peptide,\
  \ n_flank,\n                        c_flank, hit\n  --out-models-dir DIR  Directory\
  \ to write models and manifest\n  --hyperparameters FILE.json\n                \
  \        JSON or YAML of hyperparameters\n  --held-out-samples N  Number of experiments\
  \ to hold out per fold\n  --num-folds N         Number of training folds.\n  --num-replicates\
  \ N    Number of replicates per (architecture, fold) pair to\n                 \
  \       train.\n  --max-epochs N        Max training epochs. If specified here it\
  \ overrides\n                        any 'max_epochs' specified in the hyperparameters.\n\
  \  --verbosity VERBOSITY\n                        Keras verbosity. Default: 0\n\
  \  --debug               Launch python debugger on error\n  --continue-incomplete\n\
  \                        Continue training models from an incomplete training\n\
  \                        run. If this is specified then the only required\n    \
  \                    argument is --out-models-dir\n  --only-initialize     Do not\
  \ actually train models. The initialized run can\n                        be continued\
  \ later with --continue-incomplete.\n\nLocal parallelism:\n  --num-jobs N      \
  \    Number of local processes to parallelize training\n                       \
  \ over. Set to 0 for serial run. Default: 0.\n  --backend {tensorflow-gpu,tensorflow-cpu,tensorflow-default}\n\
  \                        Keras backend. If not specified will use system\n     \
  \                   default.\n  --gpus N              Number of GPUs to attempt\
  \ to parallelize across.\n                        Requires running in parallel.\n\
  \  --max-workers-per-gpu N\n                        Maximum number of workers to\
  \ assign to a GPU.\n                        Additional tasks will run on CPU.\n\
  \  --max-tasks-per-worker N\n                        Restart workers after N tasks.\
  \ Workaround for\n                        tensorflow memory leaks. Requires Python\
  \ >=3.2.\n  --worker-log-dir WORKER_LOG_DIR\n                        Write worker\
  \ stdout and stderr logs to given\n                        directory.\n\nCluster\
  \ parallelism:\n  --cluster-parallelism\n  --cluster-submit-command CLUSTER_SUBMIT_COMMAND\n\
  \                        Default: sh\n  --cluster-results-workdir CLUSTER_RESULTS_WORKDIR\n\
  \                        Default: ./cluster-workdir\n  --additional-complete-file\
  \ ADDITIONAL_COMPLETE_FILE\n                        Additional file to monitor for\
  \ job completion.\n                        Default: STDERR\n  --cluster-script-prefix-path\
  \ CLUSTER_SCRIPT_PREFIX_PATH\n  --cluster-max-retries CLUSTER_MAX_RETRIES\n    \
  \                    How many times to rerun failing jobs. Default: 3\n"
generated_using:
- --help
