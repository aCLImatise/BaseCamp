from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import File, Boolean, Int, String, Directory

Caper_Run_V0_1_0 = CommandToolBuilder(tool="caper_run", base_command=["caper", "run"], inputs=[ToolInput(tag="in_conf", input_type=File(optional=True), prefix="--conf", doc=InputDocumentation(doc="Specify config file")), ToolInput(tag="in_debug", input_type=Boolean(optional=True), prefix="--debug", doc=InputDocumentation(doc="Prints all logs >= DEBUG level")), ToolInput(tag="in_gcp_service_account_key_json", input_type=File(optional=True), prefix="--gcp-service-account-key-json", doc=InputDocumentation(doc="Secret key JSON file for Google Cloud Platform service\naccount. This service account should have enough\npermission to Storage for client functions and\nStorage/Compute Engine/Genomics API/Life Sciences API\nfor server/runner functions.")), ToolInput(tag="in_inputs", input_type=File(optional=True), prefix="--inputs", doc=InputDocumentation(doc="Workflow inputs JSON file")), ToolInput(tag="in_options", input_type=File(optional=True), prefix="--options", doc=InputDocumentation(doc="Workflow options JSON file")), ToolInput(tag="in_labels", input_type=File(optional=True), prefix="--labels", doc=InputDocumentation(doc="Workflow labels JSON file")), ToolInput(tag="in_imports", input_type=File(optional=True), prefix="--imports", doc=InputDocumentation(doc="Zip file of imported subworkflows")), ToolInput(tag="in_str_label", input_type=File(optional=True), prefix="--str-label", doc=InputDocumentation(doc="Caper's special label for a workflow This label will\nbe added to a workflow labels JSON file as a value for\na key 'caper-label'. DO NOT USE IRREGULAR CHARACTERS.\nUSE LETTERS, NUMBERS, DASHES AND UNDERSCORES ONLY\n(^[A-Za-z0-9\-\_]+$) since this label is used to\ncompose a path for workflow's temporary/cache\ndirectory (.caper_tmp/label/timestamp/)")), ToolInput(tag="in_hold", input_type=Boolean(optional=True), prefix="--hold", doc=InputDocumentation(doc="Put a hold on a workflow when submitted to a Cromwell")), ToolInput(tag="in_use_gs_util_for_s_three", input_type=Boolean(optional=True), prefix="--use-gsutil-for-s3", doc=InputDocumentation(doc="Use gsutil CLI for direct trasnfer between S3 and GCS\nbuckets. Otherwise, such file transfer will stream\nthrough local machine. Make sure that gsutil is\ninstalled on your system and it has access to\ncredentials for AWS (e.g. ~/.boto or\n~/.aws/credentials).")), ToolInput(tag="in_no_deepcopy", input_type=Boolean(optional=True), prefix="--no-deepcopy", doc=InputDocumentation(doc="(IMPORTANT) --deepcopy has been deprecated.\nDeepcopying is now activated by default. This flag\ndisables deepcopy for JSON (.json), TSV (.tsv) and CSV\n(.csv) files specified in an input JSON file\n(--inputs). Find all path/URI string values in an\ninput JSON file and make copies of files on a\nlocal/remote storage for a target backend. Make sure\nthat you have installed gsutil for GCS and aws for S3.")), ToolInput(tag="in_ignore_wom_tool", input_type=Boolean(optional=True), prefix="--ignore-womtool", doc=InputDocumentation(doc="Ignore warnings from womtool.jar.")), ToolInput(tag="in_wom_tool", input_type=File(optional=True), prefix="--womtool", doc=InputDocumentation(doc="Path or URL for Cromwell's womtool JAR file")), ToolInput(tag="in_java_heap_wom_tool", input_type=Int(optional=True), prefix="--java-heap-womtool", doc=InputDocumentation(doc="Java heap size for Womtool (java -Xmx)")), ToolInput(tag="in_max_retries", input_type=Int(optional=True), prefix="--max-retries", doc=InputDocumentation(doc="Number of retries for failing tasks. equivalent to\n'maxRetries' in workflow options JSON file.")), ToolInput(tag="in_metadata_output", input_type=File(optional=True), prefix="--metadata-output", doc=InputDocumentation(doc="An optional directory path to output metadata JSON\nfile")), ToolInput(tag="in_java_heap_run", input_type=Int(optional=True), prefix="--java-heap-run", doc=InputDocumentation(doc="Cromwell Java heap size for 'run' mode (java -Xmx)")), ToolInput(tag="in_cromwell_stdout", input_type=File(optional=True), prefix="--cromwell-stdout", doc=InputDocumentation(doc="Local file to write STDOUT of Cromwell Java process\nto. This is for Cromwell (not for Caper's logging\nsystem). Note that STDERR is redirected to STDOUT.")), ToolInput(tag="in_backend", input_type=String(optional=True), prefix="--backend", doc=InputDocumentation(doc="Backend to run a workflow")), ToolInput(tag="in_dry_run", input_type=Boolean(optional=True), prefix="--dry-run", doc=InputDocumentation(doc="Caper localizes remote files and validates WDL but\ndoes not run/submit a pipeline.")), ToolInput(tag="in_local_loc_dir", input_type=Directory(optional=True), prefix="--local-loc-dir", doc=InputDocumentation(doc="Temporary directory to store Cromwell's intermediate\nbackend files. These files include backend.conf,\nworkflow_opts.json, imports.zip. and localized input\nJSON files due to deepcopying (recursive\nlocalization). Cromwell's MySQL/PostgreSQL DB password\ncan be exposed on backend.conf on this directory.\nTherefore, DO NOT USE /tmp HERE. This directory is\nalso used for storing cached files for\nlocal/slurm/sge/pbs backends.")), ToolInput(tag="in_tmp_gcs_bucket", input_type=Directory(optional=True), prefix="--tmp-gcs-bucket", doc=InputDocumentation(doc="Temporary directory to store cached files for gcp\nbackend. e.g. gs://my-bucket/caper-cache-dir.")), ToolInput(tag="in_tmp_s_three_bucket", input_type=Int(optional=True), prefix="--tmp-s3-bucket", doc=InputDocumentation(doc="Temporary directory to store cached files for aws\nbackend. e.g. s3://my-bucket/caper-cache-dir.")), ToolInput(tag="in_docker", input_type=Boolean(optional=True), prefix="--docker", doc=InputDocumentation(doc="[DOCKER]     URI for Docker image (e.g. ubuntu:latest). This can\nalso be used as a flag to use Docker image address\ndefined in your WDL file as a comment ('#CAPER\ndocker') or as 'workflow.meta.caper_docker' in WDL.")), ToolInput(tag="in_singularity", input_type=Boolean(optional=True), prefix="--singularity", doc=InputDocumentation(doc="[SINGULARITY]\nURI or path for Singularity image (e.g.\n~/.singularity/ubuntu-latest.simg,\ndocker://ubuntu:latest, shub://vsoch/hello-world).\nThis can also be used as a flag to use Docker image\naddress defined in your WDL file as a comment ('#CAPER\nsingularity') or as 'workflow.meta.caper_singularity'\nin WDL.")), ToolInput(tag="in_no_build_singularity", input_type=Boolean(optional=True), prefix="--no-build-singularity", doc=InputDocumentation(doc="Do not build singularity image before running a\nworkflow.")), ToolInput(tag="in_slur_m_partition", input_type=String(optional=True), prefix="--slurm-partition", doc=InputDocumentation(doc="SLURM partition")), ToolInput(tag="in_slur_m_account", input_type=String(optional=True), prefix="--slurm-account", doc=InputDocumentation(doc="SLURM account")), ToolInput(tag="in_slur_m_extra_param", input_type=String(optional=True), prefix="--slurm-extra-param", doc=InputDocumentation(doc="SLURM extra parameters. Must be double-quoted")), ToolInput(tag="in_sge_pe", input_type=String(optional=True), prefix="--sge-pe", doc=InputDocumentation(doc="SGE parallel environment. Check with 'qconf -spl'")), ToolInput(tag="in_sge_queue", input_type=String(optional=True), prefix="--sge-queue", doc=InputDocumentation(doc="SGE queue. Check with 'qconf -sql'")), ToolInput(tag="in_sge_extra_param", input_type=String(optional=True), prefix="--sge-extra-param", doc=InputDocumentation(doc="SGE extra parameters. Must be double-quoted")), ToolInput(tag="in_pbs_queue", input_type=String(optional=True), prefix="--pbs-queue", doc=InputDocumentation(doc="PBS queue")), ToolInput(tag="in_pbs_extra_param", input_type=String(optional=True), prefix="--pbs-extra-param", doc=InputDocumentation(doc="PBS extra parameters. Must be double-quoted")), ToolInput(tag="in_db", input_type=String(optional=True), prefix="--db", doc=InputDocumentation(doc="Cromwell metadata database type")), ToolInput(tag="in_db_timeout", input_type=String(optional=True), prefix="--db-timeout", doc=InputDocumentation(doc="Milliseconds to wait for DB connection.")), ToolInput(tag="in_file_db", input_type=File(optional=True), prefix="--file-db", doc=InputDocumentation(doc="Default DB file for Cromwell's built-in HyperSQL\ndatabase.")), ToolInput(tag="in_mysql_db_ip", input_type=String(optional=True), prefix="--mysql-db-ip", doc=InputDocumentation(doc="MySQL Database IP address (e.g. localhost)")), ToolInput(tag="in_mysql_db_port", input_type=Int(optional=True), prefix="--mysql-db-port", doc=InputDocumentation(doc="MySQL Database TCP/IP port (e.g. 3306)")), ToolInput(tag="in_mysql_db_user", input_type=String(optional=True), prefix="--mysql-db-user", doc=InputDocumentation(doc="MySQL DB username")), ToolInput(tag="in_mysql_db_password", input_type=String(optional=True), prefix="--mysql-db-password", doc=InputDocumentation(doc="MySQL DB password")), ToolInput(tag="in_mysql_db_name", input_type=String(optional=True), prefix="--mysql-db-name", doc=InputDocumentation(doc="MySQL DB name for Cromwell")), ToolInput(tag="in_postgresql_db_ip", input_type=String(optional=True), prefix="--postgresql-db-ip", doc=InputDocumentation(doc="PostgreSQL DB IP address (e.g. localhost)")), ToolInput(tag="in_postgresql_db_port", input_type=Int(optional=True), prefix="--postgresql-db-port", doc=InputDocumentation(doc="PostgreSQL DB TCP/IP port (e.g. 5432)")), ToolInput(tag="in_postgresql_db_user", input_type=String(optional=True), prefix="--postgresql-db-user", doc=InputDocumentation(doc="PostgreSQL DB username")), ToolInput(tag="in_postgresql_db_password", input_type=String(optional=True), prefix="--postgresql-db-password", doc=InputDocumentation(doc="PostgreSQL DB password")), ToolInput(tag="in_postgresql_db_name", input_type=String(optional=True), prefix="--postgresql-db-name", doc=InputDocumentation(doc="PostgreSQL DB name for Cromwell")), ToolInput(tag="in_cromwell", input_type=File(optional=True), prefix="--cromwell", doc=InputDocumentation(doc="Path or URL for Cromwell JAR file")), ToolInput(tag="in_max_concurrent_tasks", input_type=Int(optional=True), prefix="--max-concurrent-tasks", doc=InputDocumentation(doc="Number of concurrent tasks. 'config.concurrent-job-\nlimit' in Cromwell backend configuration for each\nbackend")), ToolInput(tag="in_max_concurrent_workflows", input_type=Int(optional=True), prefix="--max-concurrent-workflows", doc=InputDocumentation(doc="Number of concurrent workflows. 'system.max-\nconcurrent-workflows' in backend configuration")), ToolInput(tag="in_disable_call_caching", input_type=Boolean(optional=True), prefix="--disable-call-caching", doc=InputDocumentation(doc="Disable Cromwell's call caching, which re-uses outputs\nfrom previous workflows")), ToolInput(tag="in_backend_file", input_type=File(optional=True), prefix="--backend-file", doc=InputDocumentation(doc="Custom Cromwell backend configuration file to override\nall")), ToolInput(tag="in_soft_glob_output", input_type=Boolean(optional=True), prefix="--soft-glob-output", doc=InputDocumentation(doc="Use soft-linking when globbing outputs for a\nfilesystem that does not allow hard-linking. e.g.\nbeeGFS. This flag does not work with backends based on\na Docker container. i.e. gcp and aws. Also, it does\nnot work with local backends (local/slurm/sge/pbs)\nwith --. However, it works fine with --singularity.")), ToolInput(tag="in_local_hash_strat", input_type=Boolean(optional=True), prefix="--local-hash-strat", doc=InputDocumentation(doc="{file,path,path+modtime}\nFile hashing strategy for call caching. For local\nbackends (local/slurm/sge/pbs) only. file: use md5sum\nhash (slow), path: use path only, path+modtime\n(default): use path + mtime.")), ToolInput(tag="in_local_out_dir", input_type=File(optional=True), prefix="--local-out-dir", doc=InputDocumentation(doc="Output directory path for local backend. Cloud\nbackends (gcp, aws) use different output directories.\nFor gcp, define --gcp-out-dir. For aws, define --aws-\nout-dir.")), ToolInput(tag="in_gcp_prj", input_type=String(optional=True), prefix="--gcp-prj", doc=InputDocumentation(doc="GC project")), ToolInput(tag="in_gcp_memory_retry_error_keys", input_type=Int(optional=True), prefix="--gcp-memory-retry-error-keys", doc=InputDocumentation(doc="If an error caught by these comma-separated keys\noccurs, then increase memory by --gcp-memory-retry-\nmultiplier for retrials controlled by --max-retries.\nSee https://cromwell.readthedocs.io/en/stable/backends\n/Google/ for details.")), ToolInput(tag="in_gcp_memory_retry_multiplier", input_type=Int(optional=True), prefix="--gcp-memory-retry-multiplier", doc=InputDocumentation(doc="If an error caught by --gcp-memory-retry-error-keys\noccurs, then increase memory by this for retrials\ncontrolled by --max-retries. See https://cromwell.read\nthedocs.io/en/stable/backends/Google/ for details.")), ToolInput(tag="in_gcp_region", input_type=String(optional=True), prefix="--gcp-region", doc=InputDocumentation(doc="GCP region for Google Cloud Life Sciences API. This is\nused only when --use-google-cloud-life-sciences is\ndefined.")), ToolInput(tag="in_gcp_call_caching_dup_strat", input_type=String(optional=True), prefix="--gcp-call-caching-dup-strat", doc=InputDocumentation(doc="Duplication strategy for call-cached outputs for GCP\nbackend: copy: make a copy, reference: refer to old\noutput in metadata.json.")), ToolInput(tag="in_out_gcs_bucket", input_type=File(optional=True), prefix="--out-gcs-bucket", doc=InputDocumentation(doc="Output directory path for GCP backend. e.g. gs://my-\nbucket/my-output.")), ToolInput(tag="in_aws_batch_arn", input_type=String(optional=True), prefix="--aws-batch-arn", doc=InputDocumentation(doc="ARN for AWS Batch")), ToolInput(tag="in_aws_region", input_type=Int(optional=True), prefix="--aws-region", doc=InputDocumentation(doc="AWS region (e.g. us-west-1)")), ToolInput(tag="in_out_s_three_bucket", input_type=File(optional=True), prefix="--out-s3-bucket", doc=InputDocumentation(doc="Output path on S3 bucket for AWS backend. e.g.\ns3://my-bucket/my-output.")), ToolInput(tag="in_use_google_cloud_life_sciences", input_type=Boolean(optional=True), prefix="--use-google-cloud-life-sciences", doc=InputDocumentation(doc="Use Google Cloud Life Sciences API (v2beta) instead of\ndeprecated Genomics API (v2alpha1).Life Sciences API\nrequires only one region specified withgcp-region.\ngcp-zones will be ignored since it is for Genomics\nAPI.See https://cloud.google.com/life-\nsciences/docs/concepts/locations for supported\nregions.")), ToolInput(tag="in_gcp_zones", input_type=Int(optional=True), prefix="--gcp-zones", doc=InputDocumentation(doc="Comma-separated GCP zones used for Genomics API. (e.g.\nus-west1-b,us-central1-b). If you use --use-google-\ncloud-life-sciences then define --gcp-region instead.\n")), ToolInput(tag="in_server_dot", input_type=String(), position=0, doc=InputDocumentation(doc="--singularity-cachedir SINGULARITY_CACHEDIR"))], outputs=[ToolOutput(tag="out_metadata_output", output_type=File(optional=True), selector=InputSelector(input_to_select="in_metadata_output", type_hint=File()), doc=OutputDocumentation(doc="An optional directory path to output metadata JSON\nfile")), ToolOutput(tag="out_local_out_dir", output_type=File(optional=True), selector=InputSelector(input_to_select="in_local_out_dir", type_hint=File()), doc=OutputDocumentation(doc="Output directory path for local backend. Cloud\nbackends (gcp, aws) use different output directories.\nFor gcp, define --gcp-out-dir. For aws, define --aws-\nout-dir.")), ToolOutput(tag="out_out_gcs_bucket", output_type=File(optional=True), selector=InputSelector(input_to_select="in_out_gcs_bucket", type_hint=File()), doc=OutputDocumentation(doc="Output directory path for GCP backend. e.g. gs://my-\nbucket/my-output.")), ToolOutput(tag="out_out_s_three_bucket", output_type=File(optional=True), selector=InputSelector(input_to_select="in_out_s_three_bucket", type_hint=File()), doc=OutputDocumentation(doc="Output path on S3 bucket for AWS backend. e.g.\ns3://my-bucket/my-output."))], container="quay.io/biocontainers/caper:1.1.0--py_0", version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Caper_Run_V0_1_0().translate("wdl")

