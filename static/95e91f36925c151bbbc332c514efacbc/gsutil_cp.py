from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import String, Boolean, File

Gsutil_Cp_V0_1_0 = CommandToolBuilder(tool="gsutil_cp", base_command=["gsutil", "cp"], inputs=[ToolInput(tag="in_sets_named_cannedacl", input_type=String(optional=True), prefix="-a", doc=InputDocumentation(doc="Sets named canned_acl when uploaded objects created. See\n'gsutil help acls' for further details.")), ToolInput(tag="in_copy_source_versions", input_type=Boolean(optional=True), prefix="-A", doc=InputDocumentation(doc="Copy all source versions from a source buckets/folders.\nIf not set, only the live version of each source object is\ncopied. Note: this option is only useful when the destination\nbucket has versioning enabled.")), ToolInput(tag="in_error_occurs_continue", input_type=Boolean(optional=True), prefix="-c", doc=InputDocumentation(doc="If an error occurs, continue to attempt to copy the remaining\nfiles. If any copies were unsuccessful, gsutil's exit status\nwill be non-zero even if this flag is set. This option is\nimplicitly set when running 'gsutil -m cp...'. Note: -c only\napplies to the actual copying operation. If an error occurs\nwhile iterating over the files in the local directory (e.g.,\ninvalid Unicode file name) gsutil will print an error message\nand abort.")), ToolInput(tag="in_copy_mode_ie", input_type=Boolean(optional=True), prefix="-D", doc=InputDocumentation(doc="Copy in 'daisy chain' mode, i.e., copying between two buckets\nby hooking a download to an upload, via the machine where\ngsutil is run. This stands in contrast to the default, where\ndata are copied between two buckets 'in the cloud', i.e.,\nwithout needing to copy via the machine where gsutil runs.\nBy default, a 'copy in the cloud' when the source is a\ncomposite object will retain the composite nature of the\nobject. However, Daisy chain mode can be used to change a\ncomposite object into a non-composite object. For example:\ngsutil cp -D -p gs://bucket/obj gs://bucket/obj_tmp\ngsutil mv -p gs://bucket/obj_tmp gs://bucket/obj\nNote: Daisy chain mode is automatically used when copying\nbetween providers (e.g., to copy data from Google Cloud Storage\nto another provider).")), ToolInput(tag="in_exclude_symlinks_specified", input_type=Boolean(optional=True), prefix="-e", doc=InputDocumentation(doc="Exclude symlinks. When specified, symbolic links will not be")), ToolInput(tag="in_outputs_manifest_file", input_type=File(optional=True), prefix="-L", doc=InputDocumentation(doc="Outputs a manifest log file with detailed information about\neach item that was copied. This manifest contains the following\ninformation for each item:\n- Source path.\n- Destination path.\n- Source size.\n- Bytes transferred.\n- MD5 hash.\n- UTC date and time transfer was started in ISO 8601 format.\n- UTC date and time transfer was completed in ISO 8601 format.\n- Upload id, if a resumable upload was performed.\n- Final result of the attempted transfer, success or failure.\n- Failure details, if any.\nIf the log file already exists, gsutil will use the file as an\ninput to the copy process, and will also append log items to\nthe existing file. Files/objects that are marked in the\nexisting log file as having been successfully copied (or\nskipped) will be ignored. Files/objects without entries will be\ncopied and ones previously marked as unsuccessful will be\nretried. This can be used in conjunction with the -c option to\nbuild a script that copies a large number of objects reliably,\nusing a bash script like the following:\nuntil gsutil cp -c -L cp.log -r ./dir gs://bucket; do\nsleep 1\ndone\nThe -c option will cause copying to continue after failures\noccur, and the -L option will allow gsutil to pick up where it\nleft off without duplicating work. The loop will continue\nrunning as long as gsutil exits with a non-zero status (such a\nstatus indicates there was at least one failure during the\ngsutil run).\nNote: If you're trying to synchronize the contents of a\ndirectory and a bucket (or two buckets), see\n'gsutil help rsync'.")), ToolInput(tag="in_noclobber_when_specified", input_type=Boolean(optional=True), prefix="-n", doc=InputDocumentation(doc="No-clobber. When specified, existing files or objects at the\ndestination will not be overwritten. Any items that are skipped\nby this option will be reported as being skipped. This option\nwill perform an additional GET request to check if an item\nexists before attempting to upload the data. This will save\nretransmitting data, but the additional HTTP requests may make\nsmall object transfers slower and more expensive.")), ToolInput(tag="in_causes_acls_preserved", input_type=Boolean(optional=True), prefix="-p", doc=InputDocumentation(doc="Causes ACLs to be preserved when copying in the cloud. Note\nthat this option has performance and cost implications when\nusing  the XML API, as it requires separate HTTP calls for\ninteracting with ACLs. (There are no such performance or cost\nimplications when using the -p option with the JSON API.) The\nperformance issue can be mitigated to some degree by using\ngsutil -m cp to cause parallel copying. Note that this option\nonly works if you have OWNER access to all of the objects that\nare copied.\nYou can avoid the additional performance and cost of using\ncp -p if you want all objects in the destination bucket to end\nup with the same ACL by setting a default object ACL on that\nbucket instead of using cp -p. See 'gsutil help defacl'.\nNote that it's not valid to specify both the -a and -p options\ntogether.")), ToolInput(tag="in_causes_posix_attributes", input_type=Boolean(optional=True), prefix="-P", doc=InputDocumentation(doc="Causes POSIX attributes to be preserved when objects are\ncopied. With this feature enabled, gsutil cp will copy fields\nprovided by stat. These are the user ID of the owner, the group\nID of the owning group, the mode (permissions) of the file, and\nthe access/modification time of the file. For downloads, these\nattributes will only be set if the source objects were uploaded\nwith this flag enabled.\nOn Windows, this flag will only set and restore access time and\nmodification time. This is because Windows doesn't have a\nnotion of POSIX uid/gid/mode.")), ToolInput(tag="in_r_r_options", input_type=Boolean(optional=True), prefix="-R", doc=InputDocumentation(doc="The -R and -r options are synonymous. Causes directories,\nbuckets, and bucket subdirectories to be copied recursively.\nIf you neglect to use this option for an upload, gsutil will\ncopy any files it finds and skip any directories. Similarly,\nneglecting to specify this option for a download will cause\ngsutil to copy any objects at the current bucket directory\nlevel, and skip any subdirectories.")), ToolInput(tag="in_storage_class_destination", input_type=String(optional=True), prefix="-s", doc=InputDocumentation(doc="The storage class of the destination object(s). If not\nspecified, the default storage class of the destination bucket\nis used. Not valid for copying to non-cloud destinations.")), ToolInput(tag="in_skip_objects_objects", input_type=Boolean(optional=True), prefix="-U", doc=InputDocumentation(doc="Skip objects with unsupported object types instead of failing.\nUnsupported object types are Amazon S3 Objects in the GLACIER\nstorage class.")), ToolInput(tag="in_requests_given_make", input_type=Boolean(optional=True), prefix="-v", doc=InputDocumentation(doc="Requests that the version-specific URL for each uploaded object\nbe printed. Given this URL you can make future upload requests\nthat are safe in the face of concurrent updates, because Google\nCloud Storage will refuse to perform the update if the current\nobject version doesn't match the version-specific URL. See\n'gsutil help versions' for more details.")), ToolInput(tag="in_ext_applies_gzip", input_type=Boolean(optional=True), prefix="-z", doc=InputDocumentation(doc="<ext,...>   Applies gzip content-encoding to any file upload whose\nextension matches the -z extension list. This is useful when\nuploading files with compressible content (such as .js, .css,\nor .html files) because it saves network bandwidth and space\nin Google Cloud Storage, which in turn reduces storage costs.\nWhen you specify the -z option, the data from your files is\ncompressed before it is uploaded, but your actual files are\nleft uncompressed on the local disk. The uploaded objects\nretain the Content-Type and name of the original files but are\ngiven a Content-Encoding header with the value 'gzip' to\nindicate that the object data stored are compressed on the\nGoogle Cloud Storage servers.\nFor example, the following command:\ngsutil cp -z html -a public-read \\ncattypes.html tabby.jpeg gs://mycats\nwill do all of the following:\n- Upload the files cattypes.html and tabby.jpeg to the bucket\ngs://mycats (cp command)\n- Set the Content-Type of cattypes.html to text/html and\ntabby.jpeg to image/jpeg (based on file extensions)\n- Compress the data in the file cattypes.html (-z option)\n- Set the Content-Encoding for cattypes.html to gzip\n(-z option)\n- Set the ACL for both files to public-read (-a option)\n- If a user tries to view cattypes.html in a browser, the\nbrowser will know to uncompress the data based on the\nContent-Encoding header and to render it as HTML based on\nthe Content-Type header.\nNote that if you download an object with Content-Encoding:gzip\ngsutil will decompress the content before writing the local\nfile.")), ToolInput(tag="in_applies_gzip_contentencoding", input_type=Boolean(optional=True), prefix="-Z", doc=InputDocumentation(doc="Applies gzip content-encoding to file uploads. This option\nworks like the -z option described above, but it applies to\nall uploaded files, regardless of extension.\nWarning: If you use this option and some of the source files\ndon't compress well (e.g., that's often true of binary data),\nthis option may result in files taking up more space in the\ncloud than they would if left uncompressed.\n")), ToolInput(tag="in_metadata_dot", input_type=String(), position=0, doc=InputDocumentation(doc="Copies spanning locations and/or storage classes cause data to be rewritten")), ToolInput(tag="in_identical_dot", input_type=String(), position=0, doc=InputDocumentation(doc="Note that by default, the gsutil cp command does not copy the object")), ToolInput(tag="in_hashing", input_type=String(), position=0, doc=InputDocumentation(doc="obj:")), ToolInput(tag="in_uploading", input_type=String(), position=0, doc=InputDocumentation(doc="gs://your-bucket/obj:                                182 b/182 B")), ToolInput(tag="in_operation_dot", input_type=String(), position=0, doc=InputDocumentation(doc="This feature is only available for Google Cloud Storage objects because it")), ToolInput(tag="in_copied_dot", input_type=String(), position=0, doc=InputDocumentation(doc="-I             Causes gsutil to read the list of files or objects to copy from"))], outputs=[], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Gsutil_Cp_V0_1_0().translate("wdl", allow_empty_container=True)

