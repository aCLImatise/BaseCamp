&id001 !Command
command:
- toil-cwl-runner
positional: []
named:
- !Flag
  optional: true
  synonyms:
  - --jobStore
  - --jobstore
  - --not-strict
  - --enable-dev
  description: Enable loading and running development versions of CWL
  args: !SimpleFlagArg
    name: JOBSTORE
- !Flag
  optional: true
  synonyms:
  - --user-space-docker-cmd
  description: "(Linux/OS X only) Specify a user space docker command\n(like udocker\
    \ or dx-docker) that will be used to call\n'pull' and 'run'"
  args: !SimpleFlagArg
    name: USER_SPACE_DOCKER_CMD
- !Flag
  optional: true
  synonyms:
  - --singularity
  description: "[experimental] Use Singularity runtime for running\ncontainers. Requires\
    \ Singularity v2.6.1+ and Linux\nwith kernel version v3.18+ or with overlayfs\
    \ support\nbackported."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-container
  description: "Do not execute jobs in a Docker container, even when\n`DockerRequirement`\
    \ is specified under `hints`."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --leave-container
  description: Do not delete Docker container used by jobs after they
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --beta-dependency-resolvers-configuration
  - --beta-dependencies-directory
  - --beta-use-biocontainers
  - --beta-conda-dependencies
  - --tmpdir-prefix
  description: Path prefix for temporary directories
  args: !SimpleFlagArg
    name: BETA_DEPENDENCY_RESOLVERS_CONFIGURATION
- !Flag
  optional: true
  synonyms:
  - --tmp-outdir-prefix
  description: Path prefix for intermediate output directories
  args: !SimpleFlagArg
    name: TMP_OUTDIR_PREFIX
- !Flag
  optional: true
  synonyms:
  - --force-docker-pull
  description: Pull latest docker image even if it is locally present
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-match-user
  description: Disable passing the current uid to `docker run --user`
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-read-only
  description: Do not set root directory in the container as read-
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --relax-path-checks
  description: "Relax requirements on path names to permit spaces and\nhash characters."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --default-container
  description: "Specify a default docker container that will be used\nif the workflow\
    \ fails to specify one."
  args: !SimpleFlagArg
    name: DEFAULT_CONTAINER
- !Flag
  optional: true
  synonyms:
  - --logCritical
  description: 'Turn on loglevel Critical. Default: INFO.'
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logError
  description: 'Turn on loglevel Error. Default: INFO.'
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logWarning
  description: 'Turn on loglevel Warning. Default: INFO.'
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logDebug
  description: 'Turn on loglevel Debug. Default: INFO.'
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logInfo
  description: 'Turn on loglevel Info. Default: INFO.'
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logOff
  description: Same as --logCRITICAL.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logLevel
  description: "Set the log level. Default: INFO. Options:\n['Critical', 'Error',\
    \ 'Warning', 'Debug', 'Info',\n'critical', 'error', 'warning', 'debug', 'info',\n\
    'CRITICAL', 'ERROR', 'WARNING', 'DEBUG', 'INFO']."
  args: !ChoiceFlagArg
    choices: !!set
      CRITICAL:
      Critical:
      debug:
      DEBUG:
      info:
      Debug:
      ERROR:
      INFO:
      Error:
      critical:
      error:
      Warning:
      WARNING:
      warning:
      Info:
- !Flag
  optional: true
  synonyms:
  - --logFile
  description: File to log in.
  args: !SimpleFlagArg
    name: LOGFILE
- !Flag
  optional: true
  synonyms:
  - --rotatingLogging
  description: "Turn on rotating logging, which prevents log files\nfrom getting too\
    \ big."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --workDir
  description: "Absolute path to directory where temporary files\ngenerated during\
    \ the Toil run should be placed.\nStandard output and error from batch system\
    \ jobs\n(unless --noStdOutErr) will be placed in this\ndirectory. A cache directory\
    \ may be placed in this\ndirectory. Temp files and folders will be placed in a\n\
    directory toil-<workflowID> within workDir. The\nworkflowID is generated by Toil\
    \ and will be reported\nin the workflow logs. Default is determined by the\nvariables\
    \ (TMPDIR, TEMP, TMP) via mkdtemp. This\ndirectory needs to exist on all machines\
    \ running jobs;\nif capturing standard output and error from batch\nsystem jobs\
    \ is desired, it will generally need to be\non a shared file system. When sharing\
    \ a cache between\ncontainers on a host, this directory must be shared\nbetween\
    \ the containers."
  args: !SimpleFlagArg
    name: WORKDIR
- !Flag
  optional: true
  synonyms:
  - --noStdOutErr
  description: "Do not capture standard output and error from batch\nsystem jobs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --stats
  description: "Records statistics about the toil workflow to be used\nby 'toil stats'."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --clean
  description: "Determines the deletion of the jobStore upon\ncompletion of the program.\
    \ Choices: ['always',\n'onError', 'never', 'onSuccess']. The --stats option\n\
    requires information from the jobStore upon completion\nso the jobStore will never\
    \ be deleted with that flag.\nIf you wish to be able to restart the run, choose\n\
    'never' or 'onSuccess'. Default is 'never' if stats is\nenabled, and 'onSuccess'\
    \ otherwise."
  args: !ChoiceFlagArg
    choices: !!set
      always:
      onError:
      never:
      onSuccess:
- !Flag
  optional: true
  synonyms:
  - --cleanWorkDir
  description: "Determines deletion of temporary worker directory upon\ncompletion\
    \ of a job. Choices: ['always', 'onError',\n'never', 'onSuccess']. Default = always.\
    \ WARNING: This\noption should be changed for debugging only. Running a\nfull\
    \ pipeline with this option could fill your disk\nwith excessive intermediate\
    \ data."
  args: !ChoiceFlagArg
    choices: !!set
      always:
      onError:
      never:
      onSuccess:
- !Flag
  optional: true
  synonyms:
  - --clusterStats
  description: "[CLUSTERSTATS]\nIf enabled, writes out JSON resource usage statistics\n\
    to a file. The default location for this file is the\ncurrent working directory,\
    \ but an absolute path can\nalso be passed to specify where this file should be\n\
    written. This options only applies when using scalable\nbatch systems."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --restart
  description: "If --restart is specified then will attempt to restart\nexisting workflow\
    \ at the location pointed to by the\n--jobStore option. Will raise an exception\
    \ if the\nworkflow does not exist"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --statePollingWait
  description: "Time, in seconds, to wait before doing a scheduler\nquery for job\
    \ state. Return cached results if within\nthe waiting period."
  args: !SimpleFlagArg
    name: STATEPOLLINGWAIT
- !Flag
  optional: true
  synonyms:
  - --batchSystem
  description: "The type of batch system to run the job(s) with,\ncurrently can be\
    \ one of parasol, single_machine,\ngrid_engine, lsf, mesos, slurm, torque, htcondor,\n\
    kubernetes. default=single_machine"
  args: !ChoiceFlagArg
    choices: !!set
      kubernetes:
      mesos:
      parasol:
      single_machine:
      htcondor:
      lsf:
      torque:
      slurm:
      grid_engine:
- !Flag
  optional: true
  synonyms:
  - --disableHotDeployment
  description: "Hot-deployment was renamed to auto-deployment. Option\nnow redirects\
    \ to --disableAutoDeployment. Left in for\nbackwards compatibility."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableAutoDeployment
  description: "Should auto-deployment of the user script be\ndeactivated? If True,\
    \ the user script/package should\nbe present at the same location on all workers.\n\
    Default = False."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxLocalJobs
  description: "For batch systems that support a local queue for\nhousekeeping jobs\
    \ (Mesos, GridEngine, htcondor, lsf,\nslurm, torque). Specifies the maximum number\
    \ of these\nhousekeeping jobs to run on the local system. The\ndefault (equal\
    \ to the number of cores) is a maximum of\n8 concurrent local housekeeping jobs."
  args: !SimpleFlagArg
    name: MAXLOCALJOBS
- !Flag
  optional: true
  synonyms:
  - --manualMemArgs
  description: "Do not add the default arguments: 'hv=MEMORY' &\n'h_vmem=MEMORY' to\
    \ the qsub call, and instead rely on\nTOIL_GRIDGENGINE_ARGS to supply alternative\
    \ arguments.\nRequires that TOIL_GRIDGENGINE_ARGS be set."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --runCwlInternalJobsOnWorkers
  description: "Whether to run CWL internal jobs (e.g. CWLScatter) on\nthe worker\
    \ nodes instead of the primary node. If false\n(default), then all such jobs are\
    \ run on the primary\nnode. Setting this to true can speed up the pipeline\nfor\
    \ very large workflows with many sub-workflows\nand/or scatters, provided that\
    \ the worker pool is\nlarge enough."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --parasolCommand
  description: "The name or path of the parasol program. Will be\nlooked up on PATH\
    \ unless it starts with a slash.\n(default: parasol)."
  args: !SimpleFlagArg
    name: PARASOLCOMMAND
- !Flag
  optional: true
  synonyms:
  - --parasolMaxBatches
  description: "Maximum number of job batches the Parasol batch is\nallowed to create.\
    \ One batch is created for jobs with\na a unique set of resource requirements.\
    \ (default:\n1000)."
  args: !SimpleFlagArg
    name: PARASOLMAXBATCHES
- !Flag
  optional: true
  synonyms:
  - --scale
  description: "A scaling factor to change the value of all submitted\ntasks's submitted\
    \ cores. Used in the single_machine\nbatch system. (default: 1)."
  args: !SimpleFlagArg
    name: SCALE
- !Flag
  optional: true
  synonyms:
  - --linkImports
  description: "When using a filesystem based job store, CWL input\nfiles are by default\
    \ symlinked in. Specifying this\noption instead copies the files into the job\
    \ store,\nwhich may protect them from being modified externally.\nWhen not specified\
    \ and as long as caching is enabled,\nToil will protect the file automatically\
    \ by changing\nthe permissions to read-only."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --noLinkImports
  description: "When using a filesystem based job store, CWL input\nfiles are by default\
    \ symlinked in. Specifying this\noption instead copies the files into the job\
    \ store,\nwhich may protect them from being modified externally.\nWhen not specified\
    \ and as long as caching is enabled,\nToil will protect the file automatically\
    \ by changing\nthe permissions to read-only."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --moveExports
  description: "When using a filesystem based job store, output files\nare by default\
    \ moved to the output directory, and a\nsymlink to the moved exported file is\
    \ created at the\ninitial location. Specifying this option instead\ncopies the\
    \ files into the output directory. Applies to\nfilesystem-based job stores only."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --noMoveExports
  description: "When using a filesystem based job store, output files\nare by default\
    \ moved to the output directory, and a\nsymlink to the moved exported file is\
    \ created at the\ninitial location. Specifying this option instead\ncopies the\
    \ files into the output directory. Applies to\nfilesystem-based job stores only."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --mesosMaster
  description: "The host and port of the Mesos master separated by\ncolon. (default:\
    \ 172.17.0.7:5050)"
  args: !SimpleFlagArg
    name: MESOSMASTERADDRESS
- !Flag
  optional: true
  synonyms:
  - --dont_allocate_mem
  description: "A flag that can block allocating memory with '--mem'\nfor job submissions\
    \ on SLURM since some system servers\nmay reject any job request that explicitly\
    \ specifies\nthe memory allocation. The default is to always\nallocate memory."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --allocate_mem
  description: "A flag that can block allocating memory with '--mem'\nfor job submissions\
    \ on SLURM since some system servers\nmay reject any job request that explicitly\
    \ specifies\nthe memory allocation. The default is to always\nallocate memory."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --kubernetesHostPath
  description: "Path on Kubernetes hosts to use as shared inter-pod\ntemp directory.\
    \ (default: None)"
  args: !SimpleFlagArg
    name: KUBERNETESHOSTPATH
- !Flag
  optional: true
  synonyms:
  - --nodeTypes
  description: "List of worker node types separated by commas. The\nsyntax for each\
    \ node type depends on the provisioner\nused. For the AWS provisioner this is\
    \ the name of an\nEC2 instance type, optionally followed by a colon and\nthe price\
    \ in dollars to bid for a spot instance of\nthat type. For example: 'c3.8xlarge:0.42'.\
    \ If no spot\nbid is specified, nodes of this type will be non-\npreemptable (non-discounted\
    \ and not subject to\npotential early termination based on the availability\n\
    of discounted instances). It is acceptable to specify\nan instance as both preemptable\
    \ and non-preemptable,\nincluding it twice in the list. In that case,\npreemptable\
    \ nodes of that type will be preferred when\ncreating new nodes once the maximum\
    \ number of\npreemptable-nodes has been reached."
  args: !SimpleFlagArg
    name: NODETYPES
- !Flag
  optional: true
  synonyms:
  - --minNodes
  description: "Mininum number of nodes of each type in the cluster,\nif using auto-scaling.\
    \ This should be provided as a\ncomma-separated list of the same length as the\
    \ list of\nnode types. default=0"
  args: !SimpleFlagArg
    name: MINNODES
- !Flag
  optional: true
  synonyms:
  - --maxNodes
  description: "Maximum number of nodes of each type in the cluster,\nif using autoscaling,\
    \ provided as a comma-separated\nlist. The first value is used as a default if\
    \ the list\nlength is less than the number of nodeTypes.\ndefault=10"
  args: !SimpleFlagArg
    name: MAXNODES
- !Flag
  optional: true
  synonyms:
  - --targetTime
  description: "Sets how rapidly you aim to complete jobs in seconds.\nShorter times\
    \ mean more aggressive parallelization.\nThe autoscaler attempts to scale up/down\
    \ so that it\nexpects all queued jobs will complete within\ntargetTime seconds.\
    \ default=1800"
  args: !SimpleFlagArg
    name: TARGETTIME
- !Flag
  optional: true
  synonyms:
  - --betaInertia
  description: "A smoothing parameter to prevent unnecessary\noscillations in the\
    \ number of provisioned nodes. This\ncontrols an exponentially weighted moving\
    \ average of\nthe estimated number of nodes. A value of 0.0 disables\nany smoothing,\
    \ and a value of 0.9 will smooth so much\nthat few changes will ever be made.\
    \ Must be between\n0.0 and 0.9. default=0.1"
  args: !SimpleFlagArg
    name: BETAINERTIA
- !Flag
  optional: true
  synonyms:
  - --scaleInterval
  description: "The interval (seconds) between assessing if the scale\nof the cluster\
    \ needs to change. default=60"
  args: !SimpleFlagArg
    name: SCALEINTERVAL
- !Flag
  optional: true
  synonyms:
  - --preemptableCompensation
  description: "The preference of the autoscaler to replace\npreemptable nodes with\
    \ non-preemptable nodes, when\npreemptable nodes cannot be started for some reason.\n\
    Defaults to 0.0. This value must be between 0.0 and\n1.0, inclusive. A value of\
    \ 0.0 disables such\ncompensation, a value of 0.5 compensates two missing\npreemptable\
    \ nodes with a non-preemptable one. A value\nof 1.0 replaces every missing pre-emptable\
    \ node with a\nnon-preemptable one."
  args: !SimpleFlagArg
    name: PREEMPTABLECOMPENSATION
- !Flag
  optional: true
  synonyms:
  - --nodeStorage
  description: "Specify the size of the root volume of worker nodes\nwhen they are\
    \ launched in gigabytes. You may want to\nset this if your jobs require a lot\
    \ of disk space.\n(default: 50)."
  args: !SimpleFlagArg
    name: NODESTORAGE
- !Flag
  optional: true
  synonyms:
  - --nodeStorageOverrides
  description: "Comma-separated list of nodeType:nodeStorage that are\nused to override\
    \ the default value from --nodeStorage\nfor the specified nodeType(s). This is\
    \ useful for\nheterogeneous jobs where some tasks require much more\ndisk than\
    \ others."
  args: !SimpleFlagArg
    name: NODESTORAGEOVERRIDES
- !Flag
  optional: true
  synonyms:
  - --metrics
  description: "Enable the prometheus/grafana dashboard for monitoring\nCPU/RAM usage,\
    \ queue size, and issued jobs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --defaultMemory
  description: "The default amount of memory to request for a job.\nOnly applicable\
    \ to jobs that do not specify an\nexplicit value for this requirement. Standard\
    \ suffixes\nlike K, Ki, M, Mi, G or Gi are supported. Default is\n2.0 Gi."
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --defaultCores
  description: "The default amount of cpu to request for a job. Only\napplicable to\
    \ jobs that do not specify an explicit\nvalue for this requirement. Fractions\
    \ of a core (for\nexample 0.1) are supported on some batch systems\n[mesos, single_machine].\
    \ Default is 1."
  args: !SimpleFlagArg
    name: FLOAT
- !Flag
  optional: true
  synonyms:
  - --defaultDisk
  description: "The default amount of disk to request for a job. Only\napplicable\
    \ to jobs that do not specify an explicit\nvalue for this requirement. Standard\
    \ suffixes like K,\nKi, M, Mi, G or Gi are supported. Default is 2.0 Gi."
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --maxCores
  description: "The max amount of cpu to request for a job. Only\napplicable to jobs\
    \ that do not specify an explicit\nvalue for this requirement. Fractions of a\
    \ core (for\nexample 0.1) are supported on some batch systems\n[mesos, single_machine].\
    \ Default is\n9223372036854775807."
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --maxMemory
  description: "The max amount of memory to request for a job. Only\napplicable to\
    \ jobs that do not specify an explicit\nvalue for this requirement. Standard suffixes\
    \ like K,\nKi, M, Mi, G or Gi are supported. Default is 8.0 Ei."
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --maxDisk
  description: "The max amount of disk to request for a job. Only\napplicable to jobs\
    \ that do not specify an explicit\nvalue for this requirement. Standard suffixes\
    \ like K,\nKi, M, Mi, G or Gi are supported. Default is 8.0 Ei."
  args: !SimpleFlagArg
    name: INT
- !Flag
  optional: true
  synonyms:
  - --retryCount
  description: "Number of times to retry a failing job before giving\nup and labeling\
    \ job failed. default=1"
  args: !SimpleFlagArg
    name: RETRYCOUNT
- !Flag
  optional: true
  synonyms:
  - --enableUnlimitedPreemptableRetries
  description: "If set, preemptable failures (or any failure due to an\ninstance getting\
    \ unexpectedly terminated) will not\ncount towards job failures and --retryCount."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --doubleMem
  description: "If set, batch jobs which die to reaching memory limit\non batch schedulers\
    \ will have their memory doubled and\nthey will be retried. The remaining retry\
    \ count will\nbe reduced by 1. Currently supported by LSF."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxJobDuration
  description: "Maximum runtime of a job (in seconds) before we kill\nit (this is\
    \ a lower bound, and the actual time before\nkilling the job may be longer).\n\
    default=9223372036854775807"
  args: !SimpleFlagArg
    name: MAXJOBDURATION
- !Flag
  optional: true
  synonyms:
  - --rescueJobsFrequency
  description: "Period of time to wait (in seconds) between checking\nfor missing/overlong\
    \ jobs, that is jobs which get lost\nby the batch system. Expert parameter. default=3600"
  args: !SimpleFlagArg
    name: RESCUEJOBSFREQUENCY
- !Flag
  optional: true
  synonyms:
  - --debugWorker
  description: "Experimental no forking mode for local debugging.\nSpecifically, workers\
    \ are not forked and stderr/stdout\nare not redirected to the log."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableWorkerOutputCapture
  description: "Let worker output go to worker's standard out/error\ninstead of per-job\
    \ logs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --badWorker
  description: "For testing purposes randomly kill --badWorker\nproportion of jobs\
    \ using SIGKILL. default=0.0"
  args: !SimpleFlagArg
    name: BADWORKER
- !Flag
  optional: true
  synonyms:
  - --badWorkerFailInterval
  description: "When killing the job pick uniformly within the\ninterval from 0.0\
    \ to --badWorkerFailInterval seconds\nafter the worker starts. default=0.01"
  args: !SimpleFlagArg
    name: BADWORKERFAILINTERVAL
- !Flag
  optional: true
  synonyms:
  - --disableCaching
  description: "[DISABLECACHING]\nDisables caching in the file store. This flag must\
    \ be\nset to use a batch system that does not support\ncleanup, such as Parasol."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableChaining
  description: "Disables chaining of jobs (chaining uses one job's\nresource allocation\
    \ for its successor job if\npossible)."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableJobStoreChecksumVerification
  description: "Disables checksum verification for files transferred\nto/from the\
    \ job store. Checksum verification is a\nsafety check to ensure the data is not\
    \ corrupted\nduring transfer. Currently only supported for non-\nstreaming AWS\
    \ files."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --maxLogFileSize
  description: "The maximum size of a job log file to keep (in bytes),\nlog files\
    \ larger than this will be truncated to the\nlast X bytes. Setting this option\
    \ to zero will prevent\nany truncation. Setting this option to a negative\nvalue\
    \ will truncate from the beginning. Default=62.0 K"
  args: !SimpleFlagArg
    name: MAXLOGFILESIZE
- !Flag
  optional: true
  synonyms:
  - --writeLogs
  description: "[WRITELOGS]\nWrite worker logs received by the leader into their\n\
    own files at the specified path. Any non-empty\nstandard output and error from\
    \ failed batch system\njobs will also be written into files at this path. The\n\
    current working directory will be used if a path is\nnot specified explicitly.\
    \ Note: By default only the\nlogs of failed jobs are returned to leader. Set log\n\
    level to 'debug' or enable '--writeLogsFromAllJobs' to\nget logs back from successful\
    \ jobs, and adjust\n'maxLogFileSize' to control the truncation limit for\nworker\
    \ logs."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --writeLogsGzip
  description: "[WRITELOGSGZIP]\nIdentical to --writeLogs except the logs files are\n\
    gzipped on the leader."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --writeLogsFromAllJobs
  description: "Whether to write logs from all jobs (including the\nsuccessful ones)\
    \ without necessarily setting the log\nlevel to 'debug'. Ensure that either --writeLogs\
    \ or\n--writeLogsGzip is set if enabling this option."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --realTimeLogging
  description: Enable real-time logging from workers to masters
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --sseKey
  description: "Path to file containing 32 character key to be used\nfor server-side\
    \ encryption on awsJobStore or\ngoogleJobStore. SSE will not be used if this flag\
    \ is\nnot passed."
  args: !SimpleFlagArg
    name: SSEKEY
- !Flag
  optional: true
  synonyms:
  - --setEnv
  description: "=VALUE or NAME, -e NAME=VALUE or NAME\nSet an environment variable\
    \ early on in the worker. If\nVALUE is omitted, it will be looked up in the current\n\
    environment. Independently of this option, the worker\nwill try to emulate the\
    \ leader's environment before\nrunning a job, except for some variables known\
    \ to vary\nacross systems. Using this option, a variable can be\ninjected into\
    \ the worker process itself before it is\nstarted."
  args: !SimpleFlagArg
    name: NAME
- !Flag
  optional: true
  synonyms:
  - --servicePollingInterval
  description: "Interval of time service jobs wait between polling for\nthe existence\
    \ of the keep-alive flag. Default: 60"
  args: !SimpleFlagArg
    name: SERVICEPOLLINGINTERVAL
- !Flag
  optional: true
  synonyms:
  - --forceDockerAppliance
  description: "Disables sanity checking the existence of the docker\nimage specified\
    \ by TOIL_APPLIANCE_SELF, which Toil\nuses to provision mesos for autoscaling."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disableProgress
  description: "Disables the progress bar shown when standard error is\na terminal."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --provenance
  description: "Save provenance to specified folder as a Research\nObject that captures\
    \ and aggregates workflow execution\nand data products."
  args: !SimpleFlagArg
    name: PROVENANCE
- !Flag
  optional: true
  synonyms:
  - --enable-user-provenance
  description: Record user account info as part of provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disable-user-provenance
  description: Do not record user account info in provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --enable-host-provenance
  description: Record host info as part of provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --disable-host-provenance
  description: Do not record host info in provenance.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --orcid
  description: "Record user ORCID identifier as part of provenance,\ne.g. https://orcid.org/0000-0002-1825-0097\
    \ or\n0000-0002-1825-0097. Alternatively the environment\nvariable ORCID may be\
    \ set."
  args: !SimpleFlagArg
    name: ORCID
- !Flag
  optional: true
  synonyms:
  - --full-name
  description: "Record full name of user as part of provenance, e.g.\nJosiah Carberry.\
    \ You may need to use shell quotes to\npreserve spaces. Alternatively the environment\n\
    variable CWL_FULL_NAME may be set.\n"
  args: !SimpleFlagArg
    name: CWL_FULL_NAME
parent:
subcommands:
- !Command
  command:
  - toil-cwl-runner
  - exit
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'exit'\n"
  generated_using: &id002
  - --help
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
- !Command
  command:
  - toil-cwl-runner
  - cwltool
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'cwltool'\n"
  generated_using: *id002
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
- !Command
  command:
  - toil-cwl-runner
  - CommandLineTools
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'CommandLineTools'\n"
  generated_using: *id002
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
- !Command
  command:
  - toil-cwl-runner
  - jobStore
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'jobStore'\n"
  generated_using: *id002
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
- !Command
  command:
  - toil-cwl-runner
  - provisioning.
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'provisioning.'\n"
  generated_using: *id002
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
- !Command
  command:
  - toil-cwl-runner
  - only
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'only'\n"
  generated_using: *id002
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
- !Command
  command:
  - toil-cwl-runner
  - CommandLineTools.
  positional:
  - !Positional
    optional: false
    position: 0
    name: example-job.yaml
    description: 'Traceback (most recent call last):'
  named:
  - !Flag
    optional: true
    synonyms:
    - --jobStore
    description: :us-west-2:jobstore \
    args: !SimpleFlagArg
      name: aws
  - !Flag
    optional: true
    synonyms:
    - --realTimeLogging
    description: \
    args: !EmptyFlagArg {}
  - !Flag
    optional: true
    synonyms:
    - --logInfo
    description: \
    args: !EmptyFlagArg {}
  parent: *id001
  subcommands: []
  usage: []
  help_flag:
  usage_flag:
  version_flag:
  help_text: "\nYou may be getting this error because your arguments are incorrect\
    \ or out of order.\n\n* All positional arguments [cwl, yml_or_json] must always\
    \ be specified last for toil-cwl-runner.\n  Note: If you're trying to specify\
    \ a jobstore, please use --jobStore.\n\n      Usage: toil-cwl-runner [options]\
    \ example.cwl example-job.yaml\n      Example: toil-cwl-runner \\\n          \
    \     --jobStore aws:us-west-2:jobstore \\\n               --realTimeLogging \\\
    \n               --logInfo \\\n               example.cwl \\\n               example-job.yaml\n\
    \nTraceback (most recent call last):\n  File \"/usr/local/bin/toil-cwl-runner\"\
    , line 10, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python3.8/site-packages/toil/cwl/cwltoil.py\"\
    , line 2117, in main\n    uri, tool_file_uri = cwltool.load_tool.resolve_tool_uri(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/cwltool/load_tool.py\", line\
    \ 98, in resolve_tool_uri\n    raise ValidationException(\"Not found: '%s'\" %\
    \ argsworkflow)\nschema_salad.exceptions.ValidationException: Not found: 'CommandLineTools.'\n"
  generated_using: *id002
  docker_image: quay.io/biocontainers/toil:5.2.0--py_0
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag: !Flag
  optional: true
  synonyms:
  - --quiet
  - --basedir
  - --outdir
  - --version
  description: show program's version number and exit
  args: !SimpleFlagArg
    name: BASEDIR
help_text: "usage: toil-cwl-runner [-h] [--logCritical] [--logError] [--logWarning]\n\
  \                       [--logDebug] [--logInfo] [--logOff]\n                  \
  \     [--logLevel {Critical,Error,Warning,Debug,Info,critical,error,warning,debug,info,CRITICAL,ERROR,WARNING,DEBUG,INFO}]\n\
  \                       [--logFile LOGFILE] [--rotatingLogging]\n              \
  \         [--workDir WORKDIR] [--noStdOutErr] [--stats]\n                      \
  \ [--clean {always,onError,never,onSuccess}]\n                       [--cleanWorkDir\
  \ {always,onError,never,onSuccess}]\n                       [--clusterStats [CLUSTERSTATS]]\
  \ [--restart]\n                       [--statePollingWait STATEPOLLINGWAIT]\n  \
  \                     [--batchSystem {parasol,single_machine,grid_engine,lsf,mesos,slurm,torque,htcondor,kubernetes}]\n\
  \                       [--disableHotDeployment] [--disableAutoDeployment]\n   \
  \                    [--maxLocalJobs MAXLOCALJOBS] [--manualMemArgs]\n         \
  \              [--runCwlInternalJobsOnWorkers]\n                       [--parasolCommand\
  \ PARASOLCOMMAND]\n                       [--parasolMaxBatches PARASOLMAXBATCHES]\
  \ [--scale SCALE]\n                       [--linkImports | --noLinkImports]\n  \
  \                     [--moveExports | --noMoveExports]\n                      \
  \ [--mesosMaster MESOSMASTERADDRESS]\n                       [--dont_allocate_mem\
  \ | --allocate_mem]\n                       [--kubernetesHostPath KUBERNETESHOSTPATH]\n\
  \                       [--provisioner {aws,gce}] [--nodeTypes NODETYPES]\n    \
  \                   [--minNodes MINNODES] [--maxNodes MAXNODES]\n              \
  \         [--targetTime TARGETTIME] [--betaInertia BETAINERTIA]\n              \
  \         [--scaleInterval SCALEINTERVAL]\n                       [--preemptableCompensation\
  \ PREEMPTABLECOMPENSATION]\n                       [--nodeStorage NODESTORAGE]\n\
  \                       [--nodeStorageOverrides NODESTORAGEOVERRIDES]\n        \
  \               [--metrics] [--defaultMemory INT]\n                       [--defaultCores\
  \ FLOAT] [--defaultDisk INT]\n                       [--maxCores INT] [--maxMemory\
  \ INT] [--maxDisk INT]\n                       [--retryCount RETRYCOUNT]\n     \
  \                  [--enableUnlimitedPreemptableRetries] [--doubleMem]\n       \
  \                [--maxJobDuration MAXJOBDURATION]\n                       [--rescueJobsFrequency\
  \ RESCUEJOBSFREQUENCY]\n                       [--debugWorker] [--disableWorkerOutputCapture]\n\
  \                       [--badWorker BADWORKER]\n                       [--badWorkerFailInterval\
  \ BADWORKERFAILINTERVAL]\n                       [--disableCaching [DISABLECACHING]]\
  \ [--disableChaining]\n                       [--disableJobStoreChecksumVerification]\n\
  \                       [--maxLogFileSize MAXLOGFILESIZE]\n                    \
  \   [--writeLogs [WRITELOGS]]\n                       [--writeLogsGzip [WRITELOGSGZIP]]\n\
  \                       [--writeLogsFromAllJobs] [--realTimeLogging]\n         \
  \              [--sseKey SSEKEY] [--setEnv NAME=VALUE or NAME]\n               \
  \        [--servicePollingInterval SERVICEPOLLINGINTERVAL]\n                   \
  \    [--forceDockerAppliance] [--disableProgress]\n                       [--jobStore\
  \ JOBSTORE] [--not-strict] [--enable-dev]\n                       [--quiet] [--basedir\
  \ BASEDIR] [--outdir OUTDIR]\n                       [--version]\n             \
  \          [--user-space-docker-cmd USER_SPACE_DOCKER_CMD | --singularity | --no-container\
  \ | --leave-container]\n                       [--preserve-environment VAR1 VAR2\
  \ [VAR1 VAR2 ...]]\n                       [--preserve-entire-environment]\n   \
  \                    [--destBucket DESTBUCKET]\n                       [--beta-dependency-resolvers-configuration\
  \ BETA_DEPENDENCY_RESOLVERS_CONFIGURATION]\n                       [--beta-dependencies-directory\
  \ BETA_DEPENDENCIES_DIRECTORY]\n                       [--beta-use-biocontainers]\
  \ [--beta-conda-dependencies]\n                       [--tmpdir-prefix TMPDIR_PREFIX]\n\
  \                       [--tmp-outdir-prefix TMP_OUTDIR_PREFIX]\n              \
  \         [--force-docker-pull] [--no-match-user]\n                       [--no-read-only]\
  \ [--strict-memory-limit]\n                       [--relax-path-checks]\n      \
  \                 [--default-container DEFAULT_CONTAINER]\n                    \
  \   [--provenance PROVENANCE] [--enable-user-provenance]\n                     \
  \  [--disable-user-provenance] [--enable-host-provenance]\n                    \
  \   [--disable-host-provenance] [--orcid ORCID]\n                       [--full-name\
  \ CWL_FULL_NAME]\n                       jobStore cwltool ...\n\npositional arguments:\n\
  \  cwltool\n  cwljob\n\noptional arguments:\n  -h, --help            show this help\
  \ message and exit\n  --jobStore JOBSTORE, --jobstore JOBSTORE\n  --not-strict\n\
  \  --enable-dev          Enable loading and running development versions of CWL\n\
  \  --quiet\n  --basedir BASEDIR\n  --outdir OUTDIR\n  --version             show\
  \ program's version number and exit\n  --user-space-docker-cmd USER_SPACE_DOCKER_CMD\n\
  \                        (Linux/OS X only) Specify a user space docker command\n\
  \                        (like udocker or dx-docker) that will be used to call\n\
  \                        'pull' and 'run'\n  --singularity         [experimental]\
  \ Use Singularity runtime for running\n                        containers. Requires\
  \ Singularity v2.6.1+ and Linux\n                        with kernel version v3.18+\
  \ or with overlayfs support\n                        backported.\n  --no-container\
  \        Do not execute jobs in a Docker container, even when\n                \
  \        `DockerRequirement` is specified under `hints`.\n  --leave-container  \
  \   Do not delete Docker container used by jobs after they\n                   \
  \     exit\n  --preserve-environment VAR1 VAR2 [VAR1 VAR2 ...]\n               \
  \         Preserve specified environment variables when running\n              \
  \          CommandLineTools\n  --preserve-entire-environment\n                 \
  \       Preserve all environment variable when running\n                       \
  \ CommandLineTools.\n  --destBucket DESTBUCKET\n                        Specify\
  \ a cloud bucket endpoint for output files.\n  --beta-dependency-resolvers-configuration\
  \ BETA_DEPENDENCY_RESOLVERS_CONFIGURATION\n  --beta-dependencies-directory BETA_DEPENDENCIES_DIRECTORY\n\
  \  --beta-use-biocontainers\n  --beta-conda-dependencies\n  --tmpdir-prefix TMPDIR_PREFIX\n\
  \                        Path prefix for temporary directories\n  --tmp-outdir-prefix\
  \ TMP_OUTDIR_PREFIX\n                        Path prefix for intermediate output\
  \ directories\n  --force-docker-pull   Pull latest docker image even if it is locally\
  \ present\n  --no-match-user       Disable passing the current uid to `docker run\
  \ --user`\n  --no-read-only        Do not set root directory in the container as\
  \ read-\n                        only\n  --strict-memory-limit\n               \
  \         When running with software containers and the Docker\n               \
  \         engine, pass either the calculated memory allocation\n               \
  \         from ResourceRequirements or the default of 1 gigabyte\n             \
  \           to Docker's --memory option.\n  --relax-path-checks   Relax requirements\
  \ on path names to permit spaces and\n                        hash characters.\n\
  \  --default-container DEFAULT_CONTAINER\n                        Specify a default\
  \ docker container that will be used\n                        if the workflow fails\
  \ to specify one.\n\nLogging Options:\n  --logCritical         Turn on loglevel\
  \ Critical. Default: INFO.\n  --logError            Turn on loglevel Error. Default:\
  \ INFO.\n  --logWarning          Turn on loglevel Warning. Default: INFO.\n  --logDebug\
  \            Turn on loglevel Debug. Default: INFO.\n  --logInfo             Turn\
  \ on loglevel Info. Default: INFO.\n  --logOff              Same as --logCRITICAL.\n\
  \  --logLevel {Critical,Error,Warning,Debug,Info,critical,error,warning,debug,info,CRITICAL,ERROR,WARNING,DEBUG,INFO}\n\
  \                        Set the log level. Default: INFO. Options:\n          \
  \              ['Critical', 'Error', 'Warning', 'Debug', 'Info',\n             \
  \           'critical', 'error', 'warning', 'debug', 'info',\n                 \
  \       'CRITICAL', 'ERROR', 'WARNING', 'DEBUG', 'INFO'].\n  --logFile LOGFILE \
  \    File to log in.\n  --rotatingLogging     Turn on rotating logging, which prevents\
  \ log files\n                        from getting too big.\n\nToil core options.:\n\
  \  Options to specify the location of the Toil workflow and turn on stats\n  collation\
  \ about the performance of jobs.\n\n  jobStore              The location of the\
  \ job store for the workflow. A job\n                        store holds persistent\
  \ information about the jobs,\n                        stats, and files in a workflow.\
  \ If the workflow is run\n                        with a distributed batch system,\
  \ the job store must be\n                        accessible by all worker nodes.\
  \ Depending on the\n                        desired job store implementation, the\
  \ location should\n                        be formatted according to one of the\
  \ following\n                        schemes: file:<path> where <path> points to\
  \ a\n                        directory on the file systen aws:<region>:<prefix>\n\
  \                        where <region> is the name of an AWS region like us-\n\
  \                        west-2 and <prefix> will be prepended to the names of\n\
  \                        any top-level AWS resources in use by job store, e.g.\n\
  \                        S3 buckets. google:<project_id>:<prefix> TODO: explain\n\
  \                        For backwards compatibility, you may also specify\n   \
  \                     ./foo (equivalent to file:./foo or just file:foo) or\n   \
  \                     /bar (equivalent to file:/bar).\n  --workDir WORKDIR     Absolute\
  \ path to directory where temporary files\n                        generated during\
  \ the Toil run should be placed.\n                        Standard output and error\
  \ from batch system jobs\n                        (unless --noStdOutErr) will be\
  \ placed in this\n                        directory. A cache directory may be placed\
  \ in this\n                        directory. Temp files and folders will be placed\
  \ in a\n                        directory toil-<workflowID> within workDir. The\n\
  \                        workflowID is generated by Toil and will be reported\n\
  \                        in the workflow logs. Default is determined by the\n  \
  \                      variables (TMPDIR, TEMP, TMP) via mkdtemp. This\n       \
  \                 directory needs to exist on all machines running jobs;\n     \
  \                   if capturing standard output and error from batch\n        \
  \                system jobs is desired, it will generally need to be\n        \
  \                on a shared file system. When sharing a cache between\n       \
  \                 containers on a host, this directory must be shared\n        \
  \                between the containers.\n  --noStdOutErr         Do not capture\
  \ standard output and error from batch\n                        system jobs.\n \
  \ --stats               Records statistics about the toil workflow to be used\n\
  \                        by 'toil stats'.\n  --clean {always,onError,never,onSuccess}\n\
  \                        Determines the deletion of the jobStore upon\n        \
  \                completion of the program. Choices: ['always',\n              \
  \          'onError', 'never', 'onSuccess']. The --stats option\n              \
  \          requires information from the jobStore upon completion\n            \
  \            so the jobStore will never be deleted with that flag.\n           \
  \             If you wish to be able to restart the run, choose\n              \
  \          'never' or 'onSuccess'. Default is 'never' if stats is\n            \
  \            enabled, and 'onSuccess' otherwise.\n  --cleanWorkDir {always,onError,never,onSuccess}\n\
  \                        Determines deletion of temporary worker directory upon\n\
  \                        completion of a job. Choices: ['always', 'onError',\n \
  \                       'never', 'onSuccess']. Default = always. WARNING: This\n\
  \                        option should be changed for debugging only. Running a\n\
  \                        full pipeline with this option could fill your disk\n \
  \                       with excessive intermediate data.\n  --clusterStats [CLUSTERSTATS]\n\
  \                        If enabled, writes out JSON resource usage statistics\n\
  \                        to a file. The default location for this file is the\n\
  \                        current working directory, but an absolute path can\n \
  \                       also be passed to specify where this file should be\n  \
  \                      written. This options only applies when using scalable\n\
  \                        batch systems.\n\nToil options for restarting an existing\
  \ workflow.:\n  Allows the restart of an existing workflow\n\n  --restart      \
  \       If --restart is specified then will attempt to restart\n               \
  \         existing workflow at the location pointed to by the\n                \
  \        --jobStore option. Will raise an exception if the\n                   \
  \     workflow does not exist\n\nToil options for specifying the batch system.:\n\
  \  Allows the specification of the batch system.\n\n  --statePollingWait STATEPOLLINGWAIT\n\
  \                        Time, in seconds, to wait before doing a scheduler\n  \
  \                      query for job state. Return cached results if within\n  \
  \                      the waiting period.\n  --batchSystem {parasol,single_machine,grid_engine,lsf,mesos,slurm,torque,htcondor,kubernetes}\n\
  \                        The type of batch system to run the job(s) with,\n    \
  \                    currently can be one of parasol, single_machine,\n        \
  \                grid_engine, lsf, mesos, slurm, torque, htcondor,\n           \
  \             kubernetes. default=single_machine\n  --disableHotDeployment\n   \
  \                     Hot-deployment was renamed to auto-deployment. Option\n  \
  \                      now redirects to --disableAutoDeployment. Left in for\n \
  \                       backwards compatibility.\n  --disableAutoDeployment\n  \
  \                      Should auto-deployment of the user script be\n          \
  \              deactivated? If True, the user script/package should\n          \
  \              be present at the same location on all workers.\n               \
  \         Default = False.\n  --maxLocalJobs MAXLOCALJOBS\n                    \
  \    For batch systems that support a local queue for\n                        housekeeping\
  \ jobs (Mesos, GridEngine, htcondor, lsf,\n                        slurm, torque).\
  \ Specifies the maximum number of these\n                        housekeeping jobs\
  \ to run on the local system. The\n                        default (equal to the\
  \ number of cores) is a maximum of\n                        8 concurrent local housekeeping\
  \ jobs.\n  --manualMemArgs       Do not add the default arguments: 'hv=MEMORY' &\n\
  \                        'h_vmem=MEMORY' to the qsub call, and instead rely on\n\
  \                        TOIL_GRIDGENGINE_ARGS to supply alternative arguments.\n\
  \                        Requires that TOIL_GRIDGENGINE_ARGS be set.\n  --runCwlInternalJobsOnWorkers\n\
  \                        Whether to run CWL internal jobs (e.g. CWLScatter) on\n\
  \                        the worker nodes instead of the primary node. If false\n\
  \                        (default), then all such jobs are run on the primary\n\
  \                        node. Setting this to true can speed up the pipeline\n\
  \                        for very large workflows with many sub-workflows\n    \
  \                    and/or scatters, provided that the worker pool is\n       \
  \                 large enough.\n  --parasolCommand PARASOLCOMMAND\n           \
  \             The name or path of the parasol program. Will be\n               \
  \         looked up on PATH unless it starts with a slash.\n                   \
  \     (default: parasol).\n  --parasolMaxBatches PARASOLMAXBATCHES\n           \
  \             Maximum number of job batches the Parasol batch is\n             \
  \           allowed to create. One batch is created for jobs with\n            \
  \            a a unique set of resource requirements. (default:\n              \
  \          1000).\n  --scale SCALE         A scaling factor to change the value\
  \ of all submitted\n                        tasks's submitted cores. Used in the\
  \ single_machine\n                        batch system. (default: 1).\n  --linkImports\
  \         When using a filesystem based job store, CWL input\n                 \
  \       files are by default symlinked in. Specifying this\n                   \
  \     option instead copies the files into the job store,\n                    \
  \    which may protect them from being modified externally.\n                  \
  \      When not specified and as long as caching is enabled,\n                 \
  \       Toil will protect the file automatically by changing\n                 \
  \       the permissions to read-only.\n  --noLinkImports       When using a filesystem\
  \ based job store, CWL input\n                        files are by default symlinked\
  \ in. Specifying this\n                        option instead copies the files into\
  \ the job store,\n                        which may protect them from being modified\
  \ externally.\n                        When not specified and as long as caching\
  \ is enabled,\n                        Toil will protect the file automatically\
  \ by changing\n                        the permissions to read-only.\n  --moveExports\
  \         When using a filesystem based job store, output files\n              \
  \          are by default moved to the output directory, and a\n               \
  \         symlink to the moved exported file is created at the\n               \
  \         initial location. Specifying this option instead\n                   \
  \     copies the files into the output directory. Applies to\n                 \
  \       filesystem-based job stores only.\n  --noMoveExports       When using a\
  \ filesystem based job store, output files\n                        are by default\
  \ moved to the output directory, and a\n                        symlink to the moved\
  \ exported file is created at the\n                        initial location. Specifying\
  \ this option instead\n                        copies the files into the output\
  \ directory. Applies to\n                        filesystem-based job stores only.\n\
  \  --mesosMaster MESOSMASTERADDRESS\n                        The host and port of\
  \ the Mesos master separated by\n                        colon. (default: 172.17.0.7:5050)\n\
  \  --dont_allocate_mem   A flag that can block allocating memory with '--mem'\n\
  \                        for job submissions on SLURM since some system servers\n\
  \                        may reject any job request that explicitly specifies\n\
  \                        the memory allocation. The default is to always\n     \
  \                   allocate memory.\n  --allocate_mem        A flag that can block\
  \ allocating memory with '--mem'\n                        for job submissions on\
  \ SLURM since some system servers\n                        may reject any job request\
  \ that explicitly specifies\n                        the memory allocation. The\
  \ default is to always\n                        allocate memory.\n  --kubernetesHostPath\
  \ KUBERNETESHOSTPATH\n                        Path on Kubernetes hosts to use as\
  \ shared inter-pod\n                        temp directory. (default: None)\n\n\
  Toil options for autoscaling the cluster of worker nodes.:\n  Allows the specification\
  \ of the minimum and maximum number of nodes in an\n  autoscaled cluster, as well\
  \ as parameters to control the level of\n  provisioning.\n\n  --provisioner {aws,gce},\
  \ -p {aws,gce}\n                        The provisioner for cluster auto-scaling.\
  \ The\n                        currently supported choices are ['aws', 'gce']. The\n\
  \                        default is None.\n  --nodeTypes NODETYPES\n           \
  \             List of worker node types separated by commas. The\n             \
  \           syntax for each node type depends on the provisioner\n             \
  \           used. For the AWS provisioner this is the name of an\n             \
  \           EC2 instance type, optionally followed by a colon and\n            \
  \            the price in dollars to bid for a spot instance of\n              \
  \          that type. For example: 'c3.8xlarge:0.42'. If no spot\n             \
  \           bid is specified, nodes of this type will be non-\n                \
  \        preemptable (non-discounted and not subject to\n                      \
  \  potential early termination based on the availability\n                     \
  \   of discounted instances). It is acceptable to specify\n                    \
  \    an instance as both preemptable and non-preemptable,\n                    \
  \    including it twice in the list. In that case,\n                        preemptable\
  \ nodes of that type will be preferred when\n                        creating new\
  \ nodes once the maximum number of\n                        preemptable-nodes has\
  \ been reached.\n  --minNodes MINNODES   Mininum number of nodes of each type in\
  \ the cluster,\n                        if using auto-scaling. This should be provided\
  \ as a\n                        comma-separated list of the same length as the list\
  \ of\n                        node types. default=0\n  --maxNodes MAXNODES   Maximum\
  \ number of nodes of each type in the cluster,\n                        if using\
  \ autoscaling, provided as a comma-separated\n                        list. The\
  \ first value is used as a default if the list\n                        length is\
  \ less than the number of nodeTypes.\n                        default=10\n  --targetTime\
  \ TARGETTIME\n                        Sets how rapidly you aim to complete jobs\
  \ in seconds.\n                        Shorter times mean more aggressive parallelization.\n\
  \                        The autoscaler attempts to scale up/down so that it\n \
  \                       expects all queued jobs will complete within\n         \
  \               targetTime seconds. default=1800\n  --betaInertia BETAINERTIA\n\
  \                        A smoothing parameter to prevent unnecessary\n        \
  \                oscillations in the number of provisioned nodes. This\n       \
  \                 controls an exponentially weighted moving average of\n       \
  \                 the estimated number of nodes. A value of 0.0 disables\n     \
  \                   any smoothing, and a value of 0.9 will smooth so much\n    \
  \                    that few changes will ever be made. Must be between\n     \
  \                   0.0 and 0.9. default=0.1\n  --scaleInterval SCALEINTERVAL\n\
  \                        The interval (seconds) between assessing if the scale\n\
  \                        of the cluster needs to change. default=60\n  --preemptableCompensation\
  \ PREEMPTABLECOMPENSATION\n                        The preference of the autoscaler\
  \ to replace\n                        preemptable nodes with non-preemptable nodes,\
  \ when\n                        preemptable nodes cannot be started for some reason.\n\
  \                        Defaults to 0.0. This value must be between 0.0 and\n \
  \                       1.0, inclusive. A value of 0.0 disables such\n         \
  \               compensation, a value of 0.5 compensates two missing\n         \
  \               preemptable nodes with a non-preemptable one. A value\n        \
  \                of 1.0 replaces every missing pre-emptable node with a\n      \
  \                  non-preemptable one.\n  --nodeStorage NODESTORAGE\n         \
  \               Specify the size of the root volume of worker nodes\n          \
  \              when they are launched in gigabytes. You may want to\n          \
  \              set this if your jobs require a lot of disk space.\n            \
  \            (default: 50).\n  --nodeStorageOverrides NODESTORAGEOVERRIDES\n   \
  \                     Comma-separated list of nodeType:nodeStorage that are\n  \
  \                      used to override the default value from --nodeStorage\n \
  \                       for the specified nodeType(s). This is useful for\n    \
  \                    heterogeneous jobs where some tasks require much more\n   \
  \                     disk than others.\n  --metrics             Enable the prometheus/grafana\
  \ dashboard for monitoring\n                        CPU/RAM usage, queue size, and\
  \ issued jobs.\n\nToil options for cores/memory requirements.:\n  The options to\
  \ specify default cores/memory requirements (if not specified\n  by the jobs themselves),\
  \ and to limit the total amount of memory/cores\n  requested from the batch system.\n\
  \n  --defaultMemory INT   The default amount of memory to request for a job.\n \
  \                       Only applicable to jobs that do not specify an\n       \
  \                 explicit value for this requirement. Standard suffixes\n     \
  \                   like K, Ki, M, Mi, G or Gi are supported. Default is\n     \
  \                   2.0 Gi.\n  --defaultCores FLOAT  The default amount of cpu to\
  \ request for a job. Only\n                        applicable to jobs that do not\
  \ specify an explicit\n                        value for this requirement. Fractions\
  \ of a core (for\n                        example 0.1) are supported on some batch\
  \ systems\n                        [mesos, single_machine]. Default is 1.\n  --defaultDisk\
  \ INT     The default amount of disk to request for a job. Only\n              \
  \          applicable to jobs that do not specify an explicit\n                \
  \        value for this requirement. Standard suffixes like K,\n               \
  \         Ki, M, Mi, G or Gi are supported. Default is 2.0 Gi.\n  --maxCores INT\
  \        The max amount of cpu to request for a job. Only\n                    \
  \    applicable to jobs that do not specify an explicit\n                      \
  \  value for this requirement. Fractions of a core (for\n                      \
  \  example 0.1) are supported on some batch systems\n                        [mesos,\
  \ single_machine]. Default is\n                        9223372036854775807.\n  --maxMemory\
  \ INT       The max amount of memory to request for a job. Only\n              \
  \          applicable to jobs that do not specify an explicit\n                \
  \        value for this requirement. Standard suffixes like K,\n               \
  \         Ki, M, Mi, G or Gi are supported. Default is 8.0 Ei.\n  --maxDisk INT\
  \         The max amount of disk to request for a job. Only\n                  \
  \      applicable to jobs that do not specify an explicit\n                    \
  \    value for this requirement. Standard suffixes like K,\n                   \
  \     Ki, M, Mi, G or Gi are supported. Default is 8.0 Ei.\n\nToil options for rescuing/killing/restarting\
  \ jobs.:\n  The options for jobs that either run too long/fail or get lost (some\
  \ batch\n  systems have issues!).\n\n  --retryCount RETRYCOUNT\n               \
  \         Number of times to retry a failing job before giving\n               \
  \         up and labeling job failed. default=1\n  --enableUnlimitedPreemptableRetries\n\
  \                        If set, preemptable failures (or any failure due to an\n\
  \                        instance getting unexpectedly terminated) will not\n  \
  \                      count towards job failures and --retryCount.\n  --doubleMem\
  \           If set, batch jobs which die to reaching memory limit\n            \
  \            on batch schedulers will have their memory doubled and\n          \
  \              they will be retried. The remaining retry count will\n          \
  \              be reduced by 1. Currently supported by LSF.\n  --maxJobDuration\
  \ MAXJOBDURATION\n                        Maximum runtime of a job (in seconds)\
  \ before we kill\n                        it (this is a lower bound, and the actual\
  \ time before\n                        killing the job may be longer).\n       \
  \                 default=9223372036854775807\n  --rescueJobsFrequency RESCUEJOBSFREQUENCY\n\
  \                        Period of time to wait (in seconds) between checking\n\
  \                        for missing/overlong jobs, that is jobs which get lost\n\
  \                        by the batch system. Expert parameter. default=3600\n\n\
  Toil debug options.:\n  Debug options for finding problems or helping with testing.\n\
  \n  --debugWorker         Experimental no forking mode for local debugging.\n  \
  \                      Specifically, workers are not forked and stderr/stdout\n\
  \                        are not redirected to the log.\n  --disableWorkerOutputCapture\n\
  \                        Let worker output go to worker's standard out/error\n \
  \                       instead of per-job logs.\n  --badWorker BADWORKER\n    \
  \                    For testing purposes randomly kill --badWorker\n          \
  \              proportion of jobs using SIGKILL. default=0.0\n  --badWorkerFailInterval\
  \ BADWORKERFAILINTERVAL\n                        When killing the job pick uniformly\
  \ within the\n                        interval from 0.0 to --badWorkerFailInterval\
  \ seconds\n                        after the worker starts. default=0.01\n\nToil\
  \ miscellaneous options.:\n  Everything else.\n\n  --disableCaching [DISABLECACHING]\n\
  \                        Disables caching in the file store. This flag must be\n\
  \                        set to use a batch system that does not support\n     \
  \                   cleanup, such as Parasol.\n  --disableChaining     Disables\
  \ chaining of jobs (chaining uses one job's\n                        resource allocation\
  \ for its successor job if\n                        possible).\n  --disableJobStoreChecksumVerification\n\
  \                        Disables checksum verification for files transferred\n\
  \                        to/from the job store. Checksum verification is a\n   \
  \                     safety check to ensure the data is not corrupted\n       \
  \                 during transfer. Currently only supported for non-\n         \
  \               streaming AWS files.\n  --maxLogFileSize MAXLOGFILESIZE\n      \
  \                  The maximum size of a job log file to keep (in bytes),\n    \
  \                    log files larger than this will be truncated to the\n     \
  \                   last X bytes. Setting this option to zero will prevent\n   \
  \                     any truncation. Setting this option to a negative\n      \
  \                  value will truncate from the beginning. Default=62.0 K\n  --writeLogs\
  \ [WRITELOGS]\n                        Write worker logs received by the leader\
  \ into their\n                        own files at the specified path. Any non-empty\n\
  \                        standard output and error from failed batch system\n  \
  \                      jobs will also be written into files at this path. The\n\
  \                        current working directory will be used if a path is\n \
  \                       not specified explicitly. Note: By default only the\n  \
  \                      logs of failed jobs are returned to leader. Set log\n   \
  \                     level to 'debug' or enable '--writeLogsFromAllJobs' to\n \
  \                       get logs back from successful jobs, and adjust\n       \
  \                 'maxLogFileSize' to control the truncation limit for\n       \
  \                 worker logs.\n  --writeLogsGzip [WRITELOGSGZIP]\n            \
  \            Identical to --writeLogs except the logs files are\n              \
  \          gzipped on the leader.\n  --writeLogsFromAllJobs\n                  \
  \      Whether to write logs from all jobs (including the\n                    \
  \    successful ones) without necessarily setting the log\n                    \
  \    level to 'debug'. Ensure that either --writeLogs or\n                     \
  \   --writeLogsGzip is set if enabling this option.\n  --realTimeLogging     Enable\
  \ real-time logging from workers to masters\n  --sseKey SSEKEY       Path to file\
  \ containing 32 character key to be used\n                        for server-side\
  \ encryption on awsJobStore or\n                        googleJobStore. SSE will\
  \ not be used if this flag is\n                        not passed.\n  --setEnv NAME=VALUE\
  \ or NAME, -e NAME=VALUE or NAME\n                        Set an environment variable\
  \ early on in the worker. If\n                        VALUE is omitted, it will\
  \ be looked up in the current\n                        environment. Independently\
  \ of this option, the worker\n                        will try to emulate the leader's\
  \ environment before\n                        running a job, except for some variables\
  \ known to vary\n                        across systems. Using this option, a variable\
  \ can be\n                        injected into the worker process itself before\
  \ it is\n                        started.\n  --servicePollingInterval SERVICEPOLLINGINTERVAL\n\
  \                        Interval of time service jobs wait between polling for\n\
  \                        the existence of the keep-alive flag. Default: 60\n  --forceDockerAppliance\n\
  \                        Disables sanity checking the existence of the docker\n\
  \                        image specified by TOIL_APPLIANCE_SELF, which Toil\n  \
  \                      uses to provision mesos for autoscaling.\n  --disableProgress\
  \     Disables the progress bar shown when standard error is\n                 \
  \       a terminal.\n\nOptions for recording provenance information of the execution:\n\
  \  --provenance PROVENANCE\n                        Save provenance to specified\
  \ folder as a Research\n                        Object that captures and aggregates\
  \ workflow execution\n                        and data products.\n  --enable-user-provenance\n\
  \                        Record user account info as part of provenance.\n  --disable-user-provenance\n\
  \                        Do not record user account info in provenance.\n  --enable-host-provenance\n\
  \                        Record host info as part of provenance.\n  --disable-host-provenance\n\
  \                        Do not record host info in provenance.\n  --orcid ORCID\
  \         Record user ORCID identifier as part of provenance,\n                \
  \        e.g. https://orcid.org/0000-0002-1825-0097 or\n                       \
  \ 0000-0002-1825-0097. Alternatively the environment\n                        variable\
  \ ORCID may be set.\n  --full-name CWL_FULL_NAME\n                        Record\
  \ full name of user as part of provenance, e.g.\n                        Josiah\
  \ Carberry. You may need to use shell quotes to\n                        preserve\
  \ spaces. Alternatively the environment\n                        variable CWL_FULL_NAME\
  \ may be set.\n"
generated_using: *id002
docker_image: quay.io/biocontainers/toil:5.2.0--py_0
