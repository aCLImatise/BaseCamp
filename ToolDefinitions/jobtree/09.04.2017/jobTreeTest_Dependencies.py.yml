!Command
command:
- jobTreeTest_Dependencies.py
positional: []
named:
- !Flag
  optional: true
  synonyms:
  - --sleepTime
  description: sleep [default=5] seconds
  args: !SimpleFlagArg
    name: SLEEPTIME
- !Flag
  optional: true
  synonyms:
  - --tree
  description: tree [balanced|comb|star|fly]
  args: !SimpleFlagArg
    name: TREE
- !Flag
  optional: true
  synonyms:
  - --size
  description: tree size (for comb or star) [default=10]
  args: !SimpleFlagArg
    name: SIZE
- !Flag
  optional: true
  synonyms:
  - --cpusPerJob
  description: Cpus per job
  args: !SimpleFlagArg
    name: CPUSPERJOB
- !Flag
  optional: true
  synonyms:
  - --logOff
  description: Turn off logging. (default is CRITICAL)
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logInfo
  description: Turn on logging at INFO level. (default is CRITICAL)
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logDebug
  description: Turn on logging at DEBUG level. (default is CRITICAL)
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --logLevel
  description: "Log at level (may be either OFF/INFO/DEBUG/CRITICAL).\n(default is\
    \ CRITICAL)"
  args: !SimpleFlagArg
    name: LOGLEVEL
- !Flag
  optional: true
  synonyms:
  - --logFile
  description: File to log in
  args: !SimpleFlagArg
    name: LOGFILE
- !Flag
  optional: true
  synonyms:
  - --rotatingLogging
  description: "Turn on rotating logging, which prevents log files\ngetting too big."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --jobTree
  description: "Directory in which to place job management files and\nthe global accessed\
    \ temporary file directories(this\nneeds to be globally accessible by all machines\n\
    running jobs). If you pass an existing directory it\nwill check if it's a valid\
    \ existing job tree, then try\nand restart the jobs in it. The default=./jobTree"
  args: !SimpleFlagArg
    name: JOBTREE
- !Flag
  optional: true
  synonyms:
  - --stats
  description: "Records statistics about the job-tree to be used by\njobTreeStats.\
    \ default=False"
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --batchSystem
  description: "The type of batch system to run the job(s) with,\ncurrently can be\
    \ 'singleMachine'/'parasol'/'acidTest'/\n'gridEngine'/'lsf'. default=singleMachine"
  args: !SimpleFlagArg
    name: BATCHSYSTEM
- !Flag
  optional: true
  synonyms:
  - --maxThreads
  description: "The maximum number of threads (technically processes\nat this point)\
    \ to use when running in single machine\nmode. Increasing this will allow more\
    \ jobs to run\nconcurrently when running on a single machine.\ndefault=4"
  args: !SimpleFlagArg
    name: MAXTHREADS
- !Flag
  optional: true
  synonyms:
  - --parasolCommand
  description: The command to run the parasol program default=parasol
  args: !SimpleFlagArg
    name: PARASOLCOMMAND
- !Flag
  optional: true
  synonyms:
  - --defaultMemory
  description: "The default amount of memory to request for a job (in\nbytes), by\
    \ default is 2^31 = 2 gigabytes,\ndefault=2147483648"
  args: !SimpleFlagArg
    name: DEFAULTMEMORY
- !Flag
  optional: true
  synonyms:
  - --defaultCpu
  description: "The default the number of cpus to dedicate a job.\ndefault=1"
  args: !SimpleFlagArg
    name: DEFAULTCPU
- !Flag
  optional: true
  synonyms:
  - --maxCpus
  description: "The maximum number of cpus to request from the batch\nsystem at any\
    \ one time. default=9223372036854775807"
  args: !SimpleFlagArg
    name: MAXCPUS
- !Flag
  optional: true
  synonyms:
  - --maxMemory
  description: "The maximum amount of memory to request from the batch\nsystem at\
    \ any one time. default=9223372036854775807"
  args: !SimpleFlagArg
    name: MAXMEMORY
- !Flag
  optional: true
  synonyms:
  - --retryCount
  description: "Number of times to retry a failing job before giving\nup and labeling\
    \ job failed. default=0"
  args: !SimpleFlagArg
    name: RETRYCOUNT
- !Flag
  optional: true
  synonyms:
  - --maxJobDuration
  description: "Maximum runtime of a job (in seconds) before we kill\nit (this is\
    \ a lower bound, and the actual time before\nkilling the job may be longer).\n\
    default=9223372036854775807"
  args: !SimpleFlagArg
    name: MAXJOBDURATION
- !Flag
  optional: true
  synonyms:
  - --rescueJobsFrequency
  description: "Period of time to wait (in seconds) between checking\nfor missing/overlong\
    \ jobs, that is jobs which get lost\nby the batch system. Expert parameter. (default\
    \ is set\nby the batch system)"
  args: !SimpleFlagArg
    name: RESCUEJOBSFREQUENCY
- !Flag
  optional: true
  synonyms:
  - --bigBatchSystem
  description: "The batch system to run for jobs with larger\nmemory/cpus requests,\
    \ currently can be\n'singleMachine'/'parasol'/'acidTest'/'gridEngine'.\ndefault=none"
  args: !SimpleFlagArg
    name: BIGBATCHSYSTEM
- !Flag
  optional: true
  synonyms:
  - --bigMemoryThreshold
  description: "The memory threshold above which to submit to the big\nqueue. default=9223372036854775807"
  args: !SimpleFlagArg
    name: BIGMEMORYTHRESHOLD
- !Flag
  optional: true
  synonyms:
  - --bigCpuThreshold
  description: "The cpu threshold above which to submit to the big\nqueue. default=9223372036854775807"
  args: !SimpleFlagArg
    name: BIGCPUTHRESHOLD
- !Flag
  optional: true
  synonyms:
  - --bigMaxCpus
  description: "The maximum number of big batch system cpus to allow\nat one time\
    \ on the big queue.\ndefault=9223372036854775807"
  args: !SimpleFlagArg
    name: BIGMAXCPUS
- !Flag
  optional: true
  synonyms:
  - --bigMaxMemory
  description: "The maximum amount of memory to request from the big\nbatch system\
    \ at any one time.\ndefault=9223372036854775807"
  args: !SimpleFlagArg
    name: BIGMAXMEMORY
- !Flag
  optional: true
  synonyms:
  - --jobTime
  description: "The approximate time (in seconds) that you'd like a\nlist of child\
    \ jobs to be run serially before being\nparallelized. This parameter allows one\
    \ to avoid over\nparallelizing tiny jobs, and therefore paying\nsignificant scheduling\
    \ overhead, by running tiny jobs\nin series on a single node/core of the cluster.\n\
    default=30"
  args: !SimpleFlagArg
    name: JOBTIME
- !Flag
  optional: true
  synonyms:
  - --maxLogFileSize
  description: "The maximum size of a job log file to keep (in bytes),\nlog files\
    \ larger than this will be truncated to the\nlast X bytes. Default is 50 kilobytes,\
    \ default=50120"
  args: !SimpleFlagArg
    name: MAXLOGFILESIZE
- !Flag
  optional: true
  synonyms:
  - --command
  description: "The command to run (which will generate subsequent\njobs). This is\
    \ deprecated\n"
  args: !SimpleFlagArg
    name: COMMAND
parent:
subcommands: []
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag:
help_text: "Usage: jobTreeTest_Dependencies.py [options]\n\nOptions:\n  -h, --help\
  \            show this help message and exit\n  --sleepTime=SLEEPTIME\n        \
  \                sleep [default=5] seconds\n  --tree=TREE           tree [balanced|comb|star|fly]\n\
  \  --size=SIZE           tree size (for comb or star) [default=10]\n  --cpusPerJob=CPUSPERJOB\n\
  \                        Cpus per job\n\n  Logging options:\n    Options that control\
  \ logging\n\n    --logOff            Turn off logging. (default is CRITICAL)\n \
  \   --logInfo           Turn on logging at INFO level. (default is CRITICAL)\n \
  \   --logDebug          Turn on logging at DEBUG level. (default is CRITICAL)\n\
  \    --logLevel=LOGLEVEL\n                        Log at level (may be either OFF/INFO/DEBUG/CRITICAL).\n\
  \                        (default is CRITICAL)\n    --logFile=LOGFILE   File to\
  \ log in\n    --rotatingLogging   Turn on rotating logging, which prevents log files\n\
  \                        getting too big.\n\n  jobTree core options:\n    Options\
  \ to specify the location of the jobTree and turn on stats\n    collation about\
  \ the performance of jobs.\n\n    --jobTree=JOBTREE   Directory in which to place\
  \ job management files and\n                        the global accessed temporary\
  \ file directories(this\n                        needs to be globally accessible\
  \ by all machines\n                        running jobs). If you pass an existing\
  \ directory it\n                        will check if it's a valid existing job\
  \ tree, then try\n                        and restart the jobs in it. The default=./jobTree\n\
  \    --stats             Records statistics about the job-tree to be used by\n \
  \                       jobTreeStats. default=False\n\n  jobTree options for specifying\
  \ the batch system:\n    Allows the specification of the batch system, and arguments\
  \ to the\n    batch system/big batch system (see below).\n\n    --batchSystem=BATCHSYSTEM\n\
  \                        The type of batch system to run the job(s) with,\n    \
  \                    currently can be 'singleMachine'/'parasol'/'acidTest'/\n  \
  \                      'gridEngine'/'lsf'. default=singleMachine\n    --maxThreads=MAXTHREADS\n\
  \                        The maximum number of threads (technically processes\n\
  \                        at this point) to use when running in single machine\n\
  \                        mode. Increasing this will allow more jobs to run\n   \
  \                     concurrently when running on a single machine.\n         \
  \               default=4\n    --parasolCommand=PARASOLCOMMAND\n               \
  \         The command to run the parasol program default=parasol\n\n  jobTree options\
  \ for cpu/memory requirements:\n    The options to specify default cpu/memory requirements\
  \ (if not\n    specified by the jobs themselves), and to limit the total amount\
  \ of\n    memory/cpu requested from the batch system.\n\n    --defaultMemory=DEFAULTMEMORY\n\
  \                        The default amount of memory to request for a job (in\n\
  \                        bytes), by default is 2^31 = 2 gigabytes,\n           \
  \             default=2147483648\n    --defaultCpu=DEFAULTCPU\n                \
  \        The default the number of cpus to dedicate a job.\n                   \
  \     default=1\n    --maxCpus=MAXCPUS   The maximum number of cpus to request from\
  \ the batch\n                        system at any one time. default=9223372036854775807\n\
  \    --maxMemory=MAXMEMORY\n                        The maximum amount of memory\
  \ to request from the batch\n                        system at any one time. default=9223372036854775807\n\
  \n  jobTree options for rescuing/killing/restarting jobs:\n    The options for jobs\
  \ that either run too long/fail or get lost (some\n    batch systems have issues!)\n\
  \n    --retryCount=RETRYCOUNT\n                        Number of times to retry\
  \ a failing job before giving\n                        up and labeling job failed.\
  \ default=0\n    --maxJobDuration=MAXJOBDURATION\n                        Maximum\
  \ runtime of a job (in seconds) before we kill\n                        it (this\
  \ is a lower bound, and the actual time before\n                        killing\
  \ the job may be longer).\n                        default=9223372036854775807\n\
  \    --rescueJobsFrequency=RESCUEJOBSFREQUENCY\n                        Period of\
  \ time to wait (in seconds) between checking\n                        for missing/overlong\
  \ jobs, that is jobs which get lost\n                        by the batch system.\
  \ Expert parameter. (default is set\n                        by the batch system)\n\
  \n  jobTree big batch system options:\n    jobTree can employ a secondary batch\
  \ system for running large\n    memory/cpu jobs using the following arguments:\n\
  \n    --bigBatchSystem=BIGBATCHSYSTEM\n                        The batch system\
  \ to run for jobs with larger\n                        memory/cpus requests, currently\
  \ can be\n                        'singleMachine'/'parasol'/'acidTest'/'gridEngine'.\n\
  \                        default=none\n    --bigMemoryThreshold=BIGMEMORYTHRESHOLD\n\
  \                        The memory threshold above which to submit to the big\n\
  \                        queue. default=9223372036854775807\n    --bigCpuThreshold=BIGCPUTHRESHOLD\n\
  \                        The cpu threshold above which to submit to the big\n  \
  \                      queue. default=9223372036854775807\n    --bigMaxCpus=BIGMAXCPUS\n\
  \                        The maximum number of big batch system cpus to allow\n\
  \                        at one time on the big queue.\n                       \
  \ default=9223372036854775807\n    --bigMaxMemory=BIGMAXMEMORY\n               \
  \         The maximum amount of memory to request from the big\n               \
  \         batch system at any one time.\n                        default=9223372036854775807\n\
  \n  jobTree miscellaneous options:\n    Miscellaneous options\n\n    --jobTime=JOBTIME\
  \   The approximate time (in seconds) that you'd like a\n                      \
  \  list of child jobs to be run serially before being\n                        parallelized.\
  \ This parameter allows one to avoid over\n                        parallelizing\
  \ tiny jobs, and therefore paying\n                        significant scheduling\
  \ overhead, by running tiny jobs\n                        in series on a single\
  \ node/core of the cluster.\n                        default=30\n    --maxLogFileSize=MAXLOGFILESIZE\n\
  \                        The maximum size of a job log file to keep (in bytes),\n\
  \                        log files larger than this will be truncated to the\n \
  \                       last X bytes. Default is 50 kilobytes, default=50120\n \
  \   --command=COMMAND   The command to run (which will generate subsequent\n   \
  \                     jobs). This is deprecated\n"
generated_using:
- --help
docker_image:
