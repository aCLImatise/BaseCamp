from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import Int, String, Boolean, File

Jobtreetest_Dependencies_Py_V0_1_0 = CommandToolBuilder(tool="jobTreeTest_Dependencies.py", base_command=["jobTreeTest_Dependencies.py"], inputs=[ToolInput(tag="in_sleep_time", input_type=Int(optional=True), prefix="--sleepTime", doc=InputDocumentation(doc="sleep [default=5] seconds")), ToolInput(tag="in_tree", input_type=String(optional=True), prefix="--tree", doc=InputDocumentation(doc="tree [balanced|comb|star|fly]")), ToolInput(tag="in_size", input_type=Int(optional=True), prefix="--size", doc=InputDocumentation(doc="tree size (for comb or star) [default=10]")), ToolInput(tag="in_cpus_per_job", input_type=String(optional=True), prefix="--cpusPerJob", doc=InputDocumentation(doc="Cpus per job")), ToolInput(tag="in_logoff", input_type=Boolean(optional=True), prefix="--logOff", doc=InputDocumentation(doc="Turn off logging. (default is CRITICAL)")), ToolInput(tag="in_loginfo", input_type=Boolean(optional=True), prefix="--logInfo", doc=InputDocumentation(doc="Turn on logging at INFO level. (default is CRITICAL)")), ToolInput(tag="in_log_debug", input_type=Boolean(optional=True), prefix="--logDebug", doc=InputDocumentation(doc="Turn on logging at DEBUG level. (default is CRITICAL)")), ToolInput(tag="in_loglevel", input_type=String(optional=True), prefix="--logLevel", doc=InputDocumentation(doc="Log at level (may be either OFF/INFO/DEBUG/CRITICAL).\n(default is CRITICAL)")), ToolInput(tag="in_log_file", input_type=File(optional=True), prefix="--logFile", doc=InputDocumentation(doc="File to log in")), ToolInput(tag="in_rotating_logging", input_type=Boolean(optional=True), prefix="--rotatingLogging", doc=InputDocumentation(doc="Turn on rotating logging, which prevents log files\ngetting too big.")), ToolInput(tag="in_job_tree", input_type=File(optional=True), prefix="--jobTree", doc=InputDocumentation(doc="Directory in which to place job management files and\nthe global accessed temporary file directories(this\nneeds to be globally accessible by all machines\nrunning jobs). If you pass an existing directory it\nwill check if it's a valid existing job tree, then try\nand restart the jobs in it. The default=./jobTree")), ToolInput(tag="in_stats", input_type=Boolean(optional=True), prefix="--stats", doc=InputDocumentation(doc="Records statistics about the job-tree to be used by\njobTreeStats. default=False")), ToolInput(tag="in_batch_system", input_type=String(optional=True), prefix="--batchSystem", doc=InputDocumentation(doc="The type of batch system to run the job(s) with,\ncurrently can be 'singleMachine'/'parasol'/'acidTest'/\n'gridEngine'/'lsf'. default=singleMachine")), ToolInput(tag="in_max_threads", input_type=Int(optional=True), prefix="--maxThreads", doc=InputDocumentation(doc="The maximum number of threads (technically processes\nat this point) to use when running in single machine\nmode. Increasing this will allow more jobs to run\nconcurrently when running on a single machine.\ndefault=4")), ToolInput(tag="in_parasol_command", input_type=String(optional=True), prefix="--parasolCommand", doc=InputDocumentation(doc="The command to run the parasol program default=parasol")), ToolInput(tag="in_default_memory", input_type=Int(optional=True), prefix="--defaultMemory", doc=InputDocumentation(doc="The default amount of memory to request for a job (in\nbytes), by default is 2^31 = 2 gigabytes,\ndefault=2147483648")), ToolInput(tag="in_default_cpu", input_type=Int(optional=True), prefix="--defaultCpu", doc=InputDocumentation(doc="The default the number of cpus to dedicate a job.\ndefault=1")), ToolInput(tag="in_max_cpus", input_type=Int(optional=True), prefix="--maxCpus", doc=InputDocumentation(doc="The maximum number of cpus to request from the batch\nsystem at any one time. default=9223372036854775807")), ToolInput(tag="in_max_memory", input_type=Int(optional=True), prefix="--maxMemory", doc=InputDocumentation(doc="The maximum amount of memory to request from the batch\nsystem at any one time. default=9223372036854775807")), ToolInput(tag="in_retry_count", input_type=Int(optional=True), prefix="--retryCount", doc=InputDocumentation(doc="Number of times to retry a failing job before giving\nup and labeling job failed. default=0")), ToolInput(tag="in_max_job_duration", input_type=Int(optional=True), prefix="--maxJobDuration", doc=InputDocumentation(doc="Maximum runtime of a job (in seconds) before we kill\nit (this is a lower bound, and the actual time before\nkilling the job may be longer).\ndefault=9223372036854775807")), ToolInput(tag="in_rescue_jobs_frequency", input_type=String(optional=True), prefix="--rescueJobsFrequency", doc=InputDocumentation(doc="Period of time to wait (in seconds) between checking\nfor missing/overlong jobs, that is jobs which get lost\nby the batch system. Expert parameter. (default is set\nby the batch system)")), ToolInput(tag="in_big_batch_system", input_type=String(optional=True), prefix="--bigBatchSystem", doc=InputDocumentation(doc="The batch system to run for jobs with larger\nmemory/cpus requests, currently can be\n'singleMachine'/'parasol'/'acidTest'/'gridEngine'.\ndefault=none")), ToolInput(tag="in_big_memory_threshold", input_type=Int(optional=True), prefix="--bigMemoryThreshold", doc=InputDocumentation(doc="The memory threshold above which to submit to the big\nqueue. default=9223372036854775807")), ToolInput(tag="in_big_cpu_threshold", input_type=Int(optional=True), prefix="--bigCpuThreshold", doc=InputDocumentation(doc="The cpu threshold above which to submit to the big\nqueue. default=9223372036854775807")), ToolInput(tag="in_big_max_cpus", input_type=Int(optional=True), prefix="--bigMaxCpus", doc=InputDocumentation(doc="The maximum number of big batch system cpus to allow\nat one time on the big queue.\ndefault=9223372036854775807")), ToolInput(tag="in_big_max_memory", input_type=Int(optional=True), prefix="--bigMaxMemory", doc=InputDocumentation(doc="The maximum amount of memory to request from the big\nbatch system at any one time.\ndefault=9223372036854775807")), ToolInput(tag="in_job_time", input_type=Int(optional=True), prefix="--jobTime", doc=InputDocumentation(doc="The approximate time (in seconds) that you'd like a\nlist of child jobs to be run serially before being\nparallelized. This parameter allows one to avoid over\nparallelizing tiny jobs, and therefore paying\nsignificant scheduling overhead, by running tiny jobs\nin series on a single node/core of the cluster.\ndefault=30")), ToolInput(tag="in_max_log_file_size", input_type=Int(optional=True), prefix="--maxLogFileSize", doc=InputDocumentation(doc="The maximum size of a job log file to keep (in bytes),\nlog files larger than this will be truncated to the\nlast X bytes. Default is 50 kilobytes, default=50120")), ToolInput(tag="in_command", input_type=String(optional=True), prefix="--command", doc=InputDocumentation(doc="The command to run (which will generate subsequent\njobs). This is deprecated\n"))], outputs=[], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Jobtreetest_Dependencies_Py_V0_1_0().translate("wdl", allow_empty_container=True)

