from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import File, Directory, Int, Boolean, String

Mhcflurry_Class1_Train_Processing_Models_V0_1_0 = CommandToolBuilder(tool="mhcflurry_class1_train_processing_models", base_command=["mhcflurry-class1-train-processing-models"], inputs=[ToolInput(tag="in_data", input_type=File(optional=True), prefix="--data", doc=InputDocumentation(doc="Training data CSV. Expected columns: peptide, n_flank,\nc_flank, hit")), ToolInput(tag="in_out_models_dir", input_type=Directory(optional=True), prefix="--out-models-dir", doc=InputDocumentation(doc="Directory to write models and manifest")), ToolInput(tag="in_hyperparameters", input_type=File(optional=True), prefix="--hyperparameters", doc=InputDocumentation(doc="JSON or YAML of hyperparameters")), ToolInput(tag="in_held_out_samples", input_type=Int(optional=True), prefix="--held-out-samples", doc=InputDocumentation(doc="Number of experiments to hold out per fold")), ToolInput(tag="in_num_folds", input_type=Int(optional=True), prefix="--num-folds", doc=InputDocumentation(doc="Number of training folds.")), ToolInput(tag="in_num_replicates", input_type=Int(optional=True), prefix="--num-replicates", doc=InputDocumentation(doc="Number of replicates per (architecture, fold) pair to")), ToolInput(tag="in_verbosity", input_type=Int(optional=True), prefix="--verbosity", doc=InputDocumentation(doc="Keras verbosity. Default: 0")), ToolInput(tag="in_debug", input_type=Boolean(optional=True), prefix="--debug", doc=InputDocumentation(doc="Launch python debugger on error")), ToolInput(tag="in_continue_incomplete", input_type=Boolean(optional=True), prefix="--continue-incomplete", doc=InputDocumentation(doc="Continue training models from an incomplete training\nrun. If this is specified then the only required\nargument is --out-models-dir")), ToolInput(tag="in_only_initialize", input_type=Boolean(optional=True), prefix="--only-initialize", doc=InputDocumentation(doc="Do not actually train models. The initialized run can\nbe continued later with --continue-incomplete.")), ToolInput(tag="in_num_jobs", input_type=Int(optional=True), prefix="--num-jobs", doc=InputDocumentation(doc="Number of local processes to parallelize training\nover. Set to 0 for serial run. Default: 0.")), ToolInput(tag="in_backend", input_type=String(optional=True), prefix="--backend", doc=InputDocumentation(doc="Keras backend. If not specified will use system\ndefault.")), ToolInput(tag="in_gpus", input_type=Int(optional=True), prefix="--gpus", doc=InputDocumentation(doc="Number of GPUs to attempt to parallelize across.\nRequires running in parallel.")), ToolInput(tag="in_max_workers_per_gpu", input_type=Int(optional=True), prefix="--max-workers-per-gpu", doc=InputDocumentation(doc="Maximum number of workers to assign to a GPU.\nAdditional tasks will run on CPU.")), ToolInput(tag="in_max_tasks_per_worker", input_type=Int(optional=True), prefix="--max-tasks-per-worker", doc=InputDocumentation(doc="Restart workers after N tasks. Workaround for\ntensorflow memory leaks. Requires Python >=3.2.")), ToolInput(tag="in_worker_log_dir", input_type=Directory(optional=True), prefix="--worker-log-dir", doc=InputDocumentation(doc="Write worker stdout and stderr logs to given\ndirectory.")), ToolInput(tag="in_cluster_submit_command", input_type=String(optional=True), prefix="--cluster-submit-command", doc=InputDocumentation(doc="Default: sh")), ToolInput(tag="in_cluster_results_workdir", input_type=String(optional=True), prefix="--cluster-results-workdir", doc=InputDocumentation(doc="Default: ./cluster-workdir")), ToolInput(tag="in_additional_complete_file", input_type=File(optional=True), prefix="--additional-complete-file", doc=InputDocumentation(doc="Additional file to monitor for job completion.\nDefault: STDERR")), ToolInput(tag="in_cluster_script_prefix_path", input_type=File(optional=True), prefix="--cluster-script-prefix-path", doc=InputDocumentation(doc="How many times to rerun failing jobs. Default: 3\n")), ToolInput(tag="in_train_dot", input_type=String(), position=0, doc=InputDocumentation(doc="--max-epochs N        Max training epochs. If specified here it overrides"))], outputs=[], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Mhcflurry_Class1_Train_Processing_Models_V0_1_0().translate("wdl", allow_empty_container=True)

