from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import Boolean, String, Directory, File

Dv_Call_Variants_Py_V0_1_0 = CommandToolBuilder(tool="dv_call_variants.py", base_command=["dv_call_variants.py"], inputs=[ToolInput(tag="in_batch_size", input_type=Boolean(optional=True), prefix="--batch_size", doc=InputDocumentation(doc=": Number of candidate variant tensors to batch together during\ninference. Larger batches use more memory but are more computational\nefficient.\n(default: '512')\n(an integer)")), ToolInput(tag="in_checkpoint", input_type=Boolean(optional=True), prefix="--checkpoint", doc=InputDocumentation(doc=": Required. Path to the TensorFlow model checkpoint to use to\nevaluate candidate variant calls.")), ToolInput(tag="in_config_string", input_type=Boolean(optional=True), prefix="--config_string", doc=InputDocumentation(doc=": String representation of a tf.ConfigProto message, with\ncomma-separated key: value pairs, such as 'allow_soft_placement: True'. The\nvalue can itself be another message, such as 'gpu_options:\n{per_process_gpu_memory_fraction: 0.5}'.")), ToolInput(tag="in_include_debug_info", input_type=String(optional=True), prefix="--include_debug_info", doc=InputDocumentation(doc="set to true.")), ToolInput(tag="in_examples", input_type=Directory(optional=True), prefix="--examples", doc=InputDocumentation(doc="Example directory from make_examples")), ToolInput(tag="in_execution_hardware", input_type=Boolean(optional=True), prefix="--execution_hardware", doc=InputDocumentation(doc=": When in cpu mode, call_variants will not place any ops\non the GPU, even if one is available. In accelerator mode call_variants\nvalidates that at least some hardware accelerator (GPU/TPU) was available\nfor us. This option is primarily for QA purposes to allow users to validate\ntheir accelerator environment is correctly configured. In auto mode, the\ndefault, op placement is entirely left up to TensorFlow.  In tpu mode, use\nand require TPU.\n(default: 'auto')")), ToolInput(tag="in_gcp_project", input_type=Boolean(optional=True), prefix="--gcp_project", doc=InputDocumentation(doc=": Project name for the Cloud TPU-enabled project. If not\nspecified, we will attempt to automatically detect the GCE project from\nmetadata.")), ToolInput(tag="in_kmp_block_time", input_type=Boolean(optional=True), prefix="--kmp_blocktime", doc=InputDocumentation(doc=": Value to set the KMP_BLOCKTIME environment variable to for\nefficient MKL inference. See\nhttps://www.tensorflow.org/performance/performance_guide for more\ninformation. The default value is 0, which provides the best performance in\nour tests. Set this flag to '' to not set the variable.\n(default: '0')")), ToolInput(tag="in_master", input_type=Boolean(optional=True), prefix="--master", doc=InputDocumentation(doc=": GRPC URL of the master (e.g. grpc://ip.address.of.tpu:8470). You\nmust specify either this flag or --tpu_name.")), ToolInput(tag="in_max_batches", input_type=Boolean(optional=True), prefix="--max_batches", doc=InputDocumentation(doc=": Max. batches to evaluate. Defaults to all.\n(an integer)")), ToolInput(tag="in_model_name", input_type=Boolean(optional=True), prefix="--model_name", doc=InputDocumentation(doc=": The name of the model architecture of --checkpoint.\n(default: 'inception_v3')")), ToolInput(tag="in_num_mappers", input_type=Boolean(optional=True), prefix="--num_mappers", doc=InputDocumentation(doc=": Number of parallel mappers to create for examples.\n(default: '48')\n(an integer)")), ToolInput(tag="in_num_readers", input_type=Boolean(optional=True), prefix="--num_readers", doc=InputDocumentation(doc=": Number of parallel readers to create for examples.\n(default: '8')\n(an integer)")), ToolInput(tag="in_outfile", input_type=File(optional=True), prefix="--outfile", doc=InputDocumentation(doc=": Required. Destination path where we will write output candidate\nvariants with additional likelihood information in TFRecord format of\nCallVariantsOutput protos.")), ToolInput(tag="in_tpu_name", input_type=Boolean(optional=True), prefix="--tpu_name", doc=InputDocumentation(doc=": Name of the Cloud TPU for Cluster Resolvers. You must specify\neither this flag or --master. An empty value corresponds to no Cloud TPU.\nSee https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolve\nr/TPUClusterResolver")), ToolInput(tag="in_tpu_zone", input_type=Boolean(optional=True), prefix="--tpu_zone", doc=InputDocumentation(doc=": GCE zone where the Cloud TPU is located in. If not specified, we\nwill attempt to automatically detect the GCE project from metadata.")), ToolInput(tag="in_sample", input_type=String(optional=True), prefix="--sample", doc=InputDocumentation(doc="Sample name")), ToolInput(tag="in_model", input_type=String(optional=True), prefix="--model", doc=InputDocumentation(doc="DeepVariant trained model to use, defaults to wgs"))], outputs=[ToolOutput(tag="out_outfile", output_type=File(optional=True), selector=InputSelector(input_to_select="in_outfile", type_hint=File()), doc=OutputDocumentation(doc=": Required. Destination path where we will write output candidate\nvariants with additional likelihood information in TFRecord format of\nCallVariantsOutput protos."))], container="quay.io/biocontainers/deepvariant:1.1.0--py36hf3e76ba_0", version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Dv_Call_Variants_Py_V0_1_0().translate("wdl")

