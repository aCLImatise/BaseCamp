!Command
command:
- fastprot_mpi
positional: []
named: []
parent:
subcommands: []
usage: []
help_flag:
usage_flag:
version_flag:
help_text: "--------------------------------------------------------------------------\n\
  The value of the MCA parameter \"plm_rsh_agent\" was set to a path\nthat could not\
  \ be found:\n\n  plm_rsh_agent: ssh : rsh\n\nPlease either unset the parameter,\
  \ or check that the path is correct\n--------------------------------------------------------------------------\n\
  [eb4d59f84164:00091] [[INVALID],INVALID] FORCE-TERMINATE AT Not found:-13 - error\
  \ plm_rsh_component.c(327)\n[eb4d59f84164:00091] *** Process received signal ***\n\
  [eb4d59f84164:00091] Signal: Segmentation fault (11)\n[eb4d59f84164:00091] Signal\
  \ code: Address not mapped (1)\n[eb4d59f84164:00091] Failing at address: (nil)\n\
  [eb4d59f84164:00091] [ 0] /lib/libpthread.so.0(+0x10220)[0x7f37f83de220]\n[eb4d59f84164:00091]\
  \ *** End of error message ***\n[eb4d59f84164:00079] [[INVALID],INVALID] ORTE_ERROR_LOG:\
  \ Unable to start a daemon on the local node in file ess_singleton_module.c at line\
  \ 532\n[eb4d59f84164:00079] [[INVALID],INVALID] ORTE_ERROR_LOG: Unable to start\
  \ a daemon on the local node in file ess_singleton_module.c at line 166\n--------------------------------------------------------------------------\n\
  It looks like orte_init failed for some reason; your parallel process is\nlikely\
  \ to abort.  There are many reasons that a parallel process can\nfail during orte_init;\
  \ some of which are due to configuration or\nenvironment problems.  This failure\
  \ appears to be an internal failure;\nhere's some additional information (which\
  \ may only be relevant to an\nOpen MPI developer):\n\n  orte_ess_init failed\n \
  \ --> Returned value Unable to start a daemon on the local node (-127) instead of\
  \ ORTE_SUCCESS\n--------------------------------------------------------------------------\n\
  --------------------------------------------------------------------------\nIt looks\
  \ like MPI_INIT failed for some reason; your parallel process is\nlikely to abort.\
  \  There are many reasons that a parallel process can\nfail during MPI_INIT; some\
  \ of which are due to configuration or environment\nproblems.  This failure appears\
  \ to be an internal failure; here's some\nadditional information (which may only\
  \ be relevant to an Open MPI\ndeveloper):\n\n  ompi_mpi_init: ompi_rte_init failed\n\
  \  --> Returned \"Unable to start a daemon on the local node\" (-127) instead of\
  \ \"Success\" (0)\n--------------------------------------------------------------------------\n\
  *** An error occurred in MPI_Init\n*** on a NULL communicator\n*** MPI_ERRORS_ARE_FATAL\
  \ (processes in this communicator will now abort,\n***    and potentially your MPI\
  \ job)\n[eb4d59f84164:00079] Local abort before MPI_INIT completed completed successfully,\
  \ but am not able to aggregate error messages, and not able to guarantee that all\
  \ other processes were killed!\n"
generated_using:
- --help
