from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import Int, Directory, Boolean, String, Float

Halla_V0_1_0 = CommandToolBuilder(tool="halla", base_command=["halla"], inputs=[ToolInput(tag="in_first_file_tabdelimited", input_type=Int(optional=True), prefix="-X", doc=InputDocumentation(doc="first file: Tab-delimited text input file, one row per feature, one column per measurement\n[REQUIRED]")), ToolInput(tag="in_second_file_tabdelimited", input_type=Int(optional=True), prefix="-Y", doc=InputDocumentation(doc="second file: Tab-delimited text input file, one row per feature, one column per measurement\n[default = the first file (-X)]")), ToolInput(tag="in_output", input_type=Directory(optional=True), prefix="--output", doc=InputDocumentation(doc="directory to write output files\n[REQUIRED]")), ToolInput(tag="in_qvalue_overall_significance", input_type=Boolean(optional=True), prefix="-q", doc=InputDocumentation(doc="<.1>, --q-value <.1>\nq-value for overall significance tests (cut-off for false discovery rate)\n[default = 0.1]")), ToolInput(tag="in_fnt", input_type=Boolean(optional=True), prefix="--fnt", doc=InputDocumentation(doc="<.25>           Estimated False Negative Tolerance in block association\n[default = 0.25]")), ToolInput(tag="in_permutation", input_type=String(optional=True), prefix="--permutation", doc=InputDocumentation(doc="permutation function\n[default = none for Spearman and Pearson and gpd for other]")), ToolInput(tag="in_descending", input_type=String(optional=True), prefix="--descending", doc=InputDocumentation(doc="descending approach\n[default = HAllA for hierarchical all-against-all]")), ToolInput(tag="in_iterations", input_type=Int(optional=True), prefix="--iterations", doc=InputDocumentation(doc="iterations for nonparametric significance testing (permutation test)\n[default = 1000]")), ToolInput(tag="in_metric", input_type=String(optional=True), prefix="--metric", doc=InputDocumentation(doc="metric to be used for similarity measurement\n[default = '']")), ToolInput(tag="in_fdr", input_type=String(optional=True), prefix="--fdr", doc=InputDocumentation(doc="approach for FDR correction\n[default = bh]")), ToolInput(tag="in_verbose", input_type=String(optional=True), prefix="--verbose", doc=InputDocumentation(doc="additional output is printed")), ToolInput(tag="in_diagnostics_plot", input_type=Boolean(optional=True), prefix="--diagnostics-plot", doc=InputDocumentation(doc="Diagnostics plot for associations")), ToolInput(tag="in_discretizing", input_type=String(optional=True), prefix="--discretizing", doc=InputDocumentation(doc="approach for discretizing continuous data\n[default = equal-freq]")), ToolInput(tag="in_linkage", input_type=String(optional=True), prefix="--linkage", doc=InputDocumentation(doc="The method to be used in linkage hierarchical clustering.")), ToolInput(tag="in_generate_one_null_samples", input_type=Boolean(optional=True), prefix="--generate-one-null-samples", doc=InputDocumentation(doc="Use one null distribution for permutation test")), ToolInput(tag="in_header", input_type=Boolean(optional=True), prefix="--header", doc=InputDocumentation(doc="the input files contain a header line")), ToolInput(tag="in_format_feature_names", input_type=Boolean(optional=True), prefix="--format-feature-names", doc=InputDocumentation(doc="Replaces special characters and for OTUs separated  by | uses the known end of a clade")), ToolInput(tag="in_nproc", input_type=Int(optional=True), prefix="--nproc", doc=InputDocumentation(doc="the number of processing units available\n[default = 1]")), ToolInput(tag="in_nb_in", input_type=Int(optional=True), prefix="--nbin", doc=InputDocumentation(doc="the number of bins for discretizing\n[default = None]")), ToolInput(tag="in_seed", input_type=Int(optional=True), prefix="--seed", doc=InputDocumentation(doc="a seed number to make the random permutation reproducible\n[default = 0,and -1 for random number]")), ToolInput(tag="in_entropy", input_type=Float(optional=True), prefix="--entropy", doc=InputDocumentation(doc="Minimum entropy threshold to filter features with low information\n[default = 0.5]")), ToolInput(tag="in_entropy_one", input_type=Int(optional=True), prefix="--entropy1", doc=InputDocumentation(doc="Minimum entropy threshold for the first dataset\n[default = None]")), ToolInput(tag="in_entropy_two", input_type=Int(optional=True), prefix="--entropy2", doc=InputDocumentation(doc="Minimum entropy threshold for the second dataset\n[default = None]")), ToolInput(tag="in_missing_char", input_type=String(optional=True), prefix="--missing-char", doc=InputDocumentation(doc="defines missing characters\n[default = '']")), ToolInput(tag="in_fill_missing", input_type=String(optional=True), prefix="--fill-missing", doc=InputDocumentation(doc="defines missing strategy to fill missing data.\nFor categorical data puts all missing data in one new category.")), ToolInput(tag="in_missing_data_category", input_type=Boolean(optional=True), prefix="--missing-data-category", doc=InputDocumentation(doc="To count the missing data as a category")), ToolInput(tag="in_write_hypothesis_tree", input_type=Boolean(optional=True), prefix="--write-hypothesis-tree", doc=InputDocumentation(doc="To write levels of hypothesis tree in the file")), ToolInput(tag="in_data_transformation_method", input_type=Boolean(optional=True), prefix="-t", doc=InputDocumentation(doc="{log,sqrt,arcsin,arcsinh,}, --transform {log,sqrt,arcsin,arcsinh,}\ndata transformation method\n[default = '' ]\n"))], outputs=[ToolOutput(tag="out_output", output_type=Directory(optional=True), selector=InputSelector(input_to_select="in_output", type_hint=File()), doc=OutputDocumentation(doc="directory to write output files\n[REQUIRED]"))], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Halla_V0_1_0().translate("wdl", allow_empty_container=True)

