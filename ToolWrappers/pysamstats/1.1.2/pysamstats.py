from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import String, Int, Boolean, File

Pysamstats_V0_1_0 = CommandToolBuilder(tool="pysamstats", base_command=["pysamstats"], inputs=[ToolInput(tag="in_type", input_type=String(optional=True), prefix="--type", doc=InputDocumentation(doc="Type of statistics to print, one of: alignment_binned,\nbaseq, baseq_ext, baseq_ext_strand, baseq_strand,\ncoverage, coverage_binned, coverage_ext,\ncoverage_ext_binned, coverage_ext_strand, coverage_gc,\ncoverage_strand, mapq, mapq_binned, mapq_strand, tlen,\ntlen_binned, tlen_strand, variation, variation_strand.")), ToolInput(tag="in_chromosome", input_type=String(optional=True), prefix="--chromosome", doc=InputDocumentation(doc="Chromosome name.")), ToolInput(tag="in_start", input_type=Int(optional=True), prefix="--start", doc=InputDocumentation(doc="Start position (1-based).")), ToolInput(tag="in_end", input_type=Int(optional=True), prefix="--end", doc=InputDocumentation(doc="End position (1-based).")), ToolInput(tag="in_zero_based", input_type=Boolean(optional=True), prefix="--zero-based", doc=InputDocumentation(doc="Use zero-based coordinates (default is false, i.e.,\nuse one-based coords).")), ToolInput(tag="in_truncate", input_type=Boolean(optional=True), prefix="--truncate", doc=InputDocumentation(doc="Truncate pileup-based stats so no records are emitted\noutside the specified range.")), ToolInput(tag="in_stepper", input_type=File(optional=True), prefix="--stepper", doc=InputDocumentation(doc="Stepper to provide to underlying pysam call. Options\nare:'all' (default): all reads are returned, except\nwhere flags BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL,\nBAM_FDUP set; 'nofilter' applies no filter to returned\nreads; 'samtools': filter & read processing as in\n_csamtools_ pileup. This requires a fasta file. For\ncomplete details see the pysam documentation.")), ToolInput(tag="in_pad", input_type=Boolean(optional=True), prefix="--pad", doc=InputDocumentation(doc="Pad pileup-based stats so a record is emitted for\nevery position (default is only covered positions).")), ToolInput(tag="in_max_depth", input_type=Int(optional=True), prefix="--max-depth", doc=InputDocumentation(doc="Maximum read depth permitted in pileup-based\nstatistics. The default limit is 8000.")), ToolInput(tag="in_fast_a", input_type=File(optional=True), prefix="--fasta", doc=InputDocumentation(doc="Reference sequence file, only required for some\nstatistics.")), ToolInput(tag="in_omit_header", input_type=Boolean(optional=True), prefix="--omit-header", doc=InputDocumentation(doc="Omit header row from output.")), ToolInput(tag="in_progress", input_type=String(optional=True), prefix="--progress", doc=InputDocumentation(doc="Report progress every N rows.")), ToolInput(tag="in_window_size", input_type=Int(optional=True), prefix="--window-size", doc=InputDocumentation(doc="Size of window for binned statistics (default is 300).")), ToolInput(tag="in_window_offset", input_type=Int(optional=True), prefix="--window-offset", doc=InputDocumentation(doc="Window offset to use for deciding which genome\nposition to report binned statistics against. The\ndefault is 150, i.e., the middle of 300bp window.")), ToolInput(tag="in_format", input_type=Int(optional=True), prefix="--format", doc=InputDocumentation(doc="Output format, one of {tsv, csv, hdf5} (defaults to\ntsv). N.B., hdf5 requires PyTables to be installed.")), ToolInput(tag="in_output", input_type=File(optional=True), prefix="--output", doc=InputDocumentation(doc="Path to output file. If not provided, write to stdout.")), ToolInput(tag="in_fields", input_type=String(optional=True), prefix="--fields", doc=InputDocumentation(doc="Comma-separated list of fields to output (defaults to\nall fields).")), ToolInput(tag="in_hdf_five_group", input_type=Int(optional=True), prefix="--hdf5-group", doc=InputDocumentation(doc="Name of HDF5 group to write to (defaults to the root\ngroup).")), ToolInput(tag="in_hdf_five_dataset", input_type=Int(optional=True), prefix="--hdf5-dataset", doc=InputDocumentation(doc="Name of HDF5 dataset to create (defaults to 'data').")), ToolInput(tag="in_hdf_five_comp_lib", input_type=Int(optional=True), prefix="--hdf5-complib", doc=InputDocumentation(doc="HDF5 compression library (defaults to zlib).")), ToolInput(tag="in_hdf_five_comp_level", input_type=Int(optional=True), prefix="--hdf5-complevel", doc=InputDocumentation(doc="HDF5 compression level (defaults to 5).")), ToolInput(tag="in_hdf_five_chunksize", input_type=Int(optional=True), prefix="--hdf5-chunksize", doc=InputDocumentation(doc="Size of chunks in number of bytes (defaults to 2**20).")), ToolInput(tag="in_min_mapq", input_type=Int(optional=True), prefix="--min-mapq", doc=InputDocumentation(doc="Only reads with mapping quality equal to or greater\nthan this value will be counted (0 by default).")), ToolInput(tag="in_min_base_q", input_type=Int(optional=True), prefix="--min-baseq", doc=InputDocumentation(doc="Only reads with base quality equal to or greater than\nthis value will be counted (0 by default). Only\napplies to pileup-based statistics.")), ToolInput(tag="in_no_dup", input_type=Boolean(optional=True), prefix="--no-dup", doc=InputDocumentation(doc="Don't count reads flagged as duplicate.")), ToolInput(tag="in_no_del", input_type=Boolean(optional=True), prefix="--no-del", doc=InputDocumentation(doc="Don't count reads aligned with a deletion at the given\nposition. Only applies to pileup-based statistics.")), ToolInput(tag="in_file", input_type=File(), position=0, doc=InputDocumentation(doc=""))], outputs=[ToolOutput(tag="out_output", output_type=File(optional=True), selector=InputSelector(input_to_select="in_output", type_hint=File()), doc=OutputDocumentation(doc="Path to output file. If not provided, write to stdout."))], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Pysamstats_V0_1_0().translate("wdl", allow_empty_container=True)

