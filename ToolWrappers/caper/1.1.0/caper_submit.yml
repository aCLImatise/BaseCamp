!Command
command:
- caper
- submit
positional:
- !Positional
  optional: false
  position: 0
  name: server.
  description: --singularity-cachedir SINGULARITY_CACHEDIR
named:
- !Flag
  optional: true
  synonyms:
  - -c
  - --conf
  description: Specify config file
  args: !SimpleFlagArg
    name: CONF
- !Flag
  optional: true
  synonyms:
  - -D
  - --debug
  description: Prints all logs >= DEBUG level
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --gcp-service-account-key-json
  description: "Secret key JSON file for Google Cloud Platform service\naccount. This\
    \ service account should have enough\npermission to Storage for client functions\
    \ and\nStorage/Compute Engine/Genomics API/Life Sciences API\nfor server/runner\
    \ functions."
  args: !SimpleFlagArg
    name: GCP_SERVICE_ACCOUNT_KEY_JSON
- !Flag
  optional: true
  synonyms:
  - --port
  description: Port for Caper server
  args: !SimpleFlagArg
    name: PORT
- !Flag
  optional: true
  synonyms:
  - --no-server-heartbeat
  description: Disable server heartbeat file.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --server-heartbeat-file
  description: "Heartbeat file for Caper clients to get IP and port of\na server"
  args: !SimpleFlagArg
    name: SERVER_HEARTBEAT_FILE
- !Flag
  optional: true
  synonyms:
  - --server-heartbeat-timeout
  description: "Timeout for a heartbeat file in Milliseconds. A\nheartbeat file older\
    \ than this interval will be\nignored."
  args: !SimpleFlagArg
    name: SERVER_HEARTBEAT_TIMEOUT
- !Flag
  optional: true
  synonyms:
  - --hostname
  - --ip
  description: Hostname (or IP address) of Caper server.
  args: !SimpleFlagArg
    name: HOSTNAME
- !Flag
  optional: true
  synonyms:
  - -i
  - --inputs
  description: Workflow inputs JSON file
  args: !SimpleFlagArg
    name: INPUTS
- !Flag
  optional: true
  synonyms:
  - -o
  - --options
  description: Workflow options JSON file
  args: !SimpleFlagArg
    name: OPTIONS
- !Flag
  optional: true
  synonyms:
  - -l
  - --labels
  description: Workflow labels JSON file
  args: !SimpleFlagArg
    name: LABELS
- !Flag
  optional: true
  synonyms:
  - -p
  - --imports
  description: Zip file of imported subworkflows
  args: !SimpleFlagArg
    name: IMPORTS
- !Flag
  optional: true
  synonyms:
  - -s
  - --str-label
  description: "Caper's special label for a workflow This label will\nbe added to\
    \ a workflow labels JSON file as a value for\na key \"caper-label\". DO NOT USE\
    \ IRREGULAR CHARACTERS.\nUSE LETTERS, NUMBERS, DASHES AND UNDERSCORES ONLY\n(^[A-Za-z0-9\\\
    -\\_]+$) since this label is used to\ncompose a path for workflow's temporary/cache\n\
    directory (.caper_tmp/label/timestamp/)"
  args: !SimpleFlagArg
    name: STR_LABEL
- !Flag
  optional: true
  synonyms:
  - --hold
  description: Put a hold on a workflow when submitted to a Cromwell
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --use-gsutil-for-s3
  description: "Use gsutil CLI for direct trasnfer between S3 and GCS\nbuckets. Otherwise,\
    \ such file transfer will stream\nthrough local machine. Make sure that gsutil\
    \ is\ninstalled on your system and it has access to\ncredentials for AWS (e.g.\
    \ ~/.boto or\n~/.aws/credentials)."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-deepcopy
  description: "(IMPORTANT) --deepcopy has been deprecated.\nDeepcopying is now activated\
    \ by default. This flag\ndisables deepcopy for JSON (.json), TSV (.tsv) and CSV\n\
    (.csv) files specified in an input JSON file\n(--inputs). Find all path/URI string\
    \ values in an\ninput JSON file and make copies of files on a\nlocal/remote storage\
    \ for a target backend. Make sure\nthat you have installed gsutil for GCS and\
    \ aws for S3."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --ignore-womtool
  description: Ignore warnings from womtool.jar.
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --womtool
  description: Path or URL for Cromwell's womtool JAR file
  args: !SimpleFlagArg
    name: WOMTOOL
- !Flag
  optional: true
  synonyms:
  - --java-heap-womtool
  description: Java heap size for Womtool (java -Xmx)
  args: !SimpleFlagArg
    name: JAVA_HEAP_WOMTOOL
- !Flag
  optional: true
  synonyms:
  - --max-retries
  description: "Number of retries for failing tasks. equivalent to\n\"maxRetries\"\
    \ in workflow options JSON file."
  args: !SimpleFlagArg
    name: MAX_RETRIES
- !Flag
  optional: true
  synonyms:
  - -b
  - --backend
  description: Backend to run a workflow
  args: !SimpleFlagArg
    name: BACKEND
- !Flag
  optional: true
  synonyms:
  - --dry-run
  description: "Caper localizes remote files and validates WDL but\ndoes not run/submit\
    \ a pipeline."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --local-loc-dir
  - --tmp-dir
  description: "Temporary directory to store Cromwell's intermediate\nbackend files.\
    \ These files include backend.conf,\nworkflow_opts.json, imports.zip. and localized\
    \ input\nJSON files due to deepcopying (recursive\nlocalization). Cromwell's MySQL/PostgreSQL\
    \ DB password\ncan be exposed on backend.conf on this directory.\nTherefore, DO\
    \ NOT USE /tmp HERE. This directory is\nalso used for storing cached files for\n\
    local/slurm/sge/pbs backends."
  args: !SimpleFlagArg
    name: LOCAL_LOC_DIR
- !Flag
  optional: true
  synonyms:
  - --gcp-loc-dir
  - --tmp-gcs-bucket
  description: "Temporary directory to store cached files for gcp\nbackend. e.g. gs://my-bucket/caper-cache-dir."
  args: !SimpleFlagArg
    name: GCP_LOC_DIR
- !Flag
  optional: true
  synonyms:
  - --aws-loc-dir
  - --tmp-s3-bucket
  description: "Temporary directory to store cached files for aws\nbackend. e.g. s3://my-bucket/caper-cache-dir."
  args: !SimpleFlagArg
    name: AWS_LOC_DIR
- !Flag
  optional: true
  synonyms:
  - --docker
  description: "[DOCKER]     URI for Docker image (e.g. ubuntu:latest). This can\n\
    also be used as a flag to use Docker image address\ndefined in your WDL file as\
    \ a comment (\"#CAPER\ndocker\") or as \"workflow.meta.caper_docker\" in WDL."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --singularity
  description: "[SINGULARITY]\nURI or path for Singularity image (e.g.\n~/.singularity/ubuntu-latest.simg,\n\
    docker://ubuntu:latest, shub://vsoch/hello-world).\nThis can also be used as a\
    \ flag to use Docker image\naddress defined in your WDL file as a comment (\"\
    #CAPER\nsingularity\") or as \"workflow.meta.caper_singularity\"\nin WDL."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --no-build-singularity
  description: "Do not build singularity image before running a\nworkflow."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --slurm-partition
  description: SLURM partition
  args: !SimpleFlagArg
    name: SLURM_PARTITION
- !Flag
  optional: true
  synonyms:
  - --slurm-account
  description: SLURM account
  args: !SimpleFlagArg
    name: SLURM_ACCOUNT
- !Flag
  optional: true
  synonyms:
  - --slurm-extra-param
  description: SLURM extra parameters. Must be double-quoted
  args: !SimpleFlagArg
    name: SLURM_EXTRA_PARAM
- !Flag
  optional: true
  synonyms:
  - --sge-pe
  description: SGE parallel environment. Check with "qconf -spl"
  args: !SimpleFlagArg
    name: SGE_PE
- !Flag
  optional: true
  synonyms:
  - --sge-queue
  description: SGE queue. Check with "qconf -sql"
  args: !SimpleFlagArg
    name: SGE_QUEUE
- !Flag
  optional: true
  synonyms:
  - --sge-extra-param
  description: SGE extra parameters. Must be double-quoted
  args: !SimpleFlagArg
    name: SGE_EXTRA_PARAM
- !Flag
  optional: true
  synonyms:
  - --pbs-queue
  description: PBS queue
  args: !SimpleFlagArg
    name: PBS_QUEUE
- !Flag
  optional: true
  synonyms:
  - --pbs-extra-param
  description: PBS extra parameters. Must be double-quoted
  args: !SimpleFlagArg
    name: PBS_EXTRA_PARAM
- !Flag
  optional: true
  synonyms:
  - --use-google-cloud-life-sciences
  description: "Use Google Cloud Life Sciences API (v2beta) instead of\ndeprecated\
    \ Genomics API (v2alpha1).Life Sciences API\nrequires only one region specified\
    \ withgcp-region.\ngcp-zones will be ignored since it is for Genomics\nAPI.See\
    \ https://cloud.google.com/life-\nsciences/docs/concepts/locations for supported\n\
    regions."
  args: !EmptyFlagArg {}
- !Flag
  optional: true
  synonyms:
  - --gcp-zones
  description: "Comma-separated GCP zones used for Genomics API. (e.g.\nus-west1-b,us-central1-b).\
    \ If you use --use-google-\ncloud-life-sciences then define --gcp-region instead.\n"
  args: !SimpleFlagArg
    name: GCP_ZONES
parent:
subcommands: []
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag:
help_text: "usage: caper submit [-h] [-c CONF] [-D]\n                    [--gcp-service-account-key-json\
  \ GCP_SERVICE_ACCOUNT_KEY_JSON]\n                    [--local-loc-dir LOCAL_LOC_DIR]\n\
  \                    [--gcp-loc-dir GCP_LOC_DIR] [--aws-loc-dir AWS_LOC_DIR]\n \
  \                   [--port PORT] [--no-server-heartbeat]\n                    [--server-heartbeat-file\
  \ SERVER_HEARTBEAT_FILE]\n                    [--server-heartbeat-timeout SERVER_HEARTBEAT_TIMEOUT]\n\
  \                    [--hostname HOSTNAME] [-i INPUTS] [-o OPTIONS] [-l LABELS]\n\
  \                    [-p IMPORTS] [-s STR_LABEL] [--hold]\n                    [--singularity-cachedir\
  \ SINGULARITY_CACHEDIR]\n                    [--use-gsutil-for-s3] [--no-deepcopy]\
  \ [--ignore-womtool]\n                    [--womtool WOMTOOL]\n                \
  \    [--java-heap-womtool JAVA_HEAP_WOMTOOL]\n                    [--max-retries\
  \ MAX_RETRIES] [--docker [DOCKER]]\n                    [--singularity [SINGULARITY]]\
  \ [--no-build-singularity]\n                    [--slurm-partition SLURM_PARTITION]\n\
  \                    [--slurm-account SLURM_ACCOUNT]\n                    [--slurm-extra-param\
  \ SLURM_EXTRA_PARAM] [--sge-pe SGE_PE]\n                    [--sge-queue SGE_QUEUE]\n\
  \                    [--sge-extra-param SGE_EXTRA_PARAM]\n                    [--pbs-queue\
  \ PBS_QUEUE]\n                    [--pbs-extra-param PBS_EXTRA_PARAM] [-b BACKEND]\n\
  \                    [--dry-run] [--use-google-cloud-life-sciences]\n          \
  \          [--gcp-zones GCP_ZONES]\n                    wdl\n\npositional arguments:\n\
  \  wdl                   Path, URL or URI for WDL script Example:\n            \
  \            /scratch/my.wdl, gs://some/where/our.wdl,\n                       \
  \ http://hello.com/world/your.wdl\n\noptional arguments:\n  -h, --help         \
  \   show this help message and exit\n  -c CONF, --conf CONF  Specify config file\n\
  \  -D, --debug           Prints all logs >= DEBUG level\n  --gcp-service-account-key-json\
  \ GCP_SERVICE_ACCOUNT_KEY_JSON\n                        Secret key JSON file for\
  \ Google Cloud Platform service\n                        account. This service account\
  \ should have enough\n                        permission to Storage for client functions\
  \ and\n                        Storage/Compute Engine/Genomics API/Life Sciences\
  \ API\n                        for server/runner functions.\n  --port PORT     \
  \      Port for Caper server\n  --no-server-heartbeat\n                        Disable\
  \ server heartbeat file.\n  --server-heartbeat-file SERVER_HEARTBEAT_FILE\n    \
  \                    Heartbeat file for Caper clients to get IP and port of\n  \
  \                      a server\n  --server-heartbeat-timeout SERVER_HEARTBEAT_TIMEOUT\n\
  \                        Timeout for a heartbeat file in Milliseconds. A\n     \
  \                   heartbeat file older than this interval will be\n          \
  \              ignored.\n  --hostname HOSTNAME, --ip HOSTNAME\n                \
  \        Hostname (or IP address) of Caper server.\n  -i INPUTS, --inputs INPUTS\n\
  \                        Workflow inputs JSON file\n  -o OPTIONS, --options OPTIONS\n\
  \                        Workflow options JSON file\n  -l LABELS, --labels LABELS\n\
  \                        Workflow labels JSON file\n  -p IMPORTS, --imports IMPORTS\n\
  \                        Zip file of imported subworkflows\n  -s STR_LABEL, --str-label\
  \ STR_LABEL\n                        Caper's special label for a workflow This label\
  \ will\n                        be added to a workflow labels JSON file as a value\
  \ for\n                        a key \"caper-label\". DO NOT USE IRREGULAR CHARACTERS.\n\
  \                        USE LETTERS, NUMBERS, DASHES AND UNDERSCORES ONLY\n   \
  \                     (^[A-Za-z0-9\\-\\_]+$) since this label is used to\n     \
  \                   compose a path for workflow's temporary/cache\n            \
  \            directory (.caper_tmp/label/timestamp/)\n  --hold                Put\
  \ a hold on a workflow when submitted to a Cromwell\n                        server.\n\
  \  --singularity-cachedir SINGULARITY_CACHEDIR\n                        Singularity\
  \ cache directory. Equivalent to exporting\n                        an environment\
  \ variable SINGULARITY_CACHEDIR. Define\n                        it to prevent repeatedly\
  \ building a singularity image\n                        for every pipeline task\n\
  \  --use-gsutil-for-s3   Use gsutil CLI for direct trasnfer between S3 and GCS\n\
  \                        buckets. Otherwise, such file transfer will stream\n  \
  \                      through local machine. Make sure that gsutil is\n       \
  \                 installed on your system and it has access to\n              \
  \          credentials for AWS (e.g. ~/.boto or\n                        ~/.aws/credentials).\n\
  \  --no-deepcopy         (IMPORTANT) --deepcopy has been deprecated.\n         \
  \               Deepcopying is now activated by default. This flag\n           \
  \             disables deepcopy for JSON (.json), TSV (.tsv) and CSV\n         \
  \               (.csv) files specified in an input JSON file\n                 \
  \       (--inputs). Find all path/URI string values in an\n                    \
  \    input JSON file and make copies of files on a\n                        local/remote\
  \ storage for a target backend. Make sure\n                        that you have\
  \ installed gsutil for GCS and aws for S3.\n  --ignore-womtool      Ignore warnings\
  \ from womtool.jar.\n  --womtool WOMTOOL     Path or URL for Cromwell's womtool\
  \ JAR file\n  --java-heap-womtool JAVA_HEAP_WOMTOOL\n                        Java\
  \ heap size for Womtool (java -Xmx)\n  --max-retries MAX_RETRIES\n             \
  \           Number of retries for failing tasks. equivalent to\n               \
  \         \"maxRetries\" in workflow options JSON file.\n  -b BACKEND, --backend\
  \ BACKEND\n                        Backend to run a workflow\n  --dry-run      \
  \       Caper localizes remote files and validates WDL but\n                   \
  \     does not run/submit a pipeline.\n\ncache directories for localization:\n \
  \ --local-loc-dir LOCAL_LOC_DIR, --tmp-dir LOCAL_LOC_DIR\n                     \
  \   Temporary directory to store Cromwell's intermediate\n                     \
  \   backend files. These files include backend.conf,\n                        workflow_opts.json,\
  \ imports.zip. and localized input\n                        JSON files due to deepcopying\
  \ (recursive\n                        localization). Cromwell's MySQL/PostgreSQL\
  \ DB password\n                        can be exposed on backend.conf on this directory.\n\
  \                        Therefore, DO NOT USE /tmp HERE. This directory is\n  \
  \                      also used for storing cached files for\n                \
  \        local/slurm/sge/pbs backends.\n  --gcp-loc-dir GCP_LOC_DIR, --tmp-gcs-bucket\
  \ GCP_LOC_DIR\n                        Temporary directory to store cached files\
  \ for gcp\n                        backend. e.g. gs://my-bucket/caper-cache-dir.\n\
  \  --aws-loc-dir AWS_LOC_DIR, --tmp-s3-bucket AWS_LOC_DIR\n                    \
  \    Temporary directory to store cached files for aws\n                       \
  \ backend. e.g. s3://my-bucket/caper-cache-dir.\n\ndependency resolver for all backends:\n\
  \  Cloud-based backends (gc and aws) will only use Docker so that \"--docker\n \
  \ URI_FOR_DOCKER_IMG\" must be specified in the command line argument or as a\n\
  \  comment \"#CAPER docker URI_FOR_DOCKER_IMG\" or value for\n  \"workflow.meta.caper_docker\"\
  in a WDL file\n\n  --docker [DOCKER]     URI for Docker image (e.g. ubuntu:latest).\
  \ This can\n                        also be used as a flag to use Docker image address\n\
  \                        defined in your WDL file as a comment (\"#CAPER\n     \
  \                   docker\") or as \"workflow.meta.caper_docker\" in WDL.\n\ndependency\
  \ resolver for local backend:\n  Singularity is for local backend only. Other backends\
  \ (gcp and aws) will\n  use Docker only. Local backend defaults to not use any container-based\n\
  \  methods. Use \"--singularity\" or \"--docker\" to use containers\n\n  --singularity\
  \ [SINGULARITY]\n                        URI or path for Singularity image (e.g.\n\
  \                        ~/.singularity/ubuntu-latest.simg,\n                  \
  \      docker://ubuntu:latest, shub://vsoch/hello-world).\n                    \
  \    This can also be used as a flag to use Docker image\n                     \
  \   address defined in your WDL file as a comment (\"#CAPER\n                  \
  \      singularity\") or as \"workflow.meta.caper_singularity\"\n              \
  \          in WDL.\n  --no-build-singularity\n                        Do not build\
  \ singularity image before running a\n                        workflow.\n\nSLURM\
  \ arguments:\n  --slurm-partition SLURM_PARTITION\n                        SLURM\
  \ partition\n  --slurm-account SLURM_ACCOUNT\n                        SLURM account\n\
  \  --slurm-extra-param SLURM_EXTRA_PARAM\n                        SLURM extra parameters.\
  \ Must be double-quoted\n\nSGE arguments:\n  --sge-pe SGE_PE       SGE parallel\
  \ environment. Check with \"qconf -spl\"\n  --sge-queue SGE_QUEUE\n            \
  \            SGE queue. Check with \"qconf -sql\"\n  --sge-extra-param SGE_EXTRA_PARAM\n\
  \                        SGE extra parameters. Must be double-quoted\n\nPBS arguments:\n\
  \  --pbs-queue PBS_QUEUE\n                        PBS queue\n  --pbs-extra-param\
  \ PBS_EXTRA_PARAM\n                        PBS extra parameters. Must be double-quoted\n\
  \nGCP backend arguments for server/runner/client:\n  --use-google-cloud-life-sciences\n\
  \                        Use Google Cloud Life Sciences API (v2beta) instead of\n\
  \                        deprecated Genomics API (v2alpha1).Life Sciences API\n\
  \                        requires only one region specified withgcp-region.\n  \
  \                      gcp-zones will be ignored since it is for Genomics\n    \
  \                    API.See https://cloud.google.com/life-\n                  \
  \      sciences/docs/concepts/locations for supported\n                        regions.\n\
  \  --gcp-zones GCP_ZONES\n                        Comma-separated GCP zones used\
  \ for Genomics API. (e.g.\n                        us-west1-b,us-central1-b). If\
  \ you use --use-google-\n                        cloud-life-sciences then define\
  \ --gcp-region instead.\n"
generated_using:
- --help
docker_image: quay.io/biocontainers/caper:1.1.0--py_0
