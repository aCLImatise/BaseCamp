from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import File, Directory, Int, String, Boolean

Bohra_Run_V0_1_0 = CommandToolBuilder(tool="bohra_run", base_command=["bohra", "run"], inputs=[ToolInput(tag="in_input_file", input_type=File(optional=True), prefix="--input_file", doc=InputDocumentation(doc="Input file = tab-delimited with 3 columns\n<isolatename> <path_to_read1> <path_to_read2>\n(default: )")), ToolInput(tag="in_job_id", input_type=Directory(optional=True), prefix="--job_id", doc=InputDocumentation(doc="Job ID, will be the name of the output directory\n(default: )")), ToolInput(tag="in_reference", input_type=File(optional=True), prefix="--reference", doc=InputDocumentation(doc="Path to reference (.gbk or .fa) (default: )")), ToolInput(tag="in_mask", input_type=File(optional=True), prefix="--mask", doc=InputDocumentation(doc="Path to mask file if used (.bed) (default: False)")), ToolInput(tag="in_kraken_db", input_type=File(optional=True), prefix="--kraken_db", doc=InputDocumentation(doc="Path to DB for use with kraken2, if no DB present\nspeciation will not be performed. [env var:\nKRAKEN2_DEFAULT_DB] (default: None)")), ToolInput(tag="in_kraken_threads", input_type=Int(optional=True), prefix="--kraken_threads", doc=InputDocumentation(doc="Number of threads for each kraken2 (default: 16)")), ToolInput(tag="in_pipeline", input_type=String(optional=True), prefix="--pipeline", doc=InputDocumentation(doc="The pipeline to run. Preview (--preview - default)\nwill calculate mash-distances and a mash-tree for\nquick inspection of your dataset. SNPs and ASSEMBLIES\n('sa') will perform SNPs and ASSEMBLIES. ALL ('all')\nwill perform SNPS, ASSEMBLIES and ROARY for pan-genome\nanalysis (default: preview)")), ToolInput(tag="in_assembler", input_type=String(optional=True), prefix="--assembler", doc=InputDocumentation(doc="Assembler to use. (default: shovill)")), ToolInput(tag="in_cpus", input_type=Int(optional=True), prefix="--cpus", doc=InputDocumentation(doc="Number of CPU cores to run, will define how many rules\nare run at a time (default: 16)")), ToolInput(tag="in_minal_n", input_type=Int(optional=True), prefix="--minaln", doc=InputDocumentation(doc="Minimum percent alignment. Isolates which do not align\nto reference at this threshold will not be included in\ncore phylogeny. (default: 0)")), ToolInput(tag="in_min_cov", input_type=Int(optional=True), prefix="--mincov", doc=InputDocumentation(doc="Minimum percent alignment. Isolates which do not have\naverage read coverage above this threshold will not be\nincluded further analysis. (default: 0)")), ToolInput(tag="in_prefill_path", input_type=File(optional=True), prefix="--prefillpath", doc=InputDocumentation(doc="Path to existing assemblies - in the form\npath_to_somewhere/isolatename/contigs.fa (default:\nNone)")), ToolInput(tag="in_mdu", input_type=Boolean(optional=True), prefix="-mdu", doc=InputDocumentation(doc="If running on MDU data (default: False)")), ToolInput(tag="in_workdir", input_type=Directory(optional=True), prefix="-workdir", doc=InputDocumentation(doc="The directory where Bohra will be run, default is\ncurrent directory (default: /)")), ToolInput(tag="in_resources", input_type=Directory(optional=True), prefix="-resources", doc=InputDocumentation(doc="Directory where templates are stored (default:\n/usr/local/lib/python3.7/site-\npackages/bohra/templates)")), ToolInput(tag="in_force", input_type=Boolean(optional=True), prefix="-force", doc=InputDocumentation(doc="Add if you would like to force a complete restart of\nthe pipeline. All previous logs will be lost.\n(default: False)")), ToolInput(tag="in_dry_run", input_type=Boolean(optional=True), prefix="-dry-run", doc=InputDocumentation(doc="If you would like to see a dry run of commands to be\nexecuted. (default: False)")), ToolInput(tag="in_cluster", input_type=Boolean(optional=True), prefix="--cluster", doc=InputDocumentation(doc="If you are running Bohra on a cluster. (default:\nFalse)")), ToolInput(tag="in_json", input_type=File(optional=True), prefix="--json", doc=InputDocumentation(doc="Path to cluster.json - required if --cluster is set\n(default: )")), ToolInput(tag="in_queue", input_type=String(optional=True), prefix="--queue", doc=InputDocumentation(doc="Type of queue (sbatch or qsub currently supported) -\nrequired if --cluster is set. (default: )")), ToolInput(tag="in_gubbins", input_type=Boolean(optional=True), prefix="--gubbins", doc=InputDocumentation(doc="Set to use gubbins for recombination correction.\n(default: False)")), ToolInput(tag="in_keep", input_type=String(optional=True), prefix="--keep", doc=InputDocumentation(doc="If you are rerunning bohra over an exisiting directory\nset --keep to 'Y' to archive report files - otherwise\nprevious reprot files will be removed. (default: N)\n"))], outputs=[ToolOutput(tag="out_job_id", output_type=Directory(optional=True), selector=InputSelector(input_to_select="in_job_id", type_hint=File()), doc=OutputDocumentation(doc="Job ID, will be the name of the output directory\n(default: )"))], container="quay.io/biocontainers/bohra:1.2.16--py_0", version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Bohra_Run_V0_1_0().translate("wdl")

