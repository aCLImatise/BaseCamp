from datetime import datetime
from typing import List, Optional, Dict, Any

from janis_core import *
from janis_core.types.common_data_types import String, Directory, File, Int, Boolean

Mikado_Serialise_V0_1_0 = CommandToolBuilder(tool="mikado_serialise", base_command=["mikado", "serialise"], inputs=[ToolInput(tag="in_start_method", input_type=String(optional=True), prefix="--start-method", doc=InputDocumentation(doc="Multiprocessing start method.")), ToolInput(tag="in_output_dir", input_type=Directory(optional=True), prefix="--output-dir", doc=InputDocumentation(doc="Output directory. Default: current working directory")), ToolInput(tag="in_orfs", input_type=File(optional=True), prefix="--orfs", doc=InputDocumentation(doc="ORF BED file(s), separated by commas")), ToolInput(tag="in_transcripts", input_type=File(optional=True), prefix="--transcripts", doc=InputDocumentation(doc="Transcript FASTA file(s) used for ORF calling and\nBLAST queries, separated by commas. If multiple files\nare given, they must be in the same order of the ORF\nfiles. E.g. valid command lines are:\n--transcript_fasta all_seqs1.fasta --orfs all_orfs.bed\n--transcript_fasta seq1.fasta,seq2.fasta --orfs\norfs1.bed,orf2.bed --transcript_fasta all_seqs.fasta\n--orfs orfs1.bed,orf2.bed These are invalid instead: #\nInverted order --transcript_fasta\nseq1.fasta,seq2.fasta --orfs orfs2.bed,orf1.bed #Two\ntranscript files, one ORF file --transcript_fasta\nseq1.fasta,seq2.fasta --orfs all_orfs.bed")), ToolInput(tag="in_max_regression", input_type=Int(optional=True), prefix="--max-regression", doc=InputDocumentation(doc="'Amount of sequence in the ORF (in %) to backtrack in\norder to find a valid START codon, if one is absent.\nDefault: None")), ToolInput(tag="in_codon_table", input_type=Int(optional=True), prefix="--codon-table", doc=InputDocumentation(doc="Codon table to use. Default: 0 (ie Standard, NCBI #1,\nbut only ATG is considered a valid start codon.")), ToolInput(tag="in_no_start_adjustment", input_type=Boolean(optional=True), prefix="--no-start-adjustment", doc=InputDocumentation(doc="Disable the start adjustment algorithm. Useful when\nusing e.g. TransDecoder vs 5+.")), ToolInput(tag="in_max_target_seqs", input_type=Int(optional=True), prefix="--max-target-seqs", doc=InputDocumentation(doc="Maximum number of target sequences.")), ToolInput(tag="in_blast_targets", input_type=String(optional=True), prefix="--blast-targets", doc=InputDocumentation(doc="Target sequences")), ToolInput(tag="in_xml", input_type=Int(optional=True), prefix="--xml", doc=InputDocumentation(doc="BLAST file(s) to parse. They can be provided in three\nways: - a comma-separated list - as a base folder -\nusing bash-like name expansion (*,?, etc.). In this\ncase, you have to enclose the filename pattern in\ndouble quotes. Multiple folders/file patterns can be\ngiven, separated by a comma. BLAST files must be\neither of two formats: - BLAST XML - BLAST tabular\nformat, with the following **custom** fields: qseqid\nsseqid pident length mismatch gapopen qstart qend\nsstart send evalue bitscore ppos btop")), ToolInput(tag="in_procs", input_type=Int(optional=True), prefix="--procs", doc=InputDocumentation(doc="Number of threads to use for analysing the BLAST\nfiles. This number should not be higher than the total\nnumber of XML files.")), ToolInput(tag="in_single_thread", input_type=Boolean(optional=True), prefix="--single-thread", doc=InputDocumentation(doc="Force serialise to run with a single thread,\nirrespective of other configuration options.")), ToolInput(tag="in_external_scores", input_type=File(optional=True), prefix="--external-scores", doc=InputDocumentation(doc="Tabular file containing external scores for the\ntranscripts. Each column should have a distinct name,\nand transcripts have to be listed on the first column.")), ToolInput(tag="in_max_objects", input_type=Int(optional=True), prefix="--max-objects", doc=InputDocumentation(doc="Maximum number of objects to cache in memory before\ncommitting to the database. Default: 100,000 i.e.\napproximately 450MB RAM usage for Drosophila.")), ToolInput(tag="in_force", input_type=Boolean(optional=True), prefix="--force", doc=InputDocumentation(doc="Flag. If set, an existing databse will be deleted\n(sqlite) or dropped (MySQL/PostGreSQL) before\nbeginning the serialisation.")), ToolInput(tag="in_optional_log_file", input_type=File(optional=True), prefix="--json-conf", doc=InputDocumentation(doc="[LOG], --log [LOG]\nOptional log file. Default: stderr")), ToolInput(tag="in_log_level", input_type=String(optional=True), prefix="--log-level", doc=InputDocumentation(doc="Log level. Default: derived from the configuration; if\nabsent, INFO")), ToolInput(tag="in_db", input_type=String(), position=0, doc=InputDocumentation(doc="Optional output database. Default: derived from")), ToolInput(tag="in__seed_seed", input_type=String(), position=1, doc=InputDocumentation(doc="--seed SEED           Random seed number."))], outputs=[ToolOutput(tag="out_output_dir", output_type=Directory(optional=True), selector=InputSelector(input_to_select="in_output_dir", type_hint=File()), doc=OutputDocumentation(doc="Output directory. Default: current working directory"))], container=None, version="v0.1.0")


if __name__ == "__main__":
    # or "cwl"
    Mikado_Serialise_V0_1_0().translate("wdl", allow_empty_container=True)

