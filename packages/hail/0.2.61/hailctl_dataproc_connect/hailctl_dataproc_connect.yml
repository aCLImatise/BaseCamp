!Command
command:
- hailctl
- dataproc
- connect
positional: []
named:
- !Flag
  optional: true
  synonyms:
  - --project
  description: "Google Cloud project for the cluster (defaults to\ncurrently set project)."
  args: !SimpleFlagArg
    name: PROJECT
- !Flag
  optional: true
  synonyms:
  - --port
  - -p
  description: "Local port to use for SSH tunnel to leader (master)\nnode (default:\
    \ 10000)."
  args: !SimpleFlagArg
    name: PORT
- !Flag
  optional: true
  synonyms:
  - --zone
  - -z
  description: Compute zone for Dataproc cluster.
  args: !SimpleFlagArg
    name: ZONE
- !Flag
  optional: true
  synonyms:
  - --dry-run
  description: Print gcloud dataproc command, but don't run it.
  args: !EmptyFlagArg {}
parent:
subcommands: []
usage: []
help_flag: !Flag
  optional: true
  synonyms:
  - -h
  - --help
  description: show this help message and exit
  args: !EmptyFlagArg {}
usage_flag:
version_flag:
help_text: "usage: hailctl dataproc connect [-h] [--project PROJECT] [--port PORT]\n\
  \                                [--zone ZONE] [--dry-run]\n                   \
  \             name\n                                {notebook,nb,spark-ui,ui,spark-history,hist}\n\
  \nConnect to a running Dataproc cluster.\n\npositional arguments:\n  name      \
  \            Cluster name.\n  {notebook,nb,spark-ui,ui,spark-history,hist}\n   \
  \                     Web service to launch.\n\noptional arguments:\n  -h, --help\
  \            show this help message and exit\n  --project PROJECT     Google Cloud\
  \ project for the cluster (defaults to\n                        currently set project).\n\
  \  --port PORT, -p PORT  Local port to use for SSH tunnel to leader (master)\n \
  \                       node (default: 10000).\n  --zone ZONE, -z ZONE  Compute\
  \ zone for Dataproc cluster.\n  --dry-run             Print gcloud dataproc command,\
  \ but don't run it.\n"
generated_using:
- --help
docker_image: quay.io/biocontainers/hail:0.2.61--py36hf1ae8f4_1
